{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peUcVKtbGPfD"
   },
   "source": [
    "# Visualization Playground\n",
    "\n",
    "## Import Libraries and seed\n",
    "Import the necessary libraries for data processing, model building, training, and evaluation. Adding a seed ensures reproducibility by making sure that the random number generation is consistent across different runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15527,
     "status": "ok",
     "timestamp": 1731066553135,
     "user": {
      "displayName": "DANIEL MORENO PARIS",
      "userId": "17921422726169854440"
     },
     "user_tz": -60
    },
    "id": "9a9HvzrNG8iw",
    "outputId": "19350658-7b5d-48e7-e90c-e7ddb3a578b1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    return seed\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1731066584724,
     "user": {
      "displayName": "DANIEL MORENO PARIS",
      "userId": "17921422726169854440"
     },
     "user_tz": -60
    },
    "id": "hAY8BfVX9XCK"
   },
   "outputs": [],
   "source": [
    "def load_data_from_directory(input_path):\n",
    "    data_frames = []\n",
    "    for file in os.listdir(input_path):\n",
    "        if file.endswith('.csv'):\n",
    "            df = pd.read_csv(os.path.join(input_path, file), delimiter=';', header=0)\n",
    "            data_frames.append(df)\n",
    "    data = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wiCTw-qcKXhn"
   },
   "source": [
    "## Preprocessing Data - Dispersion\n",
    "Define a function to preprocess the data. This includes encoding categorical labels and standardizing the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1731066584724,
     "user": {
      "displayName": "DANIEL MORENO PARIS",
      "userId": "17921422726169854440"
     },
     "user_tz": -60
    },
    "id": "zJoZqi5LDPl8"
   },
   "outputs": [],
   "source": [
    "def calculate_averages_and_dispersion(df, data_percentage):\n",
    "\n",
    "    results = []\n",
    "    for (sample, freq), group in df.groupby(['Sample', 'Frequency (GHz)']):\n",
    "        window_size = max(1, int(len(group) * data_percentage / 100))\n",
    "        # print(f\"Processing sample: {sample}, frequency: {freq} with window size: {window_size}\")\n",
    "        for start in range(0, len(group), window_size):\n",
    "            window_data = group.iloc[start:start + window_size]\n",
    "            mean_values = window_data[['LG (mV)', 'HG (mV)']].mean()\n",
    "            std_deviation_values = window_data[['LG (mV)', 'HG (mV)']].std()\n",
    "            results.append({\n",
    "                'Frequency (GHz)': freq,\n",
    "                'LG (mV) mean': mean_values['LG (mV)'],\n",
    "                'HG (mV) mean': mean_values['HG (mV)'],\n",
    "                'LG (mV) std deviation': std_deviation_values['LG (mV)'],\n",
    "                'HG (mV) std deviation': std_deviation_values['HG (mV)'],\n",
    "                # 'Thickness (mm)': window_data['Thickness (mm)'].iloc[0], ## COMMENT\n",
    "                'Sample': sample,\n",
    "            })\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXiN30xA1kKX"
   },
   "source": [
    "## Pivoting Frequency values to columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 235,
     "status": "ok",
     "timestamp": 1731067118965,
     "user": {
      "displayName": "DANIEL MORENO PARIS",
      "userId": "17921422726169854440"
     },
     "user_tz": -60
    },
    "id": "Kijzt73J1nyo"
   },
   "outputs": [],
   "source": [
    "def freq_as_variable(df, data_percentage):\n",
    "    '''Modify df to have Frequency values (100,110,120 and so on) as input variables in the columns'''\n",
    "\n",
    "    # Remove Thickness column\n",
    "    if 'Thickness (mm)' in df.columns:\n",
    "        df = df.drop(columns=['Thickness (mm)'])\n",
    "\n",
    "    if data_percentage > 0:\n",
    "        # 1s window_size 100/27s = 3.7% of the data is used for each window\n",
    "        df_window = calculate_averages_and_dispersion(df, data_percentage) \n",
    "\n",
    "        # Add a unique identifier column to avoid duplicate entries in the index\n",
    "        df_window['unique_id'] = df_window.groupby(['Sample', 'Frequency (GHz)']).cumcount()\n",
    "\n",
    "        # Pivot the DataFrame to wide format\n",
    "        df_pivot = df_window.pivot(index=['Sample', 'unique_id'], columns='Frequency (GHz)')\n",
    "\n",
    "        # Flatten the MultiIndex columns - Ordered by Frequency + (HG mean, HG std deviation, LG mean, LG std deviation)\n",
    "        df_pivot.columns = [' '.join([str(col[1]), str(col[0])]) for col in df_pivot.columns]\n",
    "\n",
    "        # Drop columns with all NaN values\n",
    "        df_pivot = df_pivot.dropna(axis=1, how='all')\n",
    "\n",
    "        # Reset index to make 'Sample' and 'unique_id' columns again\n",
    "        df_pivot = df_pivot.reset_index()\n",
    "\n",
    "        # Remove 'unique_id' column\n",
    "        df_pivot = df_pivot.drop(columns=['unique_id'])\n",
    "    else:\n",
    "        # If data_percentage is 0, do not calculate mean and std deviation, use the original data\n",
    "        df['unique_id'] = df.groupby(['Sample', 'Frequency (GHz)']).cumcount()\n",
    "        df_pivot = df.pivot(index=['Sample', 'unique_id'], columns='Frequency (GHz)')\n",
    "        df_pivot.columns = [' '.join([str(col[1]), str(col[0])]) for col in df_pivot.columns]\n",
    "        df_pivot = df_pivot.dropna(axis=1, how='all')\n",
    "        df_pivot = df_pivot.reset_index()\n",
    "        df_pivot = df_pivot.drop(columns=['unique_id'])\n",
    "\n",
    "    df_pivot = df_pivot.reindex(sorted(df_pivot.columns), axis=1)\n",
    "\n",
    "    return df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 652
    },
    "executionInfo": {
     "elapsed": 52182,
     "status": "error",
     "timestamp": 1731067172783,
     "user": {
      "displayName": "DANIEL MORENO PARIS",
      "userId": "17921422726169854440"
     },
     "user_tz": -60
    },
    "id": "UTXvxCzu6MBA",
    "outputId": "41925df4-d9a4-424b-fc94-bf98e95a101b"
   },
   "outputs": [],
   "source": [
    "# Load the data from the directory\n",
    "input_path = 'C:/Users/Danim/Documents/GitHub/PIC-PAPER-01/data/experiment_5_plastics/processed/'\n",
    "\n",
    "df = load_data_from_directory(input_path)\n",
    "\n",
    "df = pd.concat([df[['Frequency (GHz)', 'LG (mV)', 'HG (mV)']], df[['Sample']]], axis=1)\n",
    "\n",
    "# df.head()\n",
    "df.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples per frequency and Sample\n",
    "bx = df.groupby(['Sample', 'Frequency (GHz)']).size().unstack().plot.bar(figsize=(16, 4), stacked=True)\n",
    "bx.set_xlabel('Samples')\n",
    "bx.set_ylabel('Frequency (GHz)')\n",
    "plt.tight_layout()\n",
    "bx.get_legend().remove() #remove legend\n",
    "plt.show()\n",
    "\n",
    "# Balance the data by taking the mode of samples per frequency\n",
    "mean= int(df.groupby(['Sample', 'Frequency (GHz)']).size().mean())\n",
    "print(f'Mean value: {mean}')\n",
    "\n",
    "\n",
    "# Function to reduce samples to the mean value\n",
    "def reduce_to_mean(df, sample, frequency, mean):\n",
    "    # Filter the DataFrame for the specific sample and frequency\n",
    "    freq_df = df[(df['Sample'] == sample) & (df['Frequency (GHz)'] == frequency)]\n",
    "    # If the number of samples is greater than the mean, sample down to the mean\n",
    "    if len(freq_df) > mean:\n",
    "        return freq_df.sample(n=mean, random_state=42)\n",
    "    return freq_df\n",
    "\n",
    "# Apply the function to reduce samples for each combination of Sample and Frequency (GHz)\n",
    "balanced_data = []\n",
    "for (sample, frequency), group in df.groupby(['Sample', 'Frequency (GHz)']):\n",
    "    balanced_data.append(reduce_to_mean(df, sample, frequency, mean))\n",
    "\n",
    "# Combine the balanced samples into a single DataFrame\n",
    "df_balanced = pd.concat(balanced_data)\n",
    "\n",
    "bx = df_balanced.groupby(['Sample', 'Frequency (GHz)']).size().unstack().plot.bar(figsize=(16, 4), stacked=True)\n",
    "bx.set_ylabel('Frequency (GHz)')\n",
    "plt.tight_layout()\n",
    "# legend small\n",
    "bx.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "bx.get_legend().remove() #remove legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set, test_set = train_test_split(df, test_size=0.2, random_state=42, stratify=df['Sample']) \n",
    "test_percentage = 0.2\n",
    "# train_set, test_set = train_test_split(df, test_size=test_percentage, random_state=42) \n",
    "# Shuffle the data\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42)\n",
    "# train_set, test_set = train_test_split(df_balanced, test_size=test_percentage, random_state=42) \n",
    "\n",
    "# stratify=df['Sample'] to keep the same proportion of samples in the train and test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Distribution per frequency and Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train_ex = df_balanced.copy()\n",
    "\n",
    "print(train_ex.head())\n",
    "\n",
    "# Create directory for saving PDFs\n",
    "output_path = os.path.normpath(os.path.join(os.getcwd(), '..', '..', 'results/distribution_plots/'))\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# Create separate PDF for each frequency\n",
    "for f in train_ex['Frequency (GHz)'].value_counts().index.sort_values().tolist():\n",
    "    freq = f\n",
    "    ncols = 4\n",
    "    nrows = 12\n",
    "    nums_plastics = 0\n",
    "    \n",
    "    # Create individual PDF file for each frequency\n",
    "    with PdfPages(os.path.join(output_path, f'frequency_{freq}_GHz_distributions.pdf')) as pdf:\n",
    "        fig, axes = plt.subplots(nrows, ncols, figsize=(14, 20))\n",
    "        axes = axes.flatten()  # Flatten the axes array\n",
    "        \n",
    "        for r in range(nrows * ncols):  # Adjust the loop to iterate over the flattened array\n",
    "            t = train_ex['Sample'].value_counts().index.sort_values().tolist()\n",
    "            if nums_plastics < len(t):\n",
    "                df_tmp = train_ex[(train_ex['Frequency (GHz)'] == freq) & (train_ex['Sample'] == t[nums_plastics])]\n",
    "                sns.kdeplot(x=df_tmp['LG (mV)'], ax=axes[r], color='#F8766D', label='LG (mV)', fill=True)\n",
    "                sns.kdeplot(x=df_tmp['HG (mV)'], ax=axes[r], color='#00BFC4', label='HG (mV)', fill=True)\n",
    "                axes[r].legend(fontsize=\"small\")  # Increased from \"xx-small\"\n",
    "                axes[r].set_ylabel('')\n",
    "                axes[r].set_xlabel('')\n",
    "                axes[r].set_title(f\"Type {t[nums_plastics]} (mV)\", fontsize=10)  # Increased from 7\n",
    "                axes[r].tick_params(labelsize=8, width=0.5)  # Increased from 5\n",
    "                axes[r].xaxis.offsetText.set_fontsize(8)  # Increased from 6\n",
    "                axes[r].yaxis.offsetText.set_fontsize(8)  # Increased from 4\n",
    "                axes[r].set_xlim(-50, 1000)\n",
    "                nums_plastics += 1\n",
    "            else:\n",
    "                axes[r].axis('off')\n",
    "        \n",
    "        plt.suptitle(f\"All samples. Distribution of LG (mV) and HG (mV) of each plastic to {freq} GHz\", \n",
    "                    y=0.98, fontsize=12)  # Increased y from 0.93 to 0.98 and fontsize from 10 to 12\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjusted bottom margin from 0.95 to 0.96\n",
    "\n",
    "        # Save this frequency chart to its individual PDF\n",
    "        pdf.savefig(fig, bbox_inches='tight', dpi=300, facecolor='white')\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()  # Close the figure to free memory\n",
    "\n",
    "print(f\"Individual PDF files created for each frequency in: {output_path}\")\n",
    "print(\"Files created:\")\n",
    "for f in train_ex['Frequency (GHz)'].value_counts().index.sort_values().tolist():\n",
    "    print(f\"- frequency_{f}_GHz_distributions.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[\"' + '\", \"'.join(df_balanced['Sample'].unique()) + '\"]') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best frequencies for each sample\n",
    "\n",
    "df_tmp = df_balanced.copy()\n",
    "\n",
    "# Remove every character of the sample but the first one\n",
    "df_tmp['Sample'] = df_tmp['Sample'].str[0]\n",
    "\n",
    "# For every unique sample, calculate and print the mean and standard deviation of HG (mV) for each frequency\n",
    "unique_samples = df_tmp['Sample'].unique()\n",
    "\n",
    "for sample in unique_samples:\n",
    "    sample_df = df_tmp[df_tmp['Sample'] == sample]\n",
    "    sample_stats = sample_df.groupby('Frequency (GHz)')['HG (mV)'].agg(['mean', 'std']).reset_index()\n",
    "    \n",
    "    # Ensure 'mean' column is numeric\n",
    "    sample_stats['mean'] = pd.to_numeric(sample_stats['mean'], errors='coerce')\n",
    "    \n",
    "    # Filter frequencies with mean higher than 50\n",
    "    filtered_sample_stats = sample_stats[sample_stats['mean'] > 50]\n",
    "    \n",
    "    # Sort by standard deviation value\n",
    "    sorted_sample_stats = filtered_sample_stats.sort_values(by='std', ascending=False)\n",
    "    \n",
    "    # Print the sorted list\n",
    "    print(f\"Sample: {sample}\")\n",
    "    print(sorted_sample_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mV Average with error per frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_balanced.copy()\n",
    "\n",
    "# Remove every character of the sample but the first one\n",
    "df_tmp['Sample'] = df_tmp['Sample'].str[0]\n",
    "\n",
    "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'O']\n",
    "# labels = random.sample(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'O'], 4)\n",
    "\n",
    "# Define a color palette\n",
    "palette = sns.color_palette(\"husl\", len(labels))\n",
    "\n",
    "def adjust_color_brightness(color, factor=0.6):\n",
    "    return tuple([min(1, max(0, c * factor)) for c in color])\n",
    "\n",
    "with PdfPages('output_plots.pdf') as pdf:\n",
    "    fig, axes = plt.subplots(12, 1, figsize=(20, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        # Filter the DataFrame for the specific sample\n",
    "        df = df_tmp[df_tmp['Sample'].str.startswith(label)]\n",
    "\n",
    "        hg_stats = df.groupby(['Sample', 'Frequency (GHz)'])['HG (mV)'].agg(['mean', 'std']).reset_index()\n",
    "        lg_stats = df.groupby(['Sample', 'Frequency (GHz)'])['LG (mV)'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "        # Calculate the upper and lower bounds for HG\n",
    "        hg_stats['mean_plus_std'] = hg_stats['mean'] + hg_stats['std']\n",
    "        hg_stats['mean_minus_std'] = hg_stats['mean'] - hg_stats['std']\n",
    "\n",
    "        # Calculate the upper and lower bounds for LG\n",
    "        lg_stats['mean_plus_std'] = lg_stats['mean'] + lg_stats['std']\n",
    "        lg_stats['mean_minus_std'] = lg_stats['mean'] - lg_stats['std']\n",
    "\n",
    "        # Plot the average HG (mV) with shadow area for mean ± standard deviation\n",
    "        sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "        # Plot mean line for HG\n",
    "        sns.lineplot(data=hg_stats, x='Frequency (GHz)', y='mean', marker='', color=palette[i], linewidth=2, label='HG Mean', ax=axes[i])\n",
    "\n",
    "        # Plot shadow area for HG mean ± 1 std\n",
    "        axes[i].fill_between(hg_stats['Frequency (GHz)'], hg_stats['mean_minus_std'], hg_stats['mean_plus_std'], color=palette[i], alpha=0.2, label='HG Mean ± Std')\n",
    "\n",
    "        # Plot mean line for LG with darker color\n",
    "        darker_color = adjust_color_brightness(palette[i])\n",
    "        sns.lineplot(data=lg_stats, x='Frequency (GHz)', y='mean', marker='', color=darker_color, linewidth=2, label='LG Mean', ax=axes[i])\n",
    "\n",
    "        # Plot shadow area for LG mean ± 1 std\n",
    "        axes[i].fill_between(lg_stats['Frequency (GHz)'], lg_stats['mean_minus_std'], lg_stats['mean_plus_std'], color=darker_color, alpha=0.2, label='LG Mean ± Std', linestyle='--')\n",
    "\n",
    "        # Add labels and title\n",
    "        axes[i].set_xlabel('Frequency (GHz)', fontsize=12)\n",
    "        axes[i].set_ylabel('mV', fontsize=12)\n",
    "        axes[i].set_title(f'{label}', fontsize=10)\n",
    "\n",
    "        # Customize legend\n",
    "        axes[i].legend(fontsize=10, title='Legend', title_fontsize='13')\n",
    "\n",
    "        # Customize grid and background\n",
    "        axes[i].grid(True, linestyle='--', alpha=0.6)\n",
    "        axes[i].set_facecolor('#f9f9f9')\n",
    "\n",
    "        # # Set y-axis limit\n",
    "        # axes[i].set_ylim(0, 1200)\n",
    "\n",
    "        # Set y-axis ticks every 100 units\n",
    "        axes[i].set_yticks(np.arange(0, 1200, 100))\n",
    "\n",
    "        # Set x-axis ticks every 50 units\n",
    "        axes[i].set_xticks(np.arange(100, 600, 50))\n",
    "\n",
    "    # Add a main title for all charts\n",
    "    fig.suptitle('Average HG (mV) and LG (mV) with Mean ± Standard Deviation for Each Frequency', fontsize=16, y=1.02)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_balanced.copy()\n",
    "\n",
    "# Remove every character of the sample but the first one\n",
    "df_tmp['Sample'] = df_tmp['Sample'].str[0]\n",
    "\n",
    "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'O']\n",
    "\n",
    "# Define a color palette\n",
    "palette = sns.color_palette(\"husl\", len(labels))\n",
    "\n",
    "def adjust_color_brightness(color, factor=0.6):\n",
    "    return tuple([min(1, max(0, c * factor)) for c in color])\n",
    "\n",
    "# Create separate PDF for each sample\n",
    "for i, label in enumerate(labels):\n",
    "    # Create individual PDF file for each sample\n",
    "    with PdfPages(f'output_plot_{label}.pdf') as pdf:\n",
    "        # Filter the DataFrame for the specific sample\n",
    "        df = df_tmp[df_tmp['Sample'].str.startswith(label)]\n",
    "\n",
    "        hg_stats = df.groupby(['Sample', 'Frequency (GHz)'])['HG (mV)'].agg(['mean', 'std']).reset_index()\n",
    "        lg_stats = df.groupby(['Sample', 'Frequency (GHz)'])['LG (mV)'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "        # Calculate the upper and lower bounds for HG\n",
    "        hg_stats['mean_plus_std'] = hg_stats['mean'] + hg_stats['std']\n",
    "        hg_stats['mean_minus_std'] = hg_stats['mean'] - hg_stats['std']\n",
    "\n",
    "        # Calculate the upper and lower bounds for LG\n",
    "        lg_stats['mean_plus_std'] = lg_stats['mean'] + lg_stats['std']\n",
    "        lg_stats['mean_minus_std'] = lg_stats['mean'] - lg_stats['std']\n",
    "\n",
    "        # Create individual figure for this sample\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "        \n",
    "        # Plot the average HG (mV) with shadow area for mean ± standard deviation\n",
    "        sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "        # Plot mean line for HG\n",
    "        sns.lineplot(data=hg_stats, x='Frequency (GHz)', y='mean', marker='o', \n",
    "                    color=palette[i], linewidth=2, label='HG Mean', ax=ax)\n",
    "\n",
    "        # Plot shadow area for HG mean ± 1 std\n",
    "        ax.fill_between(hg_stats['Frequency (GHz)'], hg_stats['mean_minus_std'], \n",
    "                       hg_stats['mean_plus_std'], color=palette[i], alpha=0.2, \n",
    "                       label='HG Mean ± Std')\n",
    "\n",
    "        # Plot mean line for LG with darker color\n",
    "        darker_color = adjust_color_brightness(palette[i])\n",
    "        sns.lineplot(data=lg_stats, x='Frequency (GHz)', y='mean', marker='s', \n",
    "                    color=darker_color, linewidth=2, label='LG Mean', ax=ax)\n",
    "\n",
    "        # Plot shadow area for LG mean ± 1 std\n",
    "        ax.fill_between(lg_stats['Frequency (GHz)'], lg_stats['mean_minus_std'], \n",
    "                       lg_stats['mean_plus_std'], color=darker_color, alpha=0.2, \n",
    "                       label='LG Mean ± Std')\n",
    "\n",
    "        # Add labels and title\n",
    "        ax.set_xlabel('Frequency (GHz)', fontsize=14)\n",
    "        ax.set_ylabel('mV', fontsize=14)\n",
    "        ax.set_title(f'Sample {label} - Average HG and LG with Mean ± Standard Deviation', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "\n",
    "        # Customize legend\n",
    "        ax.legend(fontsize=12, title='Legend', title_fontsize='14')\n",
    "\n",
    "        # Customize grid and background\n",
    "        ax.grid(True, linestyle='--', alpha=0.6)\n",
    "        ax.set_facecolor('#f9f9f9')\n",
    "\n",
    "        # Set y-axis ticks every 100 units\n",
    "        ax.set_yticks(np.arange(0, 1200, 100))\n",
    "\n",
    "        # Set x-axis ticks every 50 units\n",
    "        ax.set_xticks(np.arange(100, 600, 50))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the individual plot to its PDF\n",
    "        pdf.savefig(fig, bbox_inches='tight', dpi=300)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "print(\"Individual PDF files created for each sample:\")\n",
    "for label in labels:\n",
    "    print(f\"- output_plot_{label}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot average HG (mV) with shadow area for mean ± standard deviation of each of the selected groups of samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_balanced.copy()\n",
    "\n",
    "labels = [['C1_3', 'C2_15', 'C3_27', 'C4_45'], ['E1_5', 'E2_17', 'E3_29', 'E4_47']]\n",
    "\n",
    "labels = [\n",
    "    [\"A1_1\", \"A2_13\", \"A3_25\", \"A4_43\"],\n",
    "    [\"B1_2\", \"B2_14\", \"B3_26\", \"B4_44\"],\n",
    "    [\"C1_3\", \"C2_15\", \"C3_27\", \"C4_45\"],\n",
    "    [\"D1_4\", \"D2_16\", \"D3_28\", \"D4_46\"],\n",
    "    # [\"E1_5\", \"E2_17\", \"E3_29\", \"E4_47\"],\n",
    "    # [\"F1_6\", \"F2_18\", \"F3_30\", \"F4_48\"],\n",
    "    # [\"G1_7\", \"G2_19\", \"G3_31\", \"G4_37\"],\n",
    "    # [\"H1_8\", \"H2_20\", \"H3_32\", \"H4_38\"],\n",
    "    # [\"I1_9\", \"I2_21\", \"I3_33\", \"I4_39\"],\n",
    "    # [\"J1_10\", \"J2_22\", \"J3_34\", \"J4_40\"],\n",
    "    # [\"L1_11\", \"L2_23\", \"L3_35\", \"L4_41\"],\n",
    "    # [\"O1_12\", \"O2_24\", \"O3_36\", \"O4_42\"]\n",
    "]\n",
    "\n",
    "with PdfPages('output_charts.pdf') as pdf:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    for label_group in labels:\n",
    "        # Filter the DataFrame for the specific group of samples\n",
    "        df_group = df_tmp[df_tmp['Sample'].isin(label_group)]\n",
    "\n",
    "        # Calculate mean and std deviation for the group\n",
    "        group_stats = df_group.groupby('Frequency (GHz)')['HG (mV)'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "        # Calculate the upper and lower bounds\n",
    "        group_stats['mean_plus_std'] = group_stats['mean'] + group_stats['std']\n",
    "        group_stats['mean_minus_std'] = group_stats['mean'] - group_stats['std']\n",
    "\n",
    "        # Plot mean line\n",
    "        sns.lineplot(data=group_stats, x='Frequency (GHz)', y='mean', marker='', label=f'{label_group} Mean')\n",
    "\n",
    "        # Plot shadow area for mean ± 1 std\n",
    "        plt.fill_between(group_stats['Frequency (GHz)'], group_stats['mean_minus_std'], group_stats['mean_plus_std'], alpha=0.2, label=f'{label_group} Mean ± Std')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Frequency (GHz)', fontsize=12)\n",
    "    plt.ylabel('HG (mV)', fontsize=12)\n",
    "    plt.title('Average HG (mV) with Mean ± Standard Deviation for Each Group of Samples', fontsize=16)\n",
    "\n",
    "    # X axis space adjustment (show 1 of each 2 ticks)\n",
    "    plt.xticks(group_stats['Frequency (GHz)'].unique(), rotation=45)\n",
    "\n",
    "    # Customize legend\n",
    "    plt.legend(fontsize=10, title='Legend', title_fontsize='13')\n",
    "\n",
    "    # Customize grid and background\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.gca().set_facecolor('#f9f9f9')\n",
    "\n",
    "    # Save plot to PDF\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "print(\"Charts saved as output_charts.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_balanced.copy()\n",
    "\n",
    "labels = [\n",
    "    [\"A1_1\", \"A2_13\", \"A3_25\", \"A4_43\"],\n",
    "    [\"B1_2\", \"B2_14\", \"B3_26\", \"B4_44\"],\n",
    "    [\"C1_3\", \"C2_15\", \"C3_27\", \"C4_45\"],\n",
    "    [\"D1_4\", \"D2_16\", \"D3_28\", \"D4_46\"],\n",
    "    # [\"E1_5\", \"E2_17\", \"E3_29\", \"E4_47\"],\n",
    "    # [\"F1_6\", \"F2_18\", \"F3_30\", \"F4_48\"],\n",
    "    # [\"G1_7\", \"G2_19\", \"G3_31\", \"G4_37\"],\n",
    "    # [\"H1_8\", \"H2_20\", \"H3_32\", \"H4_38\"],\n",
    "    # [\"I1_9\", \"I2_21\", \"I3_33\", \"I4_39\"],\n",
    "    # [\"J1_10\", \"J2_22\", \"J3_34\", \"J4_40\"],\n",
    "    # [\"L1_11\", \"L2_23\", \"L3_35\", \"L4_41\"],\n",
    "    # [\"O1_12\", \"O2_24\", \"O3_36\", \"O4_42\"]\n",
    "]\n",
    "\n",
    "with PdfPages('output_charts_error_bar.pdf') as pdf:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    for label_group in labels:\n",
    "        # Filter the DataFrame for the specific group of samples\n",
    "        df_group = df_tmp[df_tmp['Sample'].isin(label_group)]\n",
    "\n",
    "        # Calculate mean and std deviation for the group\n",
    "        group_stats = df_group.groupby('Frequency (GHz)')['HG (mV)'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "        # Plot mean line with error bars for std deviation\n",
    "        plt.errorbar(group_stats['Frequency (GHz)'], group_stats['mean'], yerr=group_stats['std'], fmt='-o', label=f'{label_group} Mean ± Std', linewidth=1, capsize=3)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Frequency (GHz)', fontsize=12)\n",
    "    plt.ylabel('HG (mV)', fontsize=12)\n",
    "    plt.title('Average HG (mV) with Mean ± Standard Deviation for Each Group of Samples', fontsize=16)\n",
    "\n",
    "    # X axis space adjustment (show 1 of each 2 ticks)\n",
    "    plt.xticks(group_stats['Frequency (GHz)'].unique(), rotation=45)\n",
    "\n",
    "    # Customize legend\n",
    "    plt.legend(fontsize=10, title='Legend', title_fontsize='13')\n",
    "\n",
    "    # Customize grid and background\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.gca().set_facecolor('#f9f9f9')\n",
    "\n",
    "    # Save plot to PDF\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "print(\"Charts saved as output_charts_error_bar.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Windowing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of data used for each window\n",
    "time_window_s = 0.1\n",
    "data_percentage = (100/(27*(1-test_percentage)))*time_window_s\n",
    "data_percentage_test = (100/(27*(test_percentage)))*time_window_s\n",
    "\n",
    "data_percentage = 0\n",
    "data_percentage_test = 0\n",
    "\n",
    "print(f\"Data percentage: {data_percentage}%\")\n",
    "print(f\"Data percentage test: {data_percentage_test}%\")\n",
    "\n",
    "# Load just a % of the data\n",
    "# df_sample = train_set.sample(frac=0.02, random_state=42)\n",
    "\n",
    "# Introduce Frequency values as input variables\n",
    "train_set_test = freq_as_variable(train_set, data_percentage)\n",
    "test_set_test = freq_as_variable(test_set, data_percentage_test)\n",
    "\n",
    "# If a row has any NaN value, remove that row\n",
    "train_set_test = train_set_test.dropna()\n",
    "test_set_test = test_set_test.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsupervised clusterization of every sample for each frequency\n",
    "# Define the number of clusters\n",
    "n_clusters = 15\n",
    "\n",
    "# Define the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('kmeans', KMeans(n_clusters=n_clusters, random_state=42))\n",
    "])\n",
    "\n",
    "# Define the frequencies and samples\n",
    "frequencies = train_ex['Frequency (GHz)'].unique()\n",
    "samples = train_ex['Sample'].unique()\n",
    "\n",
    "# Define the 14 colors and markers\n",
    "# Define 14 colors and markers\n",
    "colors = ['#F8766D', '#00BFC4', '#7CAE00', '#C77CFF', '#FF61C3', '#00BA38', '#619CFF', '#F564E3', '#00A9FF', '#FF9F00', '#00BFC4', '#F8766D', '#7CAE00', '#C77CFF', '#FF61C3']\n",
    "markers = ['o', 's', 'D', '^', 'v', '<', '>', 'p', '*', 'h', 'H', 'd', 'P', 'X', '8']\n",
    "\n",
    "# Create subplots\n",
    "ncols = 5\n",
    "nrows = int(np.ceil(len(frequencies) / ncols))\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(20, nrows * 4), sharex=True, sharey=True)\n",
    "\n",
    "# Ensure axes is iterable\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop over frequencies\n",
    "for idx, f in enumerate(frequencies):\n",
    "    n_samples = 0\n",
    "    # Loop over samples\n",
    "    for s in samples:\n",
    "        # Filter the DataFrame\n",
    "        df_tmp = train_ex[(train_ex['Frequency (GHz)'] == f) & (train_ex['Sample'] == s)]\n",
    "        # Check if there are enough samples\n",
    "        if len(df_tmp) >= n_clusters:\n",
    "            # Fit the pipeline\n",
    "            pipe.fit(df_tmp[['LG (mV)', 'HG (mV)']])\n",
    "            # Get the cluster labels\n",
    "            labels = pipe.named_steps['kmeans'].labels_\n",
    "            # Plot the data\n",
    "            axes[idx].scatter(df_tmp['LG (mV)'], df_tmp['HG (mV)'],\n",
    "                              color=colors[n_samples % len(colors)],\n",
    "                              marker=markers[n_samples % len(markers)],\n",
    "                              label=s)\n",
    "            axes[idx].set_title(f\"Frequency {f} GHz\")\n",
    "            axes[idx].set_xlabel('LG (mV)')\n",
    "            axes[idx].set_ylabel('HG (mV)')\n",
    "            axes[idx].legend(fontsize='xx-small')\n",
    "            n_samples += 1\n",
    "\n",
    "# Hide any unused subplots\n",
    "for ax in axes[len(frequencies):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "# # Save plots\n",
    "# output_path = 'C:/Users/Danim/Documents/GitHub/PIC-PAPER-01/data/experiment_2_plastics/plots/all_samples_distribution_per_freq'\n",
    "# if not os.path.exists(output_path):\n",
    "#     os.makedirs(output_path)\n",
    "# plt.savefig(f\"{output_path}/data_distribution_per_freq_{freq}.png\", dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set, test_set = train_test_split(df, test_size=0.2, random_state=42, stratify=df['Sample']) \n",
    "test_percentage = 0.25\n",
    "# train_set, test_set = train_test_split(df, test_size=test_percentage, random_state=42) \n",
    "# Shuffle the data\n",
    "df_balanced_ = df_balanced.sample(frac=1, random_state=42)\n",
    "train_set, test_set = train_test_split(df_balanced_, test_size=test_percentage, random_state=42) \n",
    "\n",
    "# stratify=df['Sample'] to keep the same proportion of samples in the train and test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 4))\n",
    "\n",
    "# Plot train set\n",
    "train_set[['Sample']].value_counts().plot.bar(ax=ax[0], legend=False)\n",
    "ax[0].set_xlabel('Data Distribution of target variable for train dataset')\n",
    "ax[0].set_ylabel('Count')\n",
    "\n",
    "# Plot test set\n",
    "test_set[['Sample']].value_counts().plot.bar(ax=ax[1], legend=False)\n",
    "ax[1].set_xlabel('Data Distribution of target variable for test dataset')\n",
    "ax[1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ex = train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ex.info()\n",
    "# train_ex.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax = train_ex['Frequency (GHz)'].plot.hist(figsize=(10, 4), bins=408)\n",
    "# ax = test_set['Frequency (GHz)'].plot.hist(ax=ax, bins=408)\n",
    "ax.set_xlabel('Frequency (GHz)')\n",
    "ax.set_ylabel('Nums of sample by frecuency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of data used for each window\n",
    "time_window_s = 0.1\n",
    "data_percentage = (100/(27*(1-test_percentage)))*time_window_s\n",
    "data_percentage_test = (100/(27*(test_percentage)))*time_window_s\n",
    "\n",
    "data_percentage = 0\n",
    "data_percentage_test = 0\n",
    "\n",
    "print(f\"Data percentage: {data_percentage}%\")\n",
    "print(f\"Data percentage test: {data_percentage_test}%\")\n",
    "\n",
    "# Load just a % of the data\n",
    "# df_sample = train_set.sample(frac=0.02, random_state=42)\n",
    "\n",
    "# Introduce Frequency values as input variables\n",
    "train_set_test = freq_as_variable(train_set, data_percentage)\n",
    "test_set_test = freq_as_variable(test_set, data_percentage_test)\n",
    "\n",
    "# If a row has any NaN value, remove that row\n",
    "train_set_test = train_set_test.dropna()\n",
    "test_set_test = test_set_test.dropna()\n",
    "\n",
    "#Save the processed data to a CSV file\n",
    "\n",
    "output_path = 'C:/Users/Danim/Documents/GitHub/PIC-PAPER-01/data/experiment_1_plastics/processed_27s/training_file/train_set.csv'\n",
    "output_path_test = 'C:/Users/Danim/Documents/GitHub/PIC-PAPER-01/data/experiment_1_plastics/processed_27s/training_file/test_set.csv'\n",
    "# output_path = 'C:/Users/Dani - TUF/Documents/GitHub/PIC-PAPER-01/data/experiment_1_plastics/processed_27s/training_file/train_set.csv'\n",
    "# output_path_test = 'C:/Users/Dani - TUF/Documents/GitHub/PIC-PAPER-01/data/experiment_1_plastics/processed_27s/training_file/test_set.csv'\n",
    "\n",
    "# train_set_test.to_csv(output_path, sep = ';', index=False)\n",
    "# test_set_test.to_csv(output_path_test, sep = ';', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train set shape: {train_set_test.shape}\")\n",
    "print(f\"Test set shape: {test_set_test.shape}\")\n",
    "print(train_set_test.head())\n",
    "print(test_set.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the two frequencies to be used as axes\n",
    "var1 = '370.0 HG (mV)'\n",
    "var2 = '420.0 HG (mV)'\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=train_set_test, x=var1, y=var2, hue='Sample', palette='tab10', s=25, alpha=0.7)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(f'{var1}')\n",
    "plt.ylabel(f'{var2}')\n",
    "plt.title(f'Scatter Plot of Samples for {var1} vs {var2}')\n",
    "\n",
    "# Customize legend\n",
    "plt.legend(title='Sample', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Add sample names to clusters\n",
    "for sample in train_set_test['Sample'].unique():\n",
    "    sample_data = train_set_test[train_set_test['Sample'] == sample]\n",
    "    cluster_center = sample_data[[var1, var2]].mean()\n",
    "    plt.text(cluster_center[var1], cluster_center[var2], sample, fontsize=9, weight='bold')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "input_size = X_train.shape[1]\n",
    "output_size = len(np.unique(y_train))\n",
    "seed = set_seed(42)\n",
    "\n",
    "input_size, output_size\n",
    "\n",
    "# print(f'input_size: {input_size}, output_size: {output_size}')\n",
    "# print(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
