{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peUcVKtbGPfD"
   },
   "source": [
    "# Classification\n",
    "\n",
    "### Import Libraries and seed\n",
    "Import the necessary libraries for data processing, model building, training, and evaluation. Adding a seed ensures reproducibility by making sure that the random number generation is consistent across different runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15527,
     "status": "ok",
     "timestamp": 1731066553135,
     "user": {
      "displayName": "DANIEL MORENO PARIS",
      "userId": "17921422726169854440"
     },
     "user_tz": -60
    },
    "id": "9a9HvzrNG8iw",
    "outputId": "19350658-7b5d-48e7-e90c-e7ddb3a578b1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from math import e\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.decomposition import PCA, FastICA, IncrementalPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from scipy.stats import zscore\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    return seed\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = set_seed(42)\n",
    "\n",
    "# Get the current directory of the notebook\n",
    "notebook_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1731066584724,
     "user": {
      "displayName": "DANIEL MORENO PARIS",
      "userId": "17921422726169854440"
     },
     "user_tz": -60
    },
    "id": "hAY8BfVX9XCK"
   },
   "outputs": [],
   "source": [
    "def load_data_from_directory(input_path, return_file_count=False):\n",
    "    data_frames = []\n",
    "    file_count = 0\n",
    "    for file in os.listdir(input_path):\n",
    "        if file.endswith('.csv'):\n",
    "            file_count += 1\n",
    "            df = pd.read_csv(os.path.join(input_path, file), delimiter=';', header=0)\n",
    "            data_frames.append(df)\n",
    "    data = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "    if return_file_count:\n",
    "        return data, file_count\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wiCTw-qcKXhn"
   },
   "source": [
    "### Preprocessing Data\n",
    "Function to preprocess the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1731066584724,
     "user": {
      "displayName": "DANIEL MORENO PARIS",
      "userId": "17921422726169854440"
     },
     "user_tz": -60
    },
    "id": "zJoZqi5LDPl8"
   },
   "outputs": [],
   "source": [
    "def calculate_averages_and_dispersion(df, data_percentage):\n",
    "\n",
    "    results = []\n",
    "    for (sample, freq), group in df.groupby(['Sample', 'Frequency (GHz)']):\n",
    "        window_size = max(1, int(len(group) * data_percentage / 100))\n",
    "        # print(f\"Processing sample: {sample}, frequency: {freq} with window size: {window_size}\")\n",
    "        for start in range(0, len(group), window_size):\n",
    "            window_data = group.iloc[start:start + window_size]\n",
    "            mean_values = window_data[['LG (mV)', 'HG (mV)']].mean()\n",
    "            std_deviation_values = window_data[['LG (mV)', 'HG (mV)']].std()\n",
    "            results.append({\n",
    "                'Frequency (GHz)': freq,\n",
    "                'LG (mV) mean': mean_values['LG (mV)'],\n",
    "                'HG (mV) mean': mean_values['HG (mV)'],\n",
    "                'LG (mV) std deviation': std_deviation_values['LG (mV)'],\n",
    "                'HG (mV) std deviation': std_deviation_values['HG (mV)'],\n",
    "                'Sample': sample,\n",
    "            })\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXiN30xA1kKX"
   },
   "source": [
    "### Pivoting Frequency values to columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 235,
     "status": "ok",
     "timestamp": 1731067118965,
     "user": {
      "displayName": "DANIEL MORENO PARIS",
      "userId": "17921422726169854440"
     },
     "user_tz": -60
    },
    "id": "Kijzt73J1nyo"
   },
   "outputs": [],
   "source": [
    "def freq_as_variable(df, data_percentage):\n",
    "    '''Modify df to have Frequency values (100,110,120 and so on) as input variables in the columns'''\n",
    "\n",
    "    if data_percentage > 0:\n",
    "        # 1s window_size 100/27s = 3.7% of the data is used for each window\n",
    "        df_window = calculate_averages_and_dispersion(df, data_percentage) \n",
    "\n",
    "        # Add a unique identifier column to avoid duplicate entries in the index\n",
    "        df_window['unique_id'] = df_window.groupby(['Sample', 'Frequency (GHz)']).cumcount()\n",
    "\n",
    "        # Pivot the DataFrame to wide format\n",
    "        df_pivot = df_window.pivot(index=['Sample', 'unique_id'], columns='Frequency (GHz)')\n",
    "\n",
    "        # Flatten the MultiIndex columns - Ordered by Frequency + (HG mean, HG std deviation, LG mean, LG std deviation)\n",
    "        df_pivot.columns = [' '.join([str(col[1]), str(col[0])]) for col in df_pivot.columns]\n",
    "\n",
    "        # Drop columns with all NaN values\n",
    "        df_pivot = df_pivot.dropna(axis=1, how='all')\n",
    "\n",
    "        # Reset index to make 'Sample' and 'unique_id' columns again\n",
    "        df_pivot = df_pivot.reset_index()\n",
    "\n",
    "        # Remove 'unique_id' column\n",
    "        df_pivot = df_pivot.drop(columns=['unique_id'])\n",
    "    else:\n",
    "        # If data_percentage is 0, do not calculate mean and std deviation, use the original data\n",
    "        df['unique_id'] = df.groupby(['Sample', 'Frequency (GHz)']).cumcount()\n",
    "        df_pivot = df.pivot(index=['Sample', 'unique_id'], columns='Frequency (GHz)')\n",
    "        df_pivot.columns = [' '.join([str(col[1]), str(col[0])]) for col in df_pivot.columns]\n",
    "        df_pivot = df_pivot.dropna(axis=1, how='all')\n",
    "        df_pivot = df_pivot.reset_index()\n",
    "        df_pivot = df_pivot.drop(columns=['unique_id'])\n",
    "\n",
    "    # Optional - Sort the columns if needed\n",
    "    df_pivot = df_pivot.reindex(sorted(df_pivot.columns), axis=1)\n",
    "\n",
    "    return df_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from directory in defined time windows and pivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_test_data(notebook_dir, input_dir='data/experiment_5_plastics/processed/', \n",
    "                           test_percentage=0.2, time_window_s=0.1, stabilised_time_s=0.1, split = False, verbose=True):\n",
    "    \"\"\" Load and prepare training and testing data for model development \"\"\"\n",
    "\n",
    "    # Load training data\n",
    "    input_path = os.path.normpath(os.path.join(notebook_dir, '..', '..', input_dir))\n",
    "    df, num_files = load_data_from_directory(input_path, return_file_count=True)\n",
    "    df = pd.concat([df[['Frequency (GHz)', 'LG (mV)', 'HG (mV)']], df[['Sample']]], axis=1)\n",
    "    \n",
    "    # Clean up sample labels - take first character only\n",
    "    df['Sample'] = df['Sample'].str[0]\n",
    "    \n",
    "    # Get unique labels\n",
    "    labels = df['Sample'].unique()\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Training data head:\")\n",
    "        print(df.head(10))\n",
    "        print(f\"Unique labels: {labels}\")\n",
    "        print(f\"Window size: {time_window_s} s\")\n",
    "\n",
    "    num_tests = num_files/df['Sample'].nunique()\n",
    "    stabilised_time_s = 12 * 1\n",
    "    # print('Tests per sample: ', num_tests)\n",
    "    # print('Stabilised time: ', stabilised_time_s)\n",
    "    \n",
    "    # Calculate the percentage of data used for each window\n",
    "    if test_percentage == 0:\n",
    "        data_percentage = (100/stabilised_time_s) * time_window_s\n",
    "        data_percentage_test = 0  # No test data\n",
    "    else:\n",
    "        data_percentage = (100/(stabilised_time_s*(1-test_percentage))) * time_window_s\n",
    "        data_percentage_test = (100/(stabilised_time_s*(test_percentage))) * time_window_s\n",
    "    \n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Data percentage for training: {data_percentage}%\")\n",
    "        print(f\"Data percentage for testing: {data_percentage_test}%\")\n",
    "\n",
    "    if split:\n",
    "    \n",
    "        # Split into train and test sets\n",
    "        if test_percentage == 0:\n",
    "            df_train = df.copy()\n",
    "            df_test = pd.DataFrame(columns=df.columns)  # Empty DataFrame with same structure\n",
    "        else:\n",
    "            df_train, df_test = train_test_split(df, test_size=test_percentage, random_state=seed) \n",
    "\n",
    "    else:\n",
    "        # Use all data as training data\n",
    "        df_train = df.copy()\n",
    "        df_train = freq_as_variable(df_train, data_percentage)\n",
    "        if verbose:\n",
    "            print(f\"Training set shape: {df_train.shape}\")\n",
    "        return df_train, labels\n",
    "\n",
    "        \n",
    "    # Introduce Frequency values as input variables\n",
    "    df_train = freq_as_variable(df_train, data_percentage)\n",
    "\n",
    "    # Only process test data if it exists\n",
    "    if not df_test.empty:\n",
    "        df_test = freq_as_variable(df_test, data_percentage_test)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Training set shape: {df_train.shape}\")\n",
    "        print(f\"Testing set shape: {df_test.shape}\")\n",
    "    \n",
    "    return df_train, df_test, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data\n",
    "### Split data into X and y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, labels, freqs, eliminate_std_dev=False, eliminate_LG=False, drop_sample=True):\n",
    "    # Reduce number of different samples for testing\n",
    "    X_ = df[df['Sample'].isin(labels)]\n",
    "\n",
    "    y_ = X_['Sample']\n",
    "\n",
    "    if drop_sample:\n",
    "        X_ = X_.drop(columns=['Sample'])\n",
    "        \n",
    "    if freqs:\n",
    "        # Subset of specific frequencies to use as input features (or without mean)\n",
    "        columns = [f'{freq}.0 HG (mV) mean' for freq in freqs] + \\\n",
    "                  [f'{freq}.0 LG (mV) mean' for freq in freqs] + \\\n",
    "                  [f'{freq}.0 HG (mV)' for freq in freqs] + \\\n",
    "                  [f'{freq}.0 LG (mV)' for freq in freqs] + \\\n",
    "                  [f'{freq}.0 HG (mV) std deviation' for freq in freqs] + \\\n",
    "                  [f'{freq}.0 LG (mV) std deviation' for freq in freqs] + \\\n",
    "                  ['Sample']\n",
    "\n",
    "\n",
    "        # Filter columns that exist in X_\n",
    "        existing_columns = [col for col in columns if col in X_.columns]\n",
    "\n",
    "        # Check if existing_columns is empty\n",
    "        if not existing_columns:\n",
    "            print(\"No matching columns found in X_.\")\n",
    "        else:\n",
    "            X_ = X_[existing_columns]\n",
    "\n",
    "        # Sort columns by frequency value\n",
    "        X_ = X_.reindex(sorted(X_.columns), axis=1)\n",
    "\n",
    "    if eliminate_std_dev:\n",
    "        # Eliminate std dev columns from the input features\n",
    "        X_ = X_.drop(columns=[col for col in X_.columns if 'std deviation' in col])\n",
    "\n",
    "    if eliminate_LG:\n",
    "        # Eliminate LG columns from the input features\n",
    "        X_ = X_.drop(columns=[col for col in X_.columns if 'LG' in col])\n",
    "\n",
    "    return X_, y_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afvxx1KzKzYp"
   },
   "source": [
    "### Define Models\n",
    "- Random Forest\n",
    "- Naive-Bayes\n",
    "- Logistic Regression\n",
    "- Gradient Boosting\n",
    "- Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_model(X_train, y_train, seed):\n",
    "    rf_model = RandomForestClassifier(random_state=seed)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    return rf_model\n",
    "\n",
    "def naive_bayes_model(X_train, y_train):\n",
    "    nb_model = GaussianNB()\n",
    "    nb_model.fit(X_train, y_train)\n",
    "    return nb_model\n",
    "\n",
    "def logistic_regression_model(X_train, y_train, seed):\n",
    "    lr_model = LogisticRegression(max_iter=1000,\n",
    "                                  random_state=seed)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    return lr_model\n",
    "\n",
    "def gradient_boosting_model(X_train, y_train, seed):\n",
    "    gb_model = GradientBoostingClassifier(random_state=seed)\n",
    "    gb_model.fit(X_train, y_train)\n",
    "    return gb_model\n",
    "\n",
    "def support_vector_machine_model(X_train, y_train, seed):\n",
    "    svm_model = SVC(random_state=seed)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    return svm_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train all Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_train, y_train, seed):\n",
    "    training_times = []\n",
    "    \n",
    "    # Random Forest\n",
    "    start_time = time.time()\n",
    "    rf_model = RandomForestClassifier(random_state=seed)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    training_times.append(time.time() - start_time)\n",
    "    \n",
    "    # Naive Bayes\n",
    "    start_time = time.time()\n",
    "    nb_model = GaussianNB()\n",
    "    nb_model.fit(X_train, y_train)\n",
    "    training_times.append(time.time() - start_time)\n",
    "    \n",
    "    # Logistic Regression\n",
    "    start_time = time.time()\n",
    "    lr_model = LogisticRegression(random_state=seed, max_iter=1000)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    training_times.append(time.time() - start_time)\n",
    "    \n",
    "    # Gradient Boosting\n",
    "    start_time = time.time()\n",
    "    gb_model = GradientBoostingClassifier(random_state=seed)\n",
    "    gb_model.fit(X_train, y_train)\n",
    "    training_times.append(time.time() - start_time)\n",
    "    \n",
    "    # SVM\n",
    "    start_time = time.time()\n",
    "    svm_model = SVC(random_state=seed)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    training_times.append(time.time() - start_time)\n",
    "    \n",
    "    return rf_model, nb_model, lr_model, gb_model, svm_model, training_times\n",
    "\n",
    "def save_models(rf_model, nb_model, lr_model, gb_model, svm_model):\n",
    "    joblib.dump(rf_model, 'random_forest_model.pkl')\n",
    "    joblib.dump(nb_model, 'naive_bayes_model.pkl')\n",
    "    joblib.dump(lr_model, 'logistic_regression_model.pkl')\n",
    "    joblib.dump(gb_model, 'gradient_boosting_model.pkl')\n",
    "    joblib.dump(svm_model, 'support_vector_machine_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply confidence threshold\n",
    "def apply_confidence_threshold(probabilities, threshold=0.7):\n",
    "    max_probs = np.max(probabilities, axis=1)\n",
    "    predictions = np.argmax(probabilities, axis=1)\n",
    "    # Replace predictions with -1 (unknown) where confidence is below threshold\n",
    "    predictions[max_probs < threshold] = -1\n",
    "    return predictions, max_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIC Criteria\n",
    "def aic_score(y_true, y_pred, n_features):\n",
    "    n = len(y_true)\n",
    "    residuals = y_true - y_pred\n",
    "    rss = np.sum(residuals**2)\n",
    "    epsilon = 1e-10  # Small value to avoid log(0)\n",
    "    aic = 2 * n_features + n * np.log((rss + epsilon) / n)\n",
    "    return aic\n",
    "\n",
    "# BIC Criteria (Also consider the number of samples)\n",
    "def bic_score(y_true, y_pred, n_features):\n",
    "    n = len(y_true)\n",
    "    residuals = y_true - y_pred\n",
    "    rss = np.sum(residuals**2)\n",
    "    epsilon = 1e-10  # Small value to avoid log(0)\n",
    "    bic = np.log(n) * n_features + n * np.log((rss + epsilon) / n)\n",
    "    return bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_results(models, data, time_window_s, accuracies, precisions, recalls, f1_scores, predictions,\n",
    "                        n_features, freqs, aic_scores, bic_scores, training_times=None, \n",
    "                        inference_times=None, csv_path='comparison_results.csv', verbose=0):\n",
    "    \n",
    "    # Determine test number\n",
    "    if os.path.exists(csv_path):\n",
    "        existing_results = pd.read_csv(csv_path, sep=';')\n",
    "        current_test = existing_results['Test'].max() + 1\n",
    "    else:\n",
    "        current_test = 1\n",
    "\n",
    "    # Initialize timing data if not provided\n",
    "    if training_times is None:\n",
    "        training_times = [0] * len(models)\n",
    "    if inference_times is None:\n",
    "        inference_times = [0] * len(models)\n",
    "\n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'Test': [current_test] * len(models),\n",
    "        'Data': [data] * len(models),\n",
    "        'Time Window (s)': time_window_s,\n",
    "        'Accuracy': accuracies,\n",
    "        'Precision': precisions,\n",
    "        'Recall': recalls,\n",
    "        'F1-Score': f1_scores,\n",
    "        'AIC': aic_scores,\n",
    "        'BIC': bic_scores,\n",
    "        'Predictions': predictions,\n",
    "        'Algorithm': models,\n",
    "        'Num_Features': [n_features] * len(models),\n",
    "        'Num Frequencies': [len(freqs)] * len(models),\n",
    "        'Frequencies': [', '.join([f\"{freq:.0f}\" for freq in freqs])] * len(models),\n",
    "        'Training_Time': training_times,\n",
    "        'Inference_Time_Per_Sample': inference_times\n",
    "    })\n",
    "\n",
    "    # Format float columns\n",
    "    float_columns = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AIC', 'BIC', \n",
    "                    'Training_Time', 'Inference_Time_Per_Sample']\n",
    "    results_df[float_columns] = results_df[float_columns].round(4)\n",
    "\n",
    "    # Append or create results file\n",
    "    if os.path.exists(csv_path):\n",
    "        updated_results = pd.concat([existing_results, results_df], ignore_index=True)\n",
    "    else:\n",
    "        updated_results = results_df\n",
    "\n",
    "    # Save updated results\n",
    "    updated_results.to_csv(csv_path, index=False, sep=';')\n",
    "\n",
    "    if verbose >= 1:\n",
    "        print(f\"\\nTest #{current_test} Results:\")\n",
    "        print(results_df)\n",
    "        if verbose >= 2:\n",
    "            print(\"\\nAll Results:\")\n",
    "            print(updated_results)\n",
    "        \n",
    "    return updated_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(y_test, y_pred, verbose=0):\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    aic_scores = []\n",
    "    bic_scores = []\n",
    "    predictions_list = []\n",
    "\n",
    "    # Label encode y_test\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_test)\n",
    "\n",
    "    for i, y_pred_i in enumerate(y_pred):\n",
    "        accuracy = accuracy_score(y_test, y_pred_i)\n",
    "        precision = precision_score(y_test, y_pred_i, average='weighted', zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred_i, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred_i, average='weighted', zero_division=0)\n",
    "\n",
    "        # Calculate AIC and BIC\n",
    "        y_test_num = le.transform(y_test)\n",
    "        y_pred_num = le.transform(y_pred_i)\n",
    "        n_features = len(y_pred_i)\n",
    "        aic = aic_score(y_test_num, y_pred_num, n_features)\n",
    "        bic = bic_score(y_test_num, y_pred_num, n_features)\n",
    "\n",
    "        # Predictions made per class with its label encoded value\n",
    "        predictions = dict(sorted(Counter(y_pred_i).items()))\n",
    "\n",
    "        print(f\"Model {i+1} - Accuracy: {accuracy}\")\n",
    "\n",
    "        if verbose >= 1:\n",
    "            print(f\"Model {i+1} - Precision: {precision}\")\n",
    "            print(f\"Model {i+1} - Recall: {recall}\")\n",
    "            print(f\"Model {i+1} - F1: {f1}\")\n",
    "            print(f\"Model {i+1} - AIC: {aic}\")\n",
    "            print(f\"Model {i+1} - BIC: {bic}\")\n",
    "            print(f\"Model {i+1} - Predictions: {predictions}\\n\")\n",
    "            if verbose >= 2:\n",
    "                # Classification report\n",
    "                print(f\"Model {i+1} - Classification Report:\\n\", classification_report(y_test, y_pred_i), '\\n')\n",
    "\n",
    "\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "        aic_scores.append(aic)\n",
    "        bic_scores.append(bic)\n",
    "        predictions_list.append(predictions)\n",
    "\n",
    "    return accuracies, precisions, recalls, f1_scores, aic_scores, bic_scores, predictions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importances(rf_model, lr_model, gb_model, nb_model, svm_model, X_train, y_train, seed, plot=True, n=10):\n",
    "    feature_names = X_train.columns\n",
    "\n",
    "    # Random Forest feature importances\n",
    "    rf_feature_importances = rf_model.feature_importances_\n",
    "    rf_feature_importances_df = pd.DataFrame({'Feature': feature_names, 'Importance': rf_feature_importances})\n",
    "    rf_feature_importances_df = rf_feature_importances_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "    # Logistic Regression feature importances\n",
    "    lr_feature_importances = lr_model.coef_[0]\n",
    "    lr_feature_importances_df = pd.DataFrame({'Feature': feature_names, 'Importance': lr_feature_importances})\n",
    "    lr_feature_importances_df = lr_feature_importances_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "    # Gradient Boosting feature importances\n",
    "    gb_feature_importances = gb_model.feature_importances_\n",
    "    gb_feature_importances_df = pd.DataFrame({'Feature': feature_names, 'Importance': gb_feature_importances})\n",
    "    gb_feature_importances_df = gb_feature_importances_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "    # Naive Bayes permutation importance\n",
    "    result_nb = permutation_importance(nb_model, X_train, y_train, n_repeats=5, random_state=seed, n_jobs=1)\n",
    "    sorted_idx_nb = result_nb.importances_mean.argsort()[::-1]\n",
    "    nb_feature_importances_df = pd.DataFrame({'Feature': feature_names[sorted_idx_nb], 'Importance': result_nb.importances_mean[sorted_idx_nb]})\n",
    "\n",
    "    # SVM permutation importance\n",
    "    result_svm = permutation_importance(svm_model, X_train, y_train, n_repeats=5, random_state=seed, n_jobs=1)\n",
    "    sorted_idx_svm = result_svm.importances_mean.argsort()[::-1]\n",
    "    svm_feature_importances_df = pd.DataFrame({'Feature': feature_names[sorted_idx_svm], 'Importance': result_svm.importances_mean[sorted_idx_svm]})\n",
    "\n",
    "    if plot:\n",
    "        # Set standard font family\n",
    "        plt.rcParams['font.family'] = 'Arial'  # or 'Arial', 'Times New Roman', etc.\n",
    "        \n",
    "        # Create directory for saving feature importance plots\n",
    "        feature_imp_path = os.path.normpath(os.path.join(notebook_dir, '..', '..', 'data/results/feature_importance_detailed/'))\n",
    "        if not os.path.exists(feature_imp_path):\n",
    "            os.makedirs(feature_imp_path)\n",
    "\n",
    "        # Define enhanced color schemes for each model\n",
    "        colors = {\n",
    "            'RF': plt.cm.viridis(np.linspace(0.2, 0.8, n)),\n",
    "            'LR': plt.cm.plasma(np.linspace(0.2, 0.8, n)),\n",
    "            'GB': plt.cm.inferno(np.linspace(0.2, 0.8, n)),\n",
    "            'NB': plt.cm.cividis(np.linspace(0.2, 0.8, n)),\n",
    "            'SVM': plt.cm.magma(np.linspace(0.2, 0.8, n))\n",
    "        }\n",
    "\n",
    "        # Random Forest Plot\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "        bars = ax.barh(rf_feature_importances_df['Feature'][:n], \n",
    "                      rf_feature_importances_df['Importance'][:n],\n",
    "                      color=colors['RF'], \n",
    "                      edgecolor='white', \n",
    "                      linewidth=0.8,\n",
    "                      alpha=0.85)\n",
    "        \n",
    "        # Add gradient effect to bars\n",
    "        for i, bar in enumerate(bars):\n",
    "            bar.set_facecolor(colors['RF'][i])\n",
    "        \n",
    "        ax.set_xlabel('Importance', fontsize=20, color='#2E2E2E', family='DejaVu Sans')\n",
    "        ax.set_title('Random Forest Feature Importances', fontsize=22, \n",
    "                    color='#2E2E2E', pad=20, family='DejaVu Sans')\n",
    "        ax.tick_params(axis='x', labelsize=18, colors='#2E2E2E')\n",
    "        ax.tick_params(axis='y', labelsize=18, colors='#2E2E2E')\n",
    "        \n",
    "        # Enhanced grid styling\n",
    "        ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.8, color='gray')\n",
    "        ax.set_axisbelow(True)\n",
    "        \n",
    "        # Subtle background gradient\n",
    "        ax.patch.set_facecolor('#FAFAFA')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(feature_imp_path, 'RF_detailed_feature_importance.pdf'), \n",
    "                   format='pdf', bbox_inches='tight', dpi=300, facecolor='white')\n",
    "        plt.show()\n",
    "\n",
    "        # Logistic Regression Plot\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "        bars = ax.barh(lr_feature_importances_df['Feature'][:n], \n",
    "                      lr_feature_importances_df['Importance'][:n],\n",
    "                      color=colors['LR'], \n",
    "                      edgecolor='white', \n",
    "                      linewidth=0.8,\n",
    "                      alpha=0.85)\n",
    "        \n",
    "        for i, bar in enumerate(bars):\n",
    "            bar.set_facecolor(colors['LR'][i])\n",
    "        \n",
    "        ax.set_xlabel('Importance', fontsize=18, color='#2E2E2E', family='DejaVu Sans')\n",
    "        ax.set_title('Logistic Regression Feature Importances', fontsize=22, \n",
    "                    color='#2E2E2E', pad=20, family='DejaVu Sans')\n",
    "        ax.tick_params(axis='x', labelsize=16, colors='#2E2E2E')\n",
    "        ax.tick_params(axis='y', labelsize=16, colors='#2E2E2E')\n",
    "        ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.8, color='gray')\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.patch.set_facecolor('#FAFAFA')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(feature_imp_path, 'LR_detailed_feature_importance.pdf'), \n",
    "                   format='pdf', bbox_inches='tight', dpi=300, facecolor='white')\n",
    "        plt.show()\n",
    "\n",
    "        # Gradient Boosting Plot\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "        bars = ax.barh(gb_feature_importances_df['Feature'][:n], \n",
    "                      gb_feature_importances_df['Importance'][:n],\n",
    "                      color=colors['GB'], \n",
    "                      edgecolor='white', \n",
    "                      linewidth=0.8,\n",
    "                      alpha=0.85)\n",
    "        \n",
    "        for i, bar in enumerate(bars):\n",
    "            bar.set_facecolor(colors['GB'][i])\n",
    "        \n",
    "        ax.set_xlabel('Importance', fontsize=18, color='#2E2E2E', family='DejaVu Sans')\n",
    "        ax.set_title('Gradient Boosting Feature Importances', fontsize=22, \n",
    "                    color='#2E2E2E', pad=20, family='DejaVu Sans')\n",
    "        ax.tick_params(axis='x', labelsize=16, colors='#2E2E2E')\n",
    "        ax.tick_params(axis='y', labelsize=16, colors='#2E2E2E')\n",
    "        ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.8, color='gray')\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.patch.set_facecolor('#FAFAFA')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(feature_imp_path, 'GB_detailed_feature_importance.pdf'), \n",
    "                   format='pdf', bbox_inches='tight', dpi=300, facecolor='white')\n",
    "        plt.show()\n",
    "\n",
    "        # Naive Bayes Plot (Enhanced Boxplot)\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        bp = ax.boxplot(result_nb.importances[sorted_idx_nb][:n].T, \n",
    "                       vert=False, \n",
    "                       labels=X_train.columns[sorted_idx_nb][:n],\n",
    "                       patch_artist=True,\n",
    "                       boxprops=dict(facecolor='#8E44AD', alpha=0.8, linewidth=1.5),\n",
    "                       whiskerprops=dict(color='#2E2E2E', linewidth=2),\n",
    "                       capprops=dict(color='#2E2E2E', linewidth=2),\n",
    "                       medianprops=dict(color='white', linewidth=3),\n",
    "                       flierprops=dict(marker='o', markerfacecolor='#E74C3C', markersize=8, alpha=0.8, markeredgecolor='white'))\n",
    "        \n",
    "        ax.set_xlabel('Permutation Importance', fontsize=18, color='#2E2E2E', family='DejaVu Sans')\n",
    "        ax.set_title('Naive Bayes Permutation Feature Importance', fontsize=22, \n",
    "                    color='#2E2E2E', pad=20, family='DejaVu Sans')\n",
    "        ax.tick_params(axis='x', labelsize=16, colors='#2E2E2E')\n",
    "        ax.tick_params(axis='y', labelsize=16, colors='#2E2E2E')\n",
    "        ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.8, color='gray')\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.patch.set_facecolor('#FAFAFA')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(feature_imp_path, 'NB_detailed_feature_importance.pdf'), \n",
    "                   format='pdf', bbox_inches='tight', dpi=300, facecolor='white')\n",
    "        plt.show()\n",
    "\n",
    "        # SVM Plot (Enhanced Boxplot)\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        bp = ax.boxplot(result_svm.importances[sorted_idx_svm][:n].T, \n",
    "                       vert=False, \n",
    "                       labels=X_train.columns[sorted_idx_svm][:n],\n",
    "                       patch_artist=True,\n",
    "                       boxprops=dict(facecolor='#E67E22', alpha=0.8, linewidth=1.5),\n",
    "                       whiskerprops=dict(color='#2E2E2E', linewidth=2),\n",
    "                       capprops=dict(color='#2E2E2E', linewidth=2),\n",
    "                       medianprops=dict(color='white', linewidth=3),\n",
    "                       flierprops=dict(marker='o', markerfacecolor='#E74C3C', markersize=8, alpha=0.8, markeredgecolor='white'))\n",
    "        \n",
    "        ax.set_xlabel('Permutation Importance', fontsize=18, color='#2E2E2E', family='DejaVu Sans')\n",
    "        ax.set_title('SVM Permutation Feature Importance', fontsize=22, \n",
    "                    color='#2E2E2E', pad=20, family='DejaVu Sans')\n",
    "        ax.tick_params(axis='x', labelsize=16, colors='#2E2E2E')\n",
    "        ax.tick_params(axis='y', labelsize=16, colors='#2E2E2E')\n",
    "        ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.8, color='gray')\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.patch.set_facecolor('#FAFAFA')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(feature_imp_path, 'SVM_detailed_feature_importance.pdf'), \n",
    "                   format='pdf', bbox_inches='tight', dpi=300, facecolor='white')\n",
    "        plt.show()\n",
    "\n",
    "    return rf_feature_importances_df, lr_feature_importances_df, gb_feature_importances_df, nb_feature_importances_df, svm_feature_importances_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_pdf(y_true, y_pred, labels, save_path=None, model_name=None):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    cmap=plt.cm.Blues\n",
    "    cax = ax.matshow(conf_matrix, cmap=cmap)\n",
    "    fig.colorbar(cax)\n",
    "    \n",
    "    # Determine text color based on cell value for better visibility\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            # Calculate percentage\n",
    "            percentage = conf_matrix[i, j] / np.sum(conf_matrix, axis=1)[i] * 100 if np.sum(conf_matrix, axis=1)[i] > 0 else 0\n",
    "            \n",
    "            # Determine text color based on cell darkness\n",
    "            cell_value = conf_matrix[i, j]\n",
    "            if cell_value > conf_matrix.max() / 3:\n",
    "                text_color = 'white'\n",
    "\n",
    "                plt.text(j, i, f'{conf_matrix[i, j]}\\n{percentage:.1f}%',\n",
    "                     horizontalalignment=\"center\",\n",
    "                     verticalalignment=\"center\",\n",
    "                     fontsize=8, \n",
    "                     ha='center', va='center', \n",
    "                     color=text_color)\n",
    "            else:\n",
    "                text_color = cmap(1.0)\n",
    "\n",
    "                if conf_matrix[i, j] != 0:\n",
    "\n",
    "                    plt.text(j, i, f'{conf_matrix[i, j]}\\n{percentage:.1f}%',\n",
    "                        horizontalalignment=\"center\",\n",
    "                        verticalalignment=\"center\",\n",
    "                        fontsize=8, \n",
    "                        ha='center', va='center', \n",
    "                        color=text_color)\n",
    "            \n",
    "\n",
    "    \n",
    "    plt.xlabel('Predicted', fontweight='bold', fontsize=12)\n",
    "    plt.ylabel('True', fontweight='bold', fontsize=12)\n",
    "    plt.xticks(np.arange(len(labels)), labels, rotation=45, fontweight='bold')\n",
    "    plt.yticks(np.arange(len(labels)), labels, fontweight='bold')\n",
    "    plt.title('Confusion Matrix', fontweight='bold', fontsize=14)\n",
    "        \n",
    "    # Adjust layout to make room for rotated x labels\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot if a path is provided\n",
    "    if save_path:\n",
    "        # Create directory if it doesn't exist\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        \n",
    "        # Create filename\n",
    "        model_suffix = f\"_{model_name}\" if model_name else \"\"\n",
    "        filename = f\"confusion_matrix{model_suffix}.pdf\"\n",
    "        filepath = os.path.join(save_path, filename)\n",
    "        \n",
    "        # Save as PDF\n",
    "        plt.savefig(filepath, format='pdf', bbox_inches='tight', dpi=300)\n",
    "        print(f\"Confusion matrix saved to: {filepath}\")\n",
    "    else:\n",
    "        print(\"Confusion matrix plot not saved.\")\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(X, y, subset_freqs, HG_diff=True, LG_diff=True):\n",
    "\n",
    "    X['Sample'] = y\n",
    "\n",
    "    # Initialize a dictionary to store results\n",
    "    mean_std_dict = {}\n",
    "\n",
    "    for freq in subset_freqs:\n",
    "        # Calculate HG and LG mean values for each frequency\n",
    "        agg_dict = {}\n",
    "        if f'{freq}.0 LG (mV) mean' in X.columns:\n",
    "            agg_dict['LG_mean'] = (f'{freq}.0 LG (mV) mean', 'mean')\n",
    "        if f'{freq}.0 HG (mV) mean' in X.columns:\n",
    "            agg_dict['HG_mean'] = (f'{freq}.0 HG (mV) mean', 'mean')\n",
    "        \n",
    "        mean_std_dict[freq] = X.groupby('Sample').agg(**agg_dict).reset_index()\n",
    "\n",
    "        mean_std_dict[freq]['Frequency'] = freq\n",
    "\n",
    "    # Concatenate all DataFrames in the dictionary\n",
    "    mean_std_df = pd.concat(mean_std_dict.values(), ignore_index=True)\n",
    "\n",
    "    # For each frequency after first one\n",
    "    for i, freq in enumerate(subset_freqs[1:]):\n",
    "        prev_freq = subset_freqs[i]  # Get previous frequency\n",
    "        \n",
    "        # For each row\n",
    "        for idx, row in X.iterrows():\n",
    "            sample = row['Sample']\n",
    "            \n",
    "            if HG_diff:\n",
    "                # Get previous frequency's HG mean for this sample\n",
    "                prev_hg = mean_std_df[\n",
    "                    (mean_std_df['Frequency'] == prev_freq) & \n",
    "                    (mean_std_df['Sample'] == sample)\n",
    "                ]['HG_mean'].values[0]\n",
    "\n",
    "\n",
    "                # 1) Inputs: xt - (xt-1) --First-order differences\n",
    "                # 2) Inputs: (xt/(xt-1)) - 1 --Escalado relativo\n",
    "\n",
    "                # Calculate and store difference\n",
    "                X.loc[idx, f'{freq}.0 HG diff'] = X.loc[idx, f'{freq}.0 HG (mV) mean'] - prev_hg\n",
    "                # X.loc[idx, f'{freq}.0 HG relative diff'] = (X.loc[idx, f'{freq}.0 HG (mV) mean'] / prev_hg) -1\n",
    "\n",
    "\n",
    "            if LG_diff:\n",
    "                prev_lg = mean_std_df[\n",
    "                    (mean_std_df['Frequency'] == prev_freq) & \n",
    "                    (mean_std_df['Sample'] == sample)\n",
    "                ]['LG_mean'].values[0]\n",
    "\n",
    "                # Calculate and store difference\n",
    "                # X.loc[idx, f'{freq}.0 LG diff'] = X.loc[idx, f'{freq}.0 LG (mV) mean'] - prev_lg\n",
    "                X.loc[idx, f'{freq}.0 LG relative diff'] = (X.loc[idx, f'{freq}.0 LG (mV) mean'] / prev_lg) -1\n",
    "\n",
    "\n",
    "    # Drop the 'Sample' column\n",
    "    X = X.drop(columns=['Sample'])\n",
    "\n",
    "    return X\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load New Test Data\n",
    "Prepare new sample for testing (Testing other samples, out of initial dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 500, 510, 520, 530, 540, 550, 560, 570, 580, 590], [310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 540], [310, 320, 330, 340, 350, 360, 370, 400, 410, 420], [330, 340, 350, 360, 410], [340, 350, 360], [350]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Subset of specific frequencies to use as input features, If freqs = [] then all frequencies are used\n",
    "\n",
    "freqs = []\n",
    "\n",
    "# Add a group with all frequencies from 100 to 590\n",
    "# freqs.append(list(range(260, 591, 10)))\n",
    "freqs.append(list(range(100, 591, 10)))\n",
    "\n",
    "\n",
    "# Favourite frequencies\n",
    "# freqs.append([250,300,320,330,340,350,360,370,380,390,400,410,420,430,440,450,460,470,480,490,500,510,520,530,540]) # TOP 25\n",
    "# freqs.append([250,310,320,330,340,350,360,370,380,390,400,410,420,430,440,450,460,470,480,490,500,510,520,540]) # TOP 24\n",
    "\n",
    "freqs.append([310,320,330,340,350,360,370,380,390,400,410,420,430,440,450,460,470,480,490,540]) # TOP 20 88% SG(3,2)\n",
    "# freqs.append([310,320,330,340,350,360,370,400,410,420,430,440,450,460,470,480,490,500,510,540]) # TOP 20 88% SG(3,2)\n",
    "# freqs.append([300,310,320,330,340,350,360,370,380,390,400,410,420,430,440,450,460,470,480,490]) # TOP 20 88% SG(3,2)\n",
    "\n",
    "# freqs.append([310,320,330,340,350,360,370,380,390,400,410,420]) # TOP 12 (86%)\n",
    "freqs.append([310,320,330,340,350,360,370,400,410,420]) # TOP 10 (88%)\n",
    "freqs.append([330,340,350,360,410]) # TOP 5 86% SG\n",
    "\n",
    "freqs.append([340,350,360]) # TOP 3\n",
    "freqs.append([350]) # TOP 1\n",
    "\n",
    "\n",
    "# # Count number of frequencies\n",
    "# print(f'freqs number: {len(freqs)}')\n",
    "\n",
    "# Array with subsets of frequencies to use for training\n",
    "# freqs.extend([\n",
    "#     [250, 300, 320],\n",
    "#     [300, 310, 320],\n",
    "#     [330, 340, 350],\n",
    "#     [360, 370, 380],\n",
    "#     [390, 400, 410],\n",
    "#     [420, 430, 440]\n",
    "# ])\n",
    "\n",
    "# Add all frequencies one by one\n",
    "# for i in range(250, 501, 10):\n",
    "#     freqs.append([i])\n",
    "\n",
    "# # Add groups of 2 frequencies\n",
    "# for i in range(300, 411, 20):\n",
    "#     if i + 10 <= 350:\n",
    "#         freqs.append([i, i+10])\n",
    "\n",
    "# # Add groups of 3 frequencies\n",
    "# for i in range(250, 441, 30):\n",
    "#     if i + 20 <= 590 and i + 10 <= 590:\n",
    "#         freqs.append([i, i+10, i+20])\n",
    "\n",
    "\n",
    "\n",
    "# freqs.append([250,320,330,410])\n",
    "\n",
    "# freqs = freqs_fav ## TESTING\n",
    "\n",
    "print(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_sampling(predictions):\n",
    "    \"\"\"\n",
    "    Takes a list of predictions and returns the most common value\n",
    "    Args: predictions: List of prediction values\n",
    "    Returns: Most frequent prediction value\n",
    "    \"\"\"\n",
    "    if not predictions:\n",
    "        return None\n",
    "        \n",
    "    # Count frequency of each prediction\n",
    "    freq_dict = {}\n",
    "    for pred in predictions:\n",
    "        freq_dict[pred] = freq_dict.get(pred, 0) + 1\n",
    "    \n",
    "    # Find value with highest frequency\n",
    "    max_freq = 0\n",
    "    mode = None\n",
    "    for value, freq in freq_dict.items():\n",
    "        if freq > max_freq:\n",
    "            max_freq = freq\n",
    "            mode = value\n",
    "            \n",
    "    return mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_probabilities(model, X):\n",
    "    \"\"\"\n",
    "    Perform inference on the dataset using the trained model and return predictions with probabilities.\n",
    "\n",
    "    Parameters:\n",
    "    model: Trained model object with predict and predict_proba methods.\n",
    "    X: Dataset to perform inference on.\n",
    "\n",
    "    Returns:\n",
    "    predictions: Array of predicted class labels.\n",
    "    probabilities: Array of predicted probabilities for each class.\n",
    "    \"\"\"\n",
    "    # Predict class labels\n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    # Predict probabilities\n",
    "    probabilities = model.predict_proba(X)\n",
    "    \n",
    "    return predictions, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_with_sampling(models, X, y_true):\n",
    "    \"\"\"\n",
    "    Evaluate multiple models using inference sampling\n",
    "    \n",
    "    Args:\n",
    "        models: List of trained model objects\n",
    "        X: Features dataset\n",
    "        y_true: True labels\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with evaluation metrics\n",
    "    \"\"\"\n",
    "        \n",
    "    # Get predictions from each model\n",
    "    all_predictions = []\n",
    "    for model in models:\n",
    "        preds, _ = predict_with_probabilities(model, X)\n",
    "        all_predictions.append(preds)\n",
    "    \n",
    "    # Get final predictions using sampling\n",
    "    final_predictions = []\n",
    "    for i in range(len(X)):\n",
    "        sample_preds = [pred[i] for pred in all_predictions]\n",
    "        final_pred = inference_sampling(sample_preds)\n",
    "        final_predictions.append(final_pred)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, final_predictions),\n",
    "        'precision': precision_score(y_true, final_predictions, average='weighted'),\n",
    "        'recall': recall_score(y_true, final_predictions, average='weighted'),\n",
    "        'f1': f1_score(y_true, final_predictions, average='weighted')\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the data prepared from the directory\n",
    "# input_path_train_data = 'data/experiment_5_plastics/processed/'\n",
    "# input_path_new_sample = 'data/experiment_5_plastics/processed/new_sample/'\n",
    "\n",
    "# window_interval = 0.1\n",
    "# test_percentage = 0.2\n",
    "\n",
    "# df_train, df_test, dummy_labels = prepare_train_test_data(notebook_dir, input_path_train_data, test_percentage=0.2, time_window_s= window_interval, stabilised_time_s=12, split = True, verbose=True)\n",
    "# print(f\"df_train: {df_train['Sample'].unique()}\")\n",
    "\n",
    "# df_new_sample, dummy_labels = prepare_train_test_data(notebook_dir, input_path_new_sample, test_percentage=0.2, time_window_s= window_interval, stabilised_time_s=12, split = False, verbose=True)\n",
    "# print(f\"df_new_sample: {df_new_sample['Sample'].unique()}\")\n",
    "\n",
    "# df_train = df_train.dropna()\n",
    "# df_test = df_test.dropna()\n",
    "# df_new_sample_2 = df_new_sample.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Window interval: 0.1\n",
      "Training data head:\n",
      "   Frequency (GHz)   LG (mV)    HG (mV) Sample\n",
      "0            100.0  0.366256  24.172872      A\n",
      "1            100.0 -0.244170  37.846416      A\n",
      "2            100.0 -1.831278  42.241484      A\n",
      "3            100.0  1.220852  36.015138      A\n",
      "4            100.0  0.610426  41.997313      A\n",
      "5            100.0 -0.244170  24.172872      A\n",
      "6            100.0  1.953363  26.370406      A\n",
      "7            100.0  0.732511  19.045293      A\n",
      "8            100.0  0.000000  32.840922      A\n",
      "9            100.0 -0.122085  22.707850      A\n",
      "Unique labels: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'L' 'O']\n",
      "Window size: 0.1 s\n",
      "Data percentage for training: 1.0416666666666665%\n",
      "Data percentage for testing: 4.166666666666666%\n",
      "Training set shape: (1193, 201)\n",
      "Testing set shape: (301, 201)\n",
      "Training data head:\n",
      "   Frequency (GHz)   LG (mV)    HG (mV) Sample\n",
      "0            100.0  0.000000  36.625564      A\n",
      "1            100.0 -0.488341  17.214015      A\n",
      "2            100.0  0.000000  35.160542      A\n",
      "3            100.0  1.587108  32.840922      A\n",
      "4            100.0  2.075449  46.636552      A\n",
      "5            100.0  0.732511  32.840922      A\n",
      "6            100.0  0.000000  37.968501      A\n",
      "7            100.0  0.610426  37.235990      A\n",
      "8            100.0  0.244170  40.288121      A\n",
      "9            100.0  1.098767  35.770968      A\n",
      "Unique labels: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'L' 'O']\n",
      "Window size: 0.1 s\n",
      "Data percentage for training: 1.0416666666666665%\n",
      "Data percentage for testing: 4.166666666666666%\n",
      "Training set shape: (1292, 201)\n",
      "Frequency: [100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 500, 510, 520, 530, 540, 550, 560, 570, 580, 590]\n",
      "Error occurred while extracting feature importances: 'numpy.ndarray' object has no attribute 'columns'\n",
      "Model 1 - Accuracy: 1.0\n",
      "Model 2 - Accuracy: 1.0\n",
      "Model 3 - Accuracy: 1.0\n",
      "Model 4 - Accuracy: 1.0\n",
      "Model 5 - Accuracy: 1.0\n",
      "df_new_sample[Sample]: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'L' 'O']\n",
      "y_new_sample: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'L' 'O']\n",
      "Model 1 - Accuracy: 0.46286701208981\n",
      "Model 2 - Accuracy: 0.5785837651122625\n",
      "Model 3 - Accuracy: 0.3082901554404145\n",
      "Model 4 - Accuracy: 0.3229706390328152\n",
      "Model 5 - Accuracy: 0.3540587219343696\n",
      "Frequency: [310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 540]\n",
      "Error occurred while extracting feature importances: 'numpy.ndarray' object has no attribute 'columns'\n",
      "Model 1 - Accuracy: 1.0\n",
      "Model 2 - Accuracy: 1.0\n",
      "Model 3 - Accuracy: 1.0\n",
      "Model 4 - Accuracy: 1.0\n",
      "Model 5 - Accuracy: 1.0\n",
      "df_new_sample[Sample]: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'L' 'O']\n",
      "y_new_sample: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'L' 'O']\n",
      "Model 1 - Accuracy: 0.5276338514680483\n",
      "Model 2 - Accuracy: 0.7651122625215889\n",
      "Model 3 - Accuracy: 0.5025906735751295\n",
      "Model 4 - Accuracy: 0.19602763385146804\n",
      "Model 5 - Accuracy: 0.6925734024179621\n",
      "Frequency: [310, 320, 330, 340, 350, 360, 370, 400, 410, 420]\n",
      "Error occurred while extracting feature importances: 'numpy.ndarray' object has no attribute 'columns'\n",
      "Model 1 - Accuracy: 1.0\n",
      "Model 2 - Accuracy: 1.0\n",
      "Model 3 - Accuracy: 1.0\n",
      "Model 4 - Accuracy: 1.0\n",
      "Model 5 - Accuracy: 1.0\n",
      "df_new_sample[Sample]: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'L' 'O']\n",
      "y_new_sample: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'L' 'O']\n",
      "Model 1 - Accuracy: 0.4326424870466321\n",
      "Model 2 - Accuracy: 0.6848013816925734\n",
      "Model 3 - Accuracy: 0.6278065630397237\n",
      "Model 4 - Accuracy: 0.33592400690846286\n",
      "Model 5 - Accuracy: 0.7219343696027634\n",
      "Frequency: [330, 340, 350, 360, 410]\n",
      "Error occurred while extracting feature importances: 'numpy.ndarray' object has no attribute 'columns'\n",
      "Model 1 - Accuracy: 1.0\n",
      "Model 2 - Accuracy: 1.0\n",
      "Model 3 - Accuracy: 1.0\n",
      "Model 4 - Accuracy: 1.0\n",
      "Model 5 - Accuracy: 1.0\n",
      "df_new_sample[Sample]: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'L' 'O']\n",
      "y_new_sample: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'L' 'O']\n",
      "Model 1 - Accuracy: 0.31519861830742657\n",
      "Model 2 - Accuracy: 0.8151986183074266\n",
      "Model 3 - Accuracy: 0.5716753022452504\n",
      "Model 4 - Accuracy: 0.1770293609671848\n",
      "Model 5 - Accuracy: 0.7487046632124352\n",
      "Confusion matrix saved to: c:\\Users\\Danim\\Documents\\GitHub\\PIC-PAPER-01\\results\\conf_matrix\\confusion_matrix_NB_[330, 340, 350, 360, 410].pdf\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuoAAAMWCAYAAACnQKNwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAmDlJREFUeJzs3XdclfX/xvHrsEEBARUcOHPn1p8jU0vNWZqWmVpq7pVmqeFeacvMgZpajkozc1VmfctC09RyprkX4gATkSMIyDi/P4gTuMLBOTfwevq4H3Hu+z7nXPcd482H9/25TRaLxSIAAAAAhuJg7wAAAAAAbkWhDgAAABgQhToAAABgQBTqAAAAgAFRqAMAAAAGRKEOAAAAGBCFOgAAAGBAFOoAAACAATnZOwAAAAByj/j4eN24ccPeMW7h4uIiNzc3e8fIgEIdAAAANhEfHy93Tz8p6bq9o9wiICBAp0+fNlSxTqEOAAAAm7hx44aUdF2uFbtJji72jvOv5BsKP7RUN27coFAHAABALuboIpOBCnWLvQPcAYU6AAAAbMvkkLoYhZGypGPMVAAAAEAuR6EOAAAAGBCtLwAAALAtkySTyd4p/mWgKOkxog4AAAAYEIU6AAAAYEC0vgAAAMC2mPUlU4yZCgAAAMjlKNQBAAAAA6L1BQAAALZlMhls1hcDZUmHEXUAAADAgCjUAQAAAAOi9QUAAAC2xawvmWLMVAAAAEAuR6EOAAAAGBCtLwAAALAtZn3JFEbUAQAAAAOiUAcAAAAMiNYXAAAA2JjBZn0x6Ni1MVMBAAAAuRyFOgAAAGBAtL4AAADAtpj1JVMYUQcAAAAMiEIdAAAAMCBaXwAAAGBbJoPN+mKkLOkYMxUAAACQy1GoAwAAAAZE6wsAAABsi1lfMoURdQAAAMCAKNQBAAAAA6L1BQAAALbFrC+ZYsxUAAAAQC5HoQ4AAAAYEK0vAAAAsC1mfckURtQBAAAAA6JQBwAAAAyIQh2AYV27dk1DhgxRiRIl5OLiIpPJJJPJpA8//NBmGRo3bmx93+7du9vsfXOrCRMmWM93iRIl7B0HQFZJm/XFSIsBGTMVAJuIiIjQ5MmT1ahRI/n7+8vFxUV58uRRpUqV1LNnT23cuFEWi8Vu+fr27atZs2YpNDRUiYmJdsthdCVKlLAWtyaTSS4uLgoPD79lv6SkJAUGBmbY1/QQ+jLPnDmT4fVCQkIe+DUBAFxMCuRac+fO1euvv674+PgM6xMTE3Xo0CEdOnRIn3zyiU6fPm2Xkc3ExER99dVX1scNGjRQmzZt5OjoqIYNG9osR//+/dWmTRtJ0qOPPmqz930QiYmJmj9/viZMmJBh/Zo1a3Tu3Dn7hMqkp556Snnz5pUkeXt72zkNANgXhTqQC7377rsaOXKk9bGjo6Nat26tmjVrymQy6cSJE/rhhx8UERFht4wXL17MMIo+YcIENWnSxOY5XnjhBZu/58Pw0UcfadSoUXJxcbGumzVrlh0T3Z3ZbJaXl5fq16+v+vXr2zsOgKxmMhmr3YRZXwAYwaFDhzRq1Cjr44IFC+qPP/7Q+vXrNW7cOI0dO1ZLly5VWFiYFixYIA8PjwzPP3/+vIYPH67KlSsrb968cnNzU4kSJdS1a1f9/vvvt7zfzT3H0dHRGj58uIoXLy4XFxeVKlVKU6dOzdBiU6JECRUvXjzD6zRt2tT6OmfOnFFISEiGdoszZ85k2D99O8jNI8tff/21WrRoIX9/fzk7O8vLy0ulS5dWu3btNG3aNKWkpFj3/a8e9WPHjql///4qV66cPDw85OHhobJly6pv3746cuTILft3797d+nqNGzfWxYsX1adPHxUqVEiurq6qUKGCFi5ceMvzMsvBIfXbenh4uL788kvr+j179mjbtm2SUn8xu5N9+/ZpwIABqlOnjooUKSJ3d3e5ubmpePHieuGFF7R169YM+5coUUIlS5bMsO6JJ57IcIzS7dtjPv74Y9WoUUPu7u7Wv5LcqUe9U6dOGdZfu3bNum358uXWbY6OjtqyZcu9nzgAMCBG1IFcZvbs2UpOTrY+njdvnqpXr37Lfs7Ozurdu3eGdVu2bFG7du0UFRWVYX1oaKhCQ0O1YsUKvffeexo2bNht3zsmJkb16tXT4cOHretOnz6t0aNHKz4+XpMmTXqQQ8uUJUuWqEePHhnWXbt2TdeuXdOpU6e0fv16vfbaa3Jzc/vP11q1apVefvnlW9qHjh8/ruPHj2vp0qVasmSJOnXqdNvnh4WFqWbNmrp48aJ13ZEjR9SnTx85OjrqlVdeuefje/LJJ7Vjxw7FxMRo9uzZ6tq1qyRp5syZ1n2efvpprVu37rbP37p1q+bNm3fL+rNnz+rs2bNatWqVPvnkkwe+sHbcuHH69ddfM73//PnztX37dp09e1ahoaEaPny45s+fr4sXL2rw4MHW/YKCgmzaGgUAWYlCHchlNm3aZP3Yx8dH7dq1y9Tzrl69qvbt21uLdHd3d/Xo0UNeXl5asWKFQkNDlZKSojfeeEM1a9ZUo0aNbnmNyMhIRUVF6eWXX1bhwoW1aNEiXb58WVJqITlmzBi5uLho9OjROnPmjKZOnWp9br9+/VS6dGlJkq+v7y0j6JmVvgitXbu22rRpo6SkJIWFhWnnzp0Zfom4mxMnTuill15SQkKCJMnPz0/dunWTyWTS0qVLdfnyZSUkJKhbt26qWbOmypQpc8trnDp1Sm5uburfv7/c3d01b948xcXFSUptT7qfQt3b21vdunVTcHCwfv/9d+3YsUOlSpXSypUrJUmNGjVS1apV71iou7q6qm7duqpWrZr8/PyUN29eRUdHa9OmTfrjjz9ksVj0+uuv64UXXpC7u/t//r8KDAy87fv8+uuvKl68uDp06CAPDw9dunTprseVL18+ff7552rcuLGSk5P10UcfqUOHDpo5c6auXLkiSapTp84tfz0BYFAOptTFKIyUJR0KdSCXOX/+vPXjsmXLWlsl/suSJUsUGRlpfbx69Wq1bNlSkvTaa6+pdOnSiomJkcVi0YwZM25bqEvSBx98oCFDhkiS6tata/1FwWw26+jRo6pcubJ69+59S/H3wgsvWNsoHkT60e9Zs2apbt26GbafOXMmQ1/3ncyZM8dapDs4OCgkJMR6sWn37t1VtWpVpaSk6MaNGwoODr7jlJJffPGF2rZtK0kqVqyYhg4dKkk6evSorl27Jk9Pz3s9RA0ePFhz586VxWLRrFmzVL58eWvWV199VX/++ecdn9u7d2/17t1bf/75pw4cOKDIyEg5OTmpbdu2+uOPPyRJV65c0a5du/T444/f9/+rkiVLas+ePcqXL1+mj6tBgwYaNWqUJk+eLElq3769YmJiJEmenp5avny5nJz4sQYg5+A7GoBM2b59u/XjAgUKWIt0KbXPvWXLllq1atUt+6bn6Oiovn37Wh+XK1cuw/abW2qywuOPP24tVJs1a6Z69eqpTJkyqlixoho2bKjKlStn6nXSH2PNmjUzzAjz6KOPqmbNmtbC9k7no3DhwtYiXbr9+bifQr1cuXJq0aKFNm7cqK+++spaDBcvXlxt27a9a6G+Z88evfzyy/rrr7/u+h4POnvMwIED76lITzN+/Hj99NNP2r59u7VIl6Tg4GCVKlXqgTIBgNFwMSmQyxQpUsT68bFjxzI9T3pae4Ek+fv737I9/bo7Fdz+/v4Zer9dXV0zbE9/Eee9uvk40kaQbzZ16lTrLxkxMTH68ccfNXfuXA0aNEhVqlRR48aNFRsb+5/v9zDOx83TXj7M8/Hqq69KSp2q8e+//5aUWhzf7ULSuLg4tWnT5j+LdOnO5zezypcvf1/Pc3R0VP/+/TOsK1iwoDp27PhAeQDYmL1vbsQNjwAYUfopDqOiorR+/fpMPc/X19f68e2mbUy/zsfH57av4ezsnOHxg9xs5+aWnbTebim1jeZOU0t6eXnpu+++U1hYmFatWqW33npLXbp0sc5us3nzZr377rv/+f5GOx83a968eYYReg8PD/Xq1euuz9myZUuGC1tff/11/f3337JYLJn65eVe5MmT576e9/fff2vEiBEZ1l26dCnDdKMAkFNQqAO5zKBBgzKMqvbv31/79++/Zb/ExEQtWrTIepFf+rmt//77b23cuNH6+NKlSxke22Ie7JvbJnbs2GH9eNq0aXf8S8HBgweVmJiookWL6rnnntOoUaP02WefZShi9+zZ85/vn/4Yd+/enWEU+uDBg9q9e/dt97UVk8lkHVWXpK5du97xF4Y06a9BkKQuXboof/78kpRhqseb3fwLx/Xr1+81bqa98sor1ruupr/GYtasWfr++++z7H0BwB7oUQdymUqVKmny5MnWudTDw8NVq1YttWnTRtWrV7/lhkdNmzaVJHXr1k2TJ0+2FnMdOnTQK6+8Ii8vLy1fvtzaL2wymawXRGal8uXLy9PT0zqf9oABA/Ttt98qPDz8jj3hkvTGG2/o999/V5MmTRQYGKgCBQrowoULWrx4sXWfzPRODxw4UPPmzVNCQoJSUlLUqFGjDLO+pLWtuLi4aODAgQ92sPepe/fuKly4sKTUGVH+y8098l27dtULL7ygM2fO6NNPP73j8woUKCBnZ2frDapGjx6t/fv3y9nZWY0bN1atWrUe4Cj+FRwcrG+//VZS6l8Ivv32Wy1YsEDvv/++LBaLunfvrgMHDqhAgQIP5f0AZCGTyVg3GTJSlnQo1IFcKCgoSHny5NGIESOUkJCgpKQkrVu37o5T9kmpxeuaNWvUtm1bXb16VXFxcQoODs6wj4ODg9599907zvjyMLm4uGjIkCGaMmWKpNSe6bVr10qSatWqpbNnz95xyr+oqCh99dVXt93m5uaWYST6Th555BF9+umn1nnUIyMj9cEHH2TYx9XVVUuWLNEjjzxyL4f20Hh4eGR6+k0p9aLYFi1aWEemDx06pPHjx0tK/UVt6dKlt32ei4uL2rRpYz3/+/bt0759+yRJ77333kMp1P/66y+98cYb1sdvv/22ypQpoylTpmjjxo3666+/FBERoR49eliLeQDI7mh9AXKpV199VadPn9aECRPUoEEDFShQQE5OTvLw8FCFChXUv39/hYSEZLhDaMOGDXXw4EG9/vrrqlSpkjw8POTi4qJixYqpS5cu+u233/T666/b7BgmTZqkqVOnqmTJknJ2dlbx4sUVFBSkzZs3y93d/bbPGT58uIYMGaK6deuqSJEicnFxkaurq0qVKqVu3brp999/V+3atTP1/s8//7z27dunfv366ZFHHpGbm5vc3NxUunRp9e7dW3v37r3jzY6MavXq1Ro6dKgKFSokFxcXPfLII5o6dao+/vjjuz5v4cKF6tatm/z9/TM95WdmJSQkqHPnztapNZ988kkNGjRIUuovQ59++qm1/WbDhg2aM2fOQ31/ALAXkyWzUz4AAAAAD8BsNsvb21uujcbL5PTfd4C2FUtSvBI2T1R0dLS8vLzsHceKEXUAAADAgCjUAQAAAAPiYlIAAADYFrO+ZAoj6gAAAIABMaIOAAAA2zI5pC5GYaQs6RgzFQAAAJDLUagDAAAABkTrCwAAAGyLi0kzhRF1AAAAwIAo1AEAAAADolBHtpSYmKikpCR7xwDsxmw2a/fu3faO8UAuXbqkY8eO2TsGAHtIm/XFSIsBGTNVNpCSkmLvCA9FdjyO8+fPa/z48Zo0aZLOnz9v7zj3LTue+zSJiYn2jvDAsvMxnD17Vn379lXt2rU1ZMgQe8e5L3/99ZcqVqyot99+W0eOHLF3HMCmLl68qODgYHXr1k1du3bV+PHjFRYWZu9YMCAuJs2kI0eO6IcfftBTTz2lChUqyMEhe/6OEx4ern379ik8PFwvvviiXF1dlZKSkm2O5/jx42rXrp0OHz6sSpUq6YknnpC/v7+cnLLHp/KlS5e0Y8cO/fLLL7p+/bpq1qypGjVqqFatWvaOlmmHDx9WcHCwBgwYoIoVK9o7zn3Jzsdw/PhxtW7dWidOnNATTzyhJk2aSJLCwsJUtGhRmQx6QVR6N27c0LRp03TlyhV99tlnyps3r/r3768KFSrYOxqQ5U6cOKHnn39e+/fvz7B+0aJFWrVqlerXr2+nZDCi7FHd2NmRI0dUv359Xb16VZUqVVLNmjU1atQoFSxYUPny5ZPFYskWPxxPnDihF154QUePHtX169f1ySefaOPGjcqTJ4+9o2VKaGionnrqKYWGhqp///5677335O7uni3OvSSdPn1aPXv21P79+xUVFSVJWrhwoWrVqqWePXuqb9++dk74344ePap69erJbDbriSeeyHZFrpS9jyE0NFQtWrTQ6dOnNWDAAM2ZM0eSFBwcrDlz5mjGjBlq3ry54b8mXFxcNHz4cF2/fl3r1q3TnDlzZLFYNGDAAIp1Gzh69KjKlStn7xi50unTp/XEE0/o/PnzatiwoUqUKKH//e9/ioqK0sWLF9WuXTtt2rRJlStXtnfUrMesL5mSPYZR7Sg2NladO3fW1atX5e7urpMnT2rZsmVq06aNevfurc2bN+vGjRvW/S0Wix3T3tnRo0fVoEED7d27V3nz5pWHh4e2bt2qL774wt7RMiUmJkajR49WaGioXn75ZQUHB8vDw8Ow5/tmR48eVaNGjRQSEqLAwEDVqlVLtWvXliTt2rVLH3zwgT7//HM7p7y7tM8hs9ms4cOHq0OHDvaOdM+y8zHExsZq3LhxOn36tF588UVrkT5jxgwNHjxYR48e1dSpU/Xjjz8a/uvCYrGoUqVKmjx5sp5//nlJqb9sBAcH6/Dhw3ZOl7N9+eWXqlChgqZMmWLvKA8kO16jdPXqVQ0ePFjnz5/XoEGDFBISoiVLligkJETPPPOMfH19dfnyZfXu3ds6mANQqP+H5ORkVapUSSaTSYULF9a8efNUvnx5nTp1SqtXr9YTTzyhHj16aN68eZKMWagfPXpUDRs21KVLlzRu3LgMf1r7/fff1a9fP61cuVJnzpyxb9C7iIuL0/79++Xh4aFXXnlFUuo36vQtO3Fxcbp8+bK9It5R2vk/d+6chg4dqh07digkJEQbNmxQr169JEmnTp3Sxo0bDfvDJ+0YIiMjNXbsWL3zzjuSpHfeeUczZ860c7rMye7HcP36de3Zs0dubm7q0aOHJOl///ufhg8frrx588rFxUVbt27V5MmT9e233xrue9HRo0c1YsQISZLJZJKTk5MqVaqkRx55xLrP3LlzNX/+fEMX6+mPI7s5duyY+vXrJ0l666239O6779o50b1Jf+6dnJyUnJxs50T3JjIyUocPH1bhwoU1fPhwSVJ8fLzKli2ryZMnW/+6FxERoatXr9oxKYyEQv0/eHl5qUePHrJYLDp58qScnZ21b98+LVmyxPoD5osvvtDAgQP1f//3f1q0aJGhLhI8ffq0Hn/8cf3999+qVauWJkyYoMcff1xFihSRlNp6sWDBAg0bNkyzZs1STEyMnRPf3p49e/TXX3/pxo0bio+PlyRrX3pacbtr1y699957ioyMtFvOm6U//3Xq1NEHH3wgNzc3OTs7K3/+/FqwYIE6duyo5ORkLV++XCdPnrR35Fvc/Dk0ceJESdKHH36ooKAgjR07VqdPn7ZzyrvLzDGcPXvWzinvbteuXfrrr7+UlJRk/ZyvVq2ahg8frhUrVmjNmjVydHTUtm3b9PXXXxvql77Tp0+rYcOGev/99zVo0CDr+tmzZ2vatGkqWLCg6tSpY123cOFCHTx40F5x7yj9cQwePNjece5Z2bJlNXz4cBUrVkwJCQkaNWpUtinWb3fuHR0dMxTrRvrZezu7du3S6dOndfnyZYWHh0uSXF1dZbFYVLZsWb355ptycHBQaGiojh8/bue0tmCAWV4yzPhizJLYmKkM5sknn7SOfG7cuFEuLi46cuSITpw4IUl64oknJKV+ETZp0sRQF2bGx8crOTlZrq6u2rVrl0aOHKk5c+Zo6dKlcnd3V//+/VW4cGFdvHhRK1euNOSItCQFBgYqf/78SkpK0qJFi3ThwgVJUkJCgrVgf+utt/Thhx8a6htc+vO/c+dOvfrqq5IkZ2dnJSQkSJJatmwpZ2dnOTk5KS4uzp5xb+vmz6GgoCDNnj1bw4YNU/HixbV48WKVLFlSkgxbsP/XMXz22WcqVqyYvWPeVfqvgU8++URhYWEqWLCgRo0apdatW6tVq1aqW7eu8uTJo/Llyxv2+9DcuXM1fPhwzZs3T0OGDFGRIkW0cOFCrVq1Sk8//bSk1F+gPvvsswxthUaQ/jjSLkbOLtL+whIUFKTBgwerUKFCSklJyTbF+p3OfVqxnpycLAcHB1ksllsu0jSKEiVKWK9rmz9/vsLDw2Uymaw/C/z9/eXp6amyZcuqSpUqdk4LozDOd3KD+7//+z9J0qpVq9SlSxdNnTpVkvTDDz9o48aNWr9+vf766y+VLl3anjFvUaFCBW3evFmBgYFycHDQe++9p1dffVVFixbV6tWrFRwcrGXLlsnNzU3JycnW0Wqj8fX1Vd68eSVJO3fuVHBwsCIiIuTq6ipJGjlypP73v/+pQYMGKlOmjD2jZnDz+Z8zZ471B0xa9kKFCik5OVnlypVTiRIl7Jj29m4+hnfeecdaYM2bN8/a5x0UFKS+ffsqJCTEvoFv427HsHDhQj3zzDOSjNm6lsbPz08eHh6SUr8G0n7Qe3p6Skr9Gti2bZuqVKmiTp06ydHR0Z5xM6hQoYL1+gwHBwdNnz5dAwcOVJEiRfTJJ5/o6aefVtGiRTVlyhQ1atRIkvTyyy/LxcXFzskzuvk45s+fn22KdZPJZP38fv311zVs2LBsVazf7dw7OjrK0dFRKSkpatOmjTp16qTNmzfbOfGtihYtqjx58igxMVGbNm1ScHCwwsPD5ebmJklasmSJoqOj9eijj1q/1gGTxcg/mQymTZs2+u6776yPN2zYoJYtW2aL6Q0PHjyo9u3b6+TJk7JYLGrevLk2btwoSerXr58WLFigRo0aae3atcqXL599w97Bxo0b9eKLL8psNsvHx0f+/v6qWrWqQkNDtWPHDvn7+2vLli2GKtTTpJ3/U6dOKSUlRX379rVe19CxY0d99dVX6tmzp+bMmWMt4I3mbp9DY8aM0dSpU+Xu7q7Dhw8bdnT65mNo2bKlNmzYICl1ykCjFYY3++6779S5c2eZzWb5+voqICBANWrU0MmTJ7V9+3YFBARo8+bNhvwakO5+/tNGRI8cOaK8efMqMDDQzmnv7MCBA+rQoYP167lfv36aO3euvWNlSvpZyqZPn64PPvhAFy9elIODg6ZOnWr4/vubz33676XPPvus1q9fr7x58+rQoUMqWrSondPeKv3XcMGCBVW8eHG1bt1au3fv1jfffKNChQppy5Ythhv0e5jMZrO8vb3l2uwdmZzd7B3HypIYr4QfRyo6OlpeXl72jmNFoZ4Jad/YFi5cqNdff11xcXGaNWuW+vfvrxs3bsjZ2dnw06FJt36DGzBggPz8/DR58mQVLFhQv/76q2F/wEupveiff/65Bg4cqOvXr1vXp12UtnLlSpUtW9aOCe/u5vPfv39/+fv7a8KECSpXrpy+//57FS9e3N4x7+pun0N+fn4KCQlRpUqV7B3zrm73/yE4OFhSarFopJHom93pa8DR0VGVKlXSl19+aeivAenu5z+7THUr5cxi3cnJSe+++66GDh1q34D/4XbFekREhNatW6eCBQsqJCRE5cuXt3fM20pKStLy5cs1YMCADF/DUuo1BOvWrTNs9oeFQv3eUKjfg3PnzqlevXo6f/682rRpo6+//treke5Z+m9wUurFN/ny5dPWrVuzzXzS+/fvV3BwsC5duqQ8efLo8ccf1zPPPKPChQvbO9p/Sn/+LRaLLBaLfH19tW3btmwzr3FO+By6+Qd9165dtWzZMnvHyrT9+/drzpw51q+Bxx57TM8++2y2+BqQsv/5T5OdjyN9sf7+++9r+vTp+vvvv1WuXDmtXr3a8MVi+nNvMpmUnJys/Pnz69dff80W30v37Nmj9957T+Hh4fLw8FDdunXVvXt3Q/8l6WGhUL83FOr3aNmyZerevbv8/Pz0119/qWDBgvaOdM8OHjyojh076siRI/L29tZvv/3GTUZsKP35z5cvn7Zt25btzn9O+Bw6cOCAOnXqpMOHDytv3rw6duyYAgIC7B0r07LT6PPtZPfznyY7H0f6z6GRI0fqvffek5Q67WfTpk3tGS1TDhw4oBdeeMH6fWj79u2G/wUjvezQNpsVrIX6U+/K5Oxu7zhWlsQ4JfxvhOEK9dz3GfKAGjZsqKpVq2rLli3ZskiXpEcffVTLly9XjRo1smWBJWW86C+7/a6Z/vxnxyJdyhmfQ5UrV9bnn3+umjVraufOndmmuLqd7PY1IOWc85+djyNtJFpKvQbL19c3w4X7Rpd27tO+D2WnIl1Shl+0s+PXMGyDEfX7EB8fb71KOztLSEgw7IWLuUFOOP8cAx5UTjn/2f04unTpohUrVqhmzZrauHGj8ufPb+9ImZbdz31uw4j6vXGyd4DsKCcU6ZL4xmZnOeH8cwx4UDnl/Gf34xgwYID27dunzz//PFsV6VL2P/e5lvVGQwZhpCzpUKgDAJDLPfbYY9qzZw9FL2Awxvz1AQAA2BRFOmA8jKgDAADAtkym1MUojJQlHUbUAQAAAAOiUAcAAAAMiEL9PiUkJGjChAlKSEiwd5T7lt2Pgfz2l92Pgfz2l92Pgfz2l92PIbvnv29ps74YaTEg5lG/T2nzgBptvs17kd2Pgfz2l92Pgfz2l92Pgfz2l92PIbvnv1fWedRbzjDePOobXzPc/wdj/voAAAAA5HLM+gIAAADbYtaXTMmxhXpKSoouXLggT09PmbLg5JvN5gz/zY6y+zGQ3/6y+zGQ3/6y+zGQ3/6y+zFkdX6LxaJr166pcOHCcnCgkSK7ybE96ufOnVNgYKC9YwAAANhdWFiYihYtau8Y//aot/rQeD3q3w01XI96jh1R9/T0lCS5VOwmk6OLndPcn7Mh79s7AgAAyMaumc16pGSgtS4yDKPNtGKkLOnk2EI9rd3F5OiSbQt1I/1GBwAAsq+saANG1jPmrw8AAABALpdjR9QBAABgUMz6kimMqAMAAAAGRKEOAAAAGBCtLwAAALApk8lkrAtcjZQlHUbUAQAAAAOiUAcAAAAMiNYXAAAA2BStL5nDiDoAAABgQBTqAAAAgAHR+pJJzepX0PiBT8vFyVFx8Tc06K0vdODYeW1Z9oZcXFJPo5Ojgyo9Uli1O07VweMX7JwYAADAoEz/LEZhpCzpUKhnQj5Pdy1+q7ua9Zyhw6fC9Vj10lr8VjfVen6qGr78vnW/Z5tW06g+rSjSAQAA8MBofcmEUoEFdCU6VodPhUuStu09qcAAH1UrXzTDft3a1dPSdb/ZIyIAAAByGAr1TDhx9pJ8vfOobtWSkqTWjSrLK6+7ihf2s+5T1D+fHq9RRiu++8NeMQEAALKFtFlfjLQYEa0vmWCOiVfn4Ys0afAzyuPuqt//PK1DJy8qKTnFuk/XZ+pq468HFXk11o5JAQAAkFNQqGfSll3H9VSvmZIkF2cnnflpqg6fumjd/vIzdfXq1JX2igcAAIAcxrCtL0uWLLH+KcLR0VFhYWF2zROQ38v6cVDvFtr8xzGdCrssSWr8f2Xl5OigTTuO2CseAABAtmHvNpfs0vpi6EI9TUpKipYuXWq/MJLG9m+tfWvG6OD68SpWyFf9Jnxu3da9XX0t+3qHLBaLHRMCAAAgJzFk68vp06e1ZcsWSVKtWrW0a9cuLV26VGPGjLFbpoGTV9xxW/dRS2wXBAAAALmCIUfUly5dKovFooCAAC1cuFCSdOLECW3dutXOyQAAAPCg7N3mQuvLfbJYLFq2bJkkqXPnzqpWrZqqVKkiKWM7zM0SEhJkNpszLAAAAEB2ZbhCffPmzTp9+rQk6aWXXsrw31WrVun69eu3fd60adPk7e1tXQIDA20TGAAAAMgChivU04+aN27cWPny5dOECRMkSWazWWvWrLnt84KCghQdHW1dbjdLzPQRz+nIhomK2ztHVcoWsa4vXayAflkyTH+uG6etnw1XhVIBmdp2s27t6unA+nH66+vxCh77opycUk9vjYrFtOOLN7Vn9Wh1ebqOdf9Gtctq9uhOmTovAAAAOYW921xofbkPMTEx+uqrr6yP04ru2Nh/byJ0p/YXV1dXeXl5ZVhutuanvWrSY4ZCL0RmWD9ndCd9vHqbqrSbpOlLftTCSS9lalt6xQv7afyANmr6ygxVemaiCvp5qWf7BpKkN3o00+vvrlKDLu9pdJ+WkiQ3V2eN6ddKY2auz9zJAQAAQK5iqEL9q6++shblBw8elMVisS4ffvihJOmXX3657znVt+05qfOXrmZYV8Anr2pULKYV3/0hSVr70z4V8fdRqcD8d912s/ZNq+nbzQcUEXlNkrToq1/VsUVNSVJiUrI83Fzk5uqs5JTUu5mO6dtKwctDFB0Td1/HAgAAgJzNUIV62mh52bJlValSpQzb2rdvL+nhz6leNMBH4ZfNSk5Osa47F35FgQG+d912s8BCvjp78Yr1ceiFKwoM8JEkTV2wUSN6Ntc3cwdq1Ix1qlK2iEoW9dO6Tfse2nEAAABkGyYDLgZkqHnUQ0JC7rgtMDAw295Q6OjpCDXr+aEkycHBpG/nDlLPscvUsUVNPdu0uswx8Ro5fbWuXmN0HQAAAKkMNaJuD+fCoxSQ30uOjv+eiqIBvgoLv3LXbTcLu3hFxQr9O9JevLCvwsKjbtlvcJcntOanvbp67bre7N1CXUd+oq17TmhQlyce8pEBAAAgO8v1hfrfUTHad+ScXmxVW5L0bNNqOn/pqk6FXb7rtput3bRPbRpVlr+fpySp13OPa9UPuzPsU7ywn56sU16LvtoqZydHOTk6ymKxKMViUV4P1yw+UgAAAGOw9wwv2WXWF0O1vmS12aM7qeXjleTv56Wv5w5UTGyCHm07UYOmrNDCSS9pRM/mMsfGq+/4z6zPudu2ueM6a8PmA9qw+YDOnI/U5Hkb9PPiYZKkLbuPa9HqjHdSfX/Ecxr+/mpJkjkmXis37tKuVaMUez1BXUcutsEZAAAAQHZhsmTXxu//YDab5e3tLdfKvWVydLF3nPsS9ccce0cAAADZmNlslr+ft6Kjo287dbU98nh7e8vr+QUyObvbO46VJTFO5lV9DHOe0uSqEXUAAADYn8kkY7WbGChKerm+Rx0AAAAwIgp1AAAAwIBofQEAAIBNmWS0mVaMlOVfjKgDAAAA9yA5OVljx45VyZIl5e7urtKlS2vy5MkZbs5psVg0btw4FSpUSO7u7mratKmOHz9+T+9DoQ4AAADcg3feeUfz5s3TnDlzdPjwYb3zzjt69913NXv2bOs+7777rmbNmqX58+dr586dypMnj5o3b674+PhMvw+tLwAAALApw91k6B6z/Pbbb2rbtq1at24tSSpRooRWrFih33//XVLqaPqHH36oMWPGqG3btpKkZcuWyd/fX+vWrVOnTp0y9T6MqAMAAABKnec9/ZKQkHDb/erXr69Nmzbp2LFjkqT9+/dr69atatmypSTp9OnTCg8PV9OmTa3P8fb2Vp06dbR9+/ZM52FEHQAAAJAUGBiY4fH48eM1YcKEW/Z78803ZTabVb58eTk6Oio5OVlvvfWWunTpIkkKDw+XJPn7+2d4nr+/v3VbZlCoAwAAwLZMMtZEK/9kCQsLy3BnUldX19vu/uWXX+rzzz/X8uXLValSJe3bt09Dhw5V4cKF1a1bt4cWi0IdAAAAkOTl5ZWhUL+T4cOH680337T2mleuXFmhoaGaNm2aunXrpoCAAElSRESEChUqZH1eRESEqlWrluk89KgDAAAA9+D69etycMhYRjs6OiolJUWSVLJkSQUEBGjTpk3W7WazWTt37lS9evUy/T6MqAMAAMC2DDbri+Ueszz99NN66623VKxYMVWqVEl79+7VBx98oFdeeUVS6qw2Q4cO1ZQpU1SmTBmVLFlSY8eOVeHChdWuXbtMvw+FOgAAAHAPZs+erbFjx2rAgAG6dOmSChcurL59+2rcuHHWfUaMGKHY2Fj16dNHV69eVYMGDfT999/Lzc0t0+9jsqS/hVIOYjab5e3trYjI6Ez1GhmRT50h9o7wwKJ2zrR3BAAAci2z2Sx/P29FRxujHkqrz3xe/FgOLh72jmOVcuO6olb0NMx5SsOIOgAAAGzKaDc8MlKW9LiYFAAAADAgCnUAAADAgGh9AQAAgE3R+pI5jKgDAAAABkShDgAAABgQrS8AAACwLdM/i1EYKUs6jKgDAAAABkShDgAAABgQrS8AAACwKWZ9yRxG1AEAAAADolAHAAAADIjWl1yiWb3yGj+gtVycnRQXf0OD3lqpA8cvSJJG92mhF1rUVEJikiKvxqpF3zl2TgsAAHIyWl8yh0I9F8jn6a7FU15Ws96zdPhUuB6rVkqLp7ysWi+8rYEvNlLlMoVVs+PbSkxKlr+fp73jAgAAQBTquUKpovl1JTpWh0+FS5K27TulwAAfVStfVK+99KRa9JujxKRkSVJE5DV7RgUAAMA/KNRzgRNhf8vXO4/qVimhHX+eUeuGj8orr5sqli6kgn6eerpRZT3btKokadZnIfrqx712TgwAAHIyWl8yh0I9FzDHxKvzyE80adDTyuPhqt//PK1DJy9KkpydHOXm5qyG3WaoWCFfhSweqqNnIqz96wAAALAPCvVcYsuuE3pq12xJkouzo878b4p27D+ta7HxWvHdLknS2YtXtH3/KdWsVIxCHQAAwM6YnjGXCMjvZf04qFdzbf7juE6du6wvf9ijp+pXkCT5eHmoVqXiOkiRDgAAslBa64uRFiMyXKHeuHHjDCfN2dlZhQoVUseOHXX69Gl7x8u2xvZrqX2rR+ngujEqVshX/SatkCSNm/ONmtUrr10r39SPC1/V9KWbtOuvs3ZOCwAAAMO2vri4uKh69eq6fv26Dhw4oFWrVunQoUM6ePCgvaNlSwOnrLzt+ivR1/X8sEU2TgMAAID/YrgR9TSFChXSjh079Oeff6pnz56SpL/++kuRkZF2TgYAAIAHYjLgYkCGHVFPc/36dZ0/f16SVKBAAXl5ed12v4SEBCUkJFgfm81mm+QDAAAAsoJhC/XQ0NAMjf0uLi767LPP5OzsfNv9p02bpokTJ9oqHgAAAJClDNv64uLiojp16qhmzZpyd3fXjRs31KNHD507d+62+wcFBSk6Otq6hIWF2TixbUwf3l5HvhmnuN0zVaVsEev60oEF9MsnQ/XnmtHauux1VSgVkKltN+vWtq4OrB2jv9aPVfCYF+TklPopUqNCoHYsH649q4LUpU1t6/6NapfR7FEds+BIAQBATmXvGV6Y9eUBpfWo79q1S7t2pc7zfeHCBc2fP/+2+7u6usrLyyvDkhOt+Wm/mvScqdALGXv154zuqI/X/qYq7d/S9KU/aeGELpnall7xwr4a37+VmvaaqUptJ6ugr6d6PltfkvRG96Z6/b01avDSdI3u3UKS5ObqrDF9WmjMrG+y6GgBAAByL8MW6ncSHx9v7wh2tW3vSZ2/FJ1hXQGfvKpRoZj1xkVrN+1XEf98KlU0/1233ax9k2r6dvNBRURekyQtWv2bOraoKUlKTEqWh5uz3FydlJxikSSN6dNCwSu2KDomLsuOFwAAILcybI/6xYsXVbduXSUlJenQoUOSJAcHBz399NN2TmY8Rf3zKfxytJKTU6zrzoVHKbCQj8zX4u647dS5yxleJzDAR2fDr1gfh16IVGCAjyRp6sIfNGd0R3m4u2rUzPWqUraIShb105jZjKYDAIB7Y7R2EyNlSc+whfqNGze0c+dOSZKnp6fq1aunYcOGqVGjRnZOljsdPROhZr1nS5IcHEz6NniAeo79VB2b19CzTarJHBuvkR+s1dVrjK4DAAA8DIYr1ENCQuwdIds5F3FVAfm95ejoYB05Lxrgo7CLUboWG3/HbTcLC49SyXQtMcUL+yks/Nb9BndurDU/7dPVmDi92au5and6R51b1dagzo015aONWXSUAAAAuUu261HHrf6OitG+I2F6sVUtSdKzTarq/KWrOnXu8l233Wztz/vVptGj8vfzlCT16lBfq37Yk2Gf4oV99WSdclq0epucnRzl5Oggi8WiFEuK8nq4ZvGRAgCAnMDeM7xkl1lfDDeijrubPaqjWjaoJH8/T309p79irsfr0XZTNGjql1o4obNG9Ggmc2y8+k5cbn3O3bbNHdtJGzYf1IYtB3XmfKQmf7RRP38yVJK0ZdcJLVqzLcP7v/9Gew2fvkaSZI6J18rvd2vXyjcVez1BXYOWZPnxAwAA5BYmi8VisXeIrGA2m+Xt7a2IyOhsO1WjT50h9o7wwKJ2zrR3BAAAci2z2Sx/P29FRxujHkqrzwr3Wi4HFw97x7FKuXFdFxZ1Nsx5SsOIOgAAAGzL9M9iFEbKkg496gAAAIABUagDAAAABkTrCwAAAGzKaDOtGClLeoyoAwAAAAbEiDoAAABsihH1zGFEHQAAADAgCnUAAADAgGh9AQAAgE2ZZLDWF4NOpM6IOgAAAGBAFOoAAACAAdH6AgAAAJti1pfMYUQdAAAAMCAKdQAAAMCAaH0BAACAbZn+WYzCSFnSoVA3sKidM+0d4YH51Bli7wgPJCf8PwAAANkTrS8AAACAATGiDgAAAJti1pfMYUQdAAAAMCAKdQAAAMCAaH0BAACATdH6kjmMqAMAAAAGRKEOAAAAGBCtLwAAALApkyl1MQojZUmPEXUAAADAgCjUAQAAAAOi9QUAAAA2ldr6Ypx+EwNFyYARdQAAAMCAGFFHttGsXnmNH9BaLs5Oiou/oUFvrdSB4xckSaP7tNALLWoqITFJkVdj1aLvHDunBQAAeDAU6sgW8nm6a/GUl9Ws9ywdPhWux6qV0uIpL6vWC29r4IuNVLlMYdXs+LYSk5Ll7+dp77gAAOBuDDbri4yUJR0KdWQLpYrm15XoWB0+FS5J2rbvlAIDfFStfFG99tKTatFvjhKTkiVJEZHX7BkVAADgoaBHHdnCibC/5eudR3WrlJAktW74qLzyuqli6UIq6OeppxtV1palr2nL0tf0XLPq9g0LAADwEDCijmzBHBOvziM/0aRBTyuPh6t+//O0Dp28KElydnKUm5uzGnaboWKFfBWyeKiOnomw9q8DAABjMZlMBpv1xThZ0qNQR7axZdcJPbVrtiTJxdlRZ/43RTv2n9a12Hit+G6XJOnsxSvavv+UalYqRqEOAACyNcO2vsTHx+uDDz5QnTp15OXlJQ8PD5UtW1Z9+/bVqVOn7B0PdhCQ38v6cVCv5tr8x3GdOndZX/6wR0/VryBJ8vHyUK1KxXWQIh0AAGRzhhxRj4qKUpMmTbR3715Jkqenp0qXLq2zZ89qwYIFqlevnkqVKmXnlLC1sf1a6rHqpeXk6KCdf55Rv0krJEnj5nyjj8Z3Vp/nGkiSpi/dpF1/nbVnVAAAcBcmg836YqQs6RmyUB80aJC1SB8+fLimTp0qJ6fUqFu2bJGzs7M948FOBk5Zedv1V6Kv6/lhi2ycBgAAIGsZrlCPjo7Wl19+KUmqWrWq3nnnnQwN/g0bNrRXNAAAAMBmDFeoHzt2TElJSZKkxx9/PNNX4SYkJCghIcH62Gw2Z0k+AAAAPBgHB5McHIzTb2IxUJb0DHcxqcVisX58L1PlTJs2Td7e3tYlMDAwK+LhAU0f3l5HvhmnuN0zVaVsEev60oEF9MsnQ/XnmtHauux1VSgVkKltN+vWtq4OrB2jv9aPVfCYF+TklPopXqNCoHYsH649q4LUpU1t6/6NapfR7FEds+BIAQAAHozhCvVy5cpZ+9G3bt2aoXC/m6CgIEVHR1uXsLCwrIyJ+7Tmp/1q0nOmQi9EZlg/Z3RHfbz2N1Vp/5amL/1JCyd0ydS29IoX9tX4/q3UtNdMVWo7WQV9PdXz2fqSpDe6N9Xr761Rg5ema3TvFpIkN1dnjenTQmNmfZNFRwsAAHD/DFeoe3t7q2PH1BHOvXv3atSoUdZWGEn66aef9Ntvv93yPFdXV3l5eWVYYDzb9p7U+UvRGdYV8MmrGhWKWedCX7tpv4r451Opovnvuu1m7ZtU07ebDyoi8pokadHq39SxRU1JUmJSsjzcnOXm6qTklNRf/sb0aaHgFVsUHROXZccLAABulTbri5EWIzJcoS5Js2fPVrVq1SRJb7/9tvz8/FS1alX5+vqqWbNmOnbsmH0D4qEq6p9P4ZejlZycYl13LjxKgYV87rrtZoEBPjobfsX6OPRCpAIDUvebuvAHjXilmb4JHqBRM9erStkiKlnUT+t+3p+FRwYAAHD/DHcxqST5+vpq+/btCg4O1sqVK3X48GEdPXpURYoUUYcOHZj5Bffs6JkINeudeldTBweTvg0eoJ5jP1XH5jX0bJNqMsfGa+QHa3X1GqPrAADAGAxZqEuSm5ubXn/9db3++uv2joIsdi7iqgLye8vR0cE6cl40wEdhF6N0LTb+jttuFhYepZLpWmKKF/ZTWPit+w3u3FhrftqnqzFxerNXc9Xu9I46t6qtQZ0ba8pHG7PoKAEAQBqTyXRPk4ZkNSNlSc+QrS/IXf6OitG+I2F6sVUtSdKzTarq/KWrOnXu8l233Wztz/vVptGj8vfzlCT16lBfq37Yk2Gf4oV99WSdclq0epucnRzl5Oggi8WiFEuK8nq4ZvGRAgAAZJ5hR9SRM80e1VEtG1SSv5+nvp7TXzHX4/VouykaNPVLLZzQWSN6NJM5Nl59Jy63Pudu2+aO7aQNmw9qw5aDOnM+UpM/2qifPxkqSdqy64QWrdmW4f3ff6O9hk9fI0kyx8Rr5fe7tWvlm4q9nqCuQUuy/PgBAAAyy2TJ7PyH2YzZbJa3t7ciIqOZAcaOfOoMsXeEBxK1c6a9IwAAcN/MZrP8/bwVHW2MeiitPqswfK0cXfPYO45VckKsDr/3rGHOUxpaXwAAAAADolAHAAAADIgedQAAANgUs75kDiPqAAAAgAFRqAMAAAAGROsLAAAAbIrWl8xhRB0AAAAwIAp1AAAAwIBofQEAAIBNmUypi1EYKUt6jKgDAAAABkShDgAAABgQrS8AAACwKZMMNuuLjJMlPUbUAQAAAAOiUAcAAAAMiNYXAAAA2BSzvmQOhTqyVNTOmfaO8EB8ag+yd4QHEvXHHHtHAAAA94nWFwAAAMCAGFEHAACATZlMBpv1xUBZ0mNEHQAAADAgCnUAAADAgGh9AQAAgE0x60vmMKIOAAAAGBCFOgAAAGBAtL4AAADAppj1JXMYUQcAAAAMiEIdAAAAMCBaXwAAAGBTzPqSOYyoAwAAAAbEiDpgI83qV9D4gU/LxclRcfE3NOitL3Tg2HltWfaGXFxSvxSdHB1U6ZHCqt1xqg4ev2DnxAAAwJ4o1AEbyOfprsVvdVeznjN0+FS4HqteWovf6qZaz09Vw5fft+73bNNqGtWnFUU6ACBHY9aXzKH1BbCBUoEFdCU6VodPhUuStu09qcAAH1UrXzTDft3a1dPSdb/ZIyIAADAYCnXABk6cvSRf7zyqW7WkJKl1o8ryyuuu4oX9rPsU9c+nx2uU0Yrv/rBXTAAAYCC0vgA2YI6JV+fhizRp8DPK4+6q3/88rUMnLyopOcW6T9dn6mrjrwcVeTXWjkkBALABg836IiNlSYdCHbCRLbuO66leMyVJLs5OOvPTVB0+ddG6/eVn6urVqSvtFQ8AABiMoVpfGjdubL24wNHRUZ6enipXrpx69OihPXv22Dse8EAC8ntZPw7q3UKb/zimU2GXJUmN/6+snBwdtGnHEXvFAwAABmPIEXUXFxdVr15d586d0/Hjx3Xs2DF99tlnmjdvnnr16mXveMB9Gdu/tR6rXlpOjo7a+edp9ZvwuXVb93b1tezrHbJYLHZMCACAbTDrS+YYslAvVKiQduzYIUnatWuXnnvuOYWGhqp///5q0KCBypcvb+eEwL0bOHnFHbd1H7XEdkEAAEC2YKjWl9upVauWZs5M7etNSkrSxx9/bOdEAAAAQNYz5Ij6zR5//HHrx4cOHbrtPgkJCUpISLA+NpvNWZ4LAAAA985ksFlfjJQlPcOPqEtSSkrKf+4zbdo0eXt7W5fAwEAbJAMAAACyRrYo1H/99VfrxxUrVrztPkFBQYqOjrYuYWFhtoqHXGT6iOd0ZMNExe2doypli1jXly5WQL8sGaY/143T1s+Gq0KpgExtu1m3dvV0YP04/fX1eAWPfVFOTqlfojUqFtOOL97UntWj1eXpOtb9G9Uuq9mjO2XBkQIAAHszfKG+a9cuvfbaa5IkR0dH9ejR47b7ubq6ysvLK8MCPGxrftqrJj1mKPRCZIb1c0Z30sert6lKu0mavuRHLZz0Uqa2pVe8sJ/GD2ijpq/MUKVnJqqgn5d6tm8gSXqjRzO9/u4qNejynkb3aSlJcnN11ph+rTRm5vosOloAALJG2qwvRlqMyJCF+sWLF1W3bl0FBgbq//7v/xQaGionJyfNnz//jiPqgC1s23NS5y9dzbCugE9e1ahYTCu++0OStPanfSri76NSgfnvuu1m7ZtW07ebDygi8pokadFXv6pji5qSpMSkZHm4ucjN1VnJ/7SCjenbSsHLQxQdE5dVhwsAAOzIkBeT3rhxQ7///rvy5MmjRx55RPXr19err76qGjVq2DsacIuiAT4Kv2xWcvK/11KcC7+iwABfmWPi7rgt7WZHaQIL+ersxSvWx6EXrigwwEeSNHXBRs0Z86I83Fw0asY6VSlbRCWL+mnMLEbTAQDIqQxVqIeEhNg7AmBIR09HqFnPDyVJDg4mfTt3kHqOXaaOLWrq2abVZY6J18jpq3X1GqPrAADjY9aXzDFk6wuQnZwLj1JAfi85Ov775VQ0wFdh4Vfuuu1mYRevqFghX+vj4oV9FRYedct+g7s8oTU/7dXVa9f1Zu8W6jryE23dc0KDujzxkI8MAADYE4U68ID+jorRviPn9GKr2pKkZ5tW0/lLV3Uq7PJdt91s7aZ9atOosvz9PCVJvZ57XKt+2J1hn+KF/fRknfJa9NVWOTs5ysnRURaLRSkWi/J6uGbxkQIAAFsyVOsLYHSzR3dSy8cryd/PS1/PHaiY2AQ92naiBk1ZoYWTXtKIns1ljo1X3/GfWZ9zt21zx3XWhs0HtGHzAZ05H6nJ8zbo58XDJElbdh/XotVbM7z/+yOe0/D3V0uSzDHxWrlxl3atGqXY6wnqOnKxDc4AAAAPzmgzrRgpS3omi8VisXeIrGA2m+Xt7a2IyGimasR986k9yN4RHkjUH3PsHQEAYEdms1n+ft6KjjZGPZRWn9Wd8r2c3PLYO45VUnysdoxpYZjzlIbWFwAAAMCAaH0BAACATdH6kjmMqAMAAAAGRKEOAAAAGBCtLwAAALApbniUOYyoAwAAAAZEoQ4AAAAYEK0vAAAAsClmfckcRtQBAAAAA6JQBwAAAAyI1hcAAADYFLO+ZA4j6gAAAIABUagDAAAABkTrCwAAAGyKWV8yJ8cX6ubribI4Jdo7xn3x9nC2d4RcL+qPOfaOgGzOp/k0e0d4IFE/BNk7AgDkWrS+AAAAAAZEoQ4AAACbMunfmV8MsdzHMZw/f15du3aVn5+f3N3dVblyZe3atcu63WKxaNy4cSpUqJDc3d3VtGlTHT9+/J7eg0IdAAAAuAdRUVF67LHH5OzsrI0bN+rQoUOaPn26fHx8rPu8++67mjVrlubPn6+dO3cqT548at68ueLj4zP9Pjm+Rx0AAAB4mN555x0FBgZq8eLF1nUlS5a0fmyxWPThhx9qzJgxatu2rSRp2bJl8vf317p169SpU6dMvQ8j6gAAALApB5PJcIskmc3mDEtCQsJt83/99deqVauWnn/+eRUsWFDVq1fXwoULrdtPnz6t8PBwNW3a1LrO29tbderU0fbt2zN/nu7z/AIAAAA5SmBgoLy9va3LtGm3n7nr1KlTmjdvnsqUKaMffvhB/fv316uvvqqlS5dKksLDwyVJ/v7+GZ7n7+9v3ZYZtL4AAAAAksLCwuTl5WV97Orqetv9UlJSVKtWLU2dOlWSVL16dR08eFDz589Xt27dHloeRtQBAABgU3af5eU2iyR5eXllWO5UqBcqVEgVK1bMsK5ChQo6e/asJCkgIECSFBERkWGfiIgI67bMoFAHAAAA7sFjjz2mo0ePZlh37NgxFS9eXFLqhaUBAQHatGmTdbvZbNbOnTtVr169TL8PrS8AAACwKZPJJFPaMLYB3GuW1157TfXr19fUqVPVsWNH/f7771qwYIEWLFhgfb2hQ4dqypQpKlOmjEqWLKmxY8eqcOHCateuXabfh0IdAAAAuAe1a9fW2rVrFRQUpEmTJqlkyZL68MMP1aVLF+s+I0aMUGxsrPr06aOrV6+qQYMG+v777+Xm5pbp96FQBwAAAO5RmzZt1KZNmztuN5lMmjRpkiZNmnTf70Ghfh+iomPVedhc6+P4+ESdvRip3esmKZ9XHjsmA5CTNatdSuN7NJSLs6Pi4hM1aMb3OnDqkgrk89CikU+rVOF8SkhM1pCZP2jbgTB7xwWAO3IwpS5GYaQs6VGo3wcf7zza+PFw6+MFX/yinftOUKQDyDL58rpp8ahn1GzoZzocelmPVS6qxaOeUa1eizS5V2P9fvi82gatVM1yhbRyYnuV7zJPSckp9o4NAHgAzPryEKzcsEMdW9e1dwwAOVipwvl0xRynw6GXJUnbDpxTYEEvVSvjrw6NK2jRN3slSbuPXtTFyBg9XrWYPeMCAB4CCvUHtPvgaUXHxKlJvYr/vTMA3KcT56Pk6+WuuhWLSJJa13tEXnlcVSIgn5wdHRQRFWvdNzQ8WoEFve70UgBgf6Z/Z34xwiJaX3KmlRt2qsNTteTk5GjvKAByMHNsgjpPXKNJvRorj7uzfj90QYfO/K087i72jgYAyCIU6g8g9nqCNvyyT+s/es3eUQDkAlv2ndVT+z6XJLk4O+rMqsHafvCckpJT5O+TxzqqXjzAW2GXzPaMCgB4CGh9eQDf/rJXFR4prEeK+9s7CoBcIMD33wvWg7o+ps17Q3XqQpTWbDmiXk9XlyTVLFdIhfN76tf9Z+0VEwD+k8lkvMWIDFmoN27c+I49ROvWrbN3PKuVG3aqY6s69o4BIJcY272h9i3uo4PL+qmYv7f6vf+dJGnMwl9Ut1JRHVjaVwtGtFaPaV8z4wsA5ACGbn1xcXFR9erVM6zz9fW1U5pbrZk7xN4RAOQiAz/YeNv1l6Ku6+mRX9g4DQAgqxm6UC9UqJB27Nhh7xgAAAB4iEz//DMKI2VJz9CF+r1ISEhQQkKC9bHZzIVUAAAAyL4M2aOeJjQ09NZ5Lu9g2rRp8vb2ti6BgYE2TAoAAAA8XIYeUb9dj/qdBAUFadiwYdbHZrP5nor1qOhYdR421/o4Pj5RZy9Gave6Scrn9e9MC0dOXtC4D1fr8tUYOTk6qGr5Ypr8Wge5uboo+tp19R2zWFHRsapdpZSmDHtOkhR5NUYDxi/RZ9P7y5n51gGk06x2KY3v0VAuzo6Ki0/UoBnf68CpS/poeGvVe7So4hISFRuXqOFzf9Luoxdv+xpdnqqsoc//n5JTLLJYLJrwyRb98PtJOTk6aPn4Z1U8wFunL1xVl0lrlZxikauzo759t5OeH7taV2PibXzEACA5mFIXozBSlvQMXajfS4+6q6urXF1d7/u9fLzzaOPHw62PF3zxi3buO5GhSE99H2dNHNpBFUoXVnJyil6d/KnmLf9Zr/VooXU/7la96o9oSPfmenFosI6euqhypQppypx1GtmnDUU6gAzy5XXT4lHPqNnQz3Q49LIeq1xUi0c9o1q9FunrrUc1YPp3Sk6xqGXdR/T5uHYq32XeLa/h4+mmDwY1U5VuHykiKlb1Hy2qFRPaq/hzs9SsdildMcep47jVmv9GKz31f6W1cccJBb30mOav202RDgAGZ+jWF3tauWGHOraue8v6kkULqELpwpIkx39G1M+FX5EkOTk5Ki7hhlJSUnQjMUnOzo4K2XlY3p4eqlGphC3jA8gGShXOpyvmOB0OvSxJ2nbgnAILeqlaGX9t2H5CySkWSdLvh86rcH5POd5myMfBZJLJJOX1SL1DqXdeN52/fE2SlJiULA83Z0mSh5uzbiQm69FSBVQu0E+rNx+xxSECAB6AoQv1ixcvqm7duhmWlStXZvn77j54WtExcWpSr+Jd97sel6AvNuxQs8celSQ926ymQs9fVqte0/VYzbIKyO+t4E9/1Bu9W2V5ZgDZz4nzUfL1clfdikUkSa3rPSKvPK4q7u+dYb+B7Wvr+50nrYV7epHmOL364Q/aPr+Hji4foPlvtFKfd7+VJG3afVrXrt/QzgWvKDo2QSF7z+idfk30RvBPWX9wAHAXd7pfjj0XIzJ068uNGze0c+fODOsuXrx9j+bDtHLDTnV4qpac7tKqciMxSYMmLlPDWuXUomEVSZKHu6vmTeph3WfSnLXq17mJzpy7rLmfpf5gHPRyM1V8pEjWHgCAbMEcm6DOE9doUq/GyuPurN8PXdChM39nuFlRp6aV1KFxeTV77bPbvoZXHlcNbF9Ljw9cqqNnI9Wq3iNaObGDqvVYoMSklAxzrw9qX1vfbDsuR0cHLRn1jFydHTV//R5t3hea5ccKALh3hizUQ0JC7PbesdcTtOGXfVr/0Wt33CcxKVmDJixTQV8vjX/12dvus+9wqCKjYtSkfiU9P2iWPhjdVZJFr09boS9nDcqi9ACymy37zuqpfZ9LklycHXVm1WAdDo2UJD3XuIJGv9RArYav0KWo67d9fpOaJXQ1JkFHz6Y+57vtJzT/jdYq5u+tk+ejrPsVK+il5nVK65k3v9CikU/r4w37tPdYuDbPeVk1ey7K4qMEANwPQ7e+2MO3v+xVhUcK65Hi/rfdnpSUrMETlymfl4emDe942z+VJCYl6+3532rMwHaSpOvxN2Qypf6Z53pcwi37A8i9Anz/vWA9qOtj2rw3VKcuRKlDo/Ia36OhWg9fobBLd74vxOmLV1WldEH5+6S+Tp2KReTkaNK5m57z/qBmGjH3J1ksUh43Z1ksFqVYLMrzTw87ANhSal1krMWIDDmibk8rN+xUpzYZLyL94OONKpjfS13bPqZvf9mn77f8qfKlC6tVr/clSbUeLanJrz1n3X/Bip/VvnktFfD1lCQNe6WleoxcIEka1f8ZGx0JgOxgbPeGeqxyoJwcHbTz0Hn1e/87SdLiUc8o4kqsvpz87/eWVsNX6Io5Tr3aVFeh/Hk1ecmv2nc8Qu8u/00bp3dWYlKykpJT1HXyOiUkJluf98KTFfXnyUvWi1bfX7Fdwa+3lIuTo6Z9ts22BwwAyDSTxWK59eqkHMBsNsvb21vHwy7L08vL3nHui7cHI11AdufTfJq9IzyQqB+C7B0BwAMwm83y9/NWdHS0vAxQD6XVZ61m/SJn97z2jmOVGBej7159wjDnKQ0j6gAAALApB5NJDgbqNzFSlvToUQcAAAAMiEIdAAAAMCBaXwAAAGBTRptpxUhZ0mNEHQAAADAgCnUAAADAgGh9AQAAgE2ZTKbb3jTSXoyUJT1G1AEAAAADolAHAAAADIjWFwAAANgUs75kDiPqAAAAgAFRqAMAAAAGROsLAAAAbMrBZJKDgfpNjJQlPUbUAQAAAAOiUAcAAAAMKMe3vnh5OMvLw9neMQDcJ5/ag+wd4YFE/THH3hEAwHBM/yxGYaQs6TGiDgAAABgQhToAAABgQDm+9QUAAADGYjKZZDLQTCtGypIeI+oAAACAAVGoAwAAAAZE6wsAAABsysGUuhiFkbKkx4g6AAAAYEAU6gAAAIAB0foCAAAAm2LWl8xhRB0AAAAwIAp1AAAAwIBofQEAAIDNGbTbxFAo1AHkGs3qV9D4gU/LxclRcfE3NOitL3Tg2HltWfaGXFxSvx06OTqo0iOFVbvjVB08fsHOiQEAuRmFOoBcIZ+nuxa/1V3Nes7Q4VPheqx6aS1+q5tqPT9VDV9+37rfs02raVSfVhTpAAC7o0cdQK5QKrCArkTH6vCpcEnStr0nFRjgo2rli2bYr1u7elq67jd7RASAXCNt1hcjLUZEoQ4gVzhx9pJ8vfOobtWSkqTWjSrLK6+7ihf2s+5T1D+fHq9RRiu++8NeMQEAsKL1BUCuYI6JV+fhizRp8DPK4+6q3/88rUMnLyopOcW6T9dn6mrjrwcVeTXWjkkBAEhFoQ4g19iy67ie6jVTkuTi7KQzP03V4VMXrdtffqauXp260l7xACDXcDClLkZhpCzpGbL1pXHjxnfsH1q3bp294wHIpgLye1k/DurdQpv/OKZTYZclSY3/r6ycHB20accRe8UDACADQ4+ou7i4qHr16hnW+fr62ikNgOxubP/Weqx6aTk5Omrnn6fVb8Ln1m3d29XXsq93yGKx2DEhAAD/MnShXqhQIe3YscPeMQDkEAMnr7jjtu6jltguCADkckabacVIWdIzZOsLAAAAkNsZekQ9NDT0lt9w7vRn6YSEBCUkJFgfm83mLM0GAAAAZCVDF+q361G/k2nTpmnixIlZnAiAvU0f8ZxaN6qs4oX9VOeFafrz2HlJUuliBbRo0kvyy5dX5pg49R73qfXmRnfbdrNu7erpjR7N5GAyKeSPYxoybaWSklJUo2IxzR3XWS7Ojpq+5Cd9/s1OSVKj2mX13FM1NPitL2xzAgAgBzD9sxiFkbKkZ+jWl7Qe9fTLnQQFBSk6Otq6hIWF2TApAFtZ89NeNekxQ6EXIjOsnzO6kz5evU1V2k3S9CU/auGklzK1Lb3ihf00fkAbNX1lhio9M1EF/bzUs30DSdIbPZrp9XdXqUGX9zS6T0tJkpurs8b0a6UxM9dn0dECAHIzQxfq98LV1VVeXl4ZFgA5z7Y9J3X+0tUM6wr45FWNisWsdxRd+9M+FfH3UanA/HfddrP2Tavp280HFBF5TZK06Ktf1bFFTUlSYlKyPNxc5ObqrOSU1JskjenbSsHLQxQdE5dVhwsAyMUM3foCAJlRNMBH4ZfNSk53l9Fz4VcUGOArc0zcHbelzaGeJrCQr85evGJ9HHrhigIDfCRJUxds1JwxL8rDzUWjZqxTlbJFVLKon8bMYjQdAO6Vg8kkBwPNtGKkLOlRqANAJhw9HaFmPT+UJDk4mPTt3EHqOXaZOraoqWebVpc5Jl4jp6/W1WuMrgMAHo6H1vqSmJj4sF5KISEhslgsOnPmzEN7TQA517nwKAXk95Kj47/f0ooG+Cos/Mpdt90s7OIVFSv0703Vihf2VVh41C37De7yhNb8tFdXr13Xm71bqOvIT7R1zwkN6vLEQz4yAEBudt+FelJSkt577z1VrVpVrq6ucnd3V3x8vHr27KlXXnmFizkB2MzfUTHad+ScXmxVW5L0bNNqOn/pqk6FXb7rtput3bRPbRpVlr+fpySp13OPa9UPuzPsU7ywn56sU16LvtoqZydHOTk6ymKxKMViUV4P1yw+UgDIGUwm4y1GdF+tL/Hx8WrRooV+/fVXSalzm5tMJrm5uSk0NFS//PKLKlasqDfeeOOhhgWA2aM7qeXjleTv56Wv5w5UTGyCHm07UYOmrNDCSS9pRM/mMsfGq+/4z6zPudu2ueM6a8PmA9qw+YDOnI/U5Hkb9PPiYZKkLbuPa9HqrRne//0Rz2n4+6slSeaYeK3cuEu7Vo1S7PUEdR252AZnAACQW5gsd7qD0F1MmjRJEyZMyPhCJpOSk5P1zjvvKCgoSI8//rg2b978sHLeM7PZLG9vb0VERjMDDJCN+dQeZO8IDyTqjzn2jgAgFzObzfL381Z0tDHqobT67OXF2+XikdfecaxuXI/Rsh71DHOe0txX68vy5ctlMpnUpk0bffPNNxm2PfLII5Kk06dPP3g6AAAA5Dgmk8lwixHdV+tL2kWegwcPloeHR4Zt+fLlkyRdunTpgYIBAAAAudl9jainFecXLly4Zduff/4pSYb6swEAAACQ3dxXoV6zZk1ZLBaNHj1a33//vXX9smXLNHnyZJlMJtWuXfuhhQQAAEDOYe8ZXrLLrC/3VagPGpR6cdfFixc1depUa19Pjx49dPXq1Qz7AAAAALh391Wot23bVmPGjJHFYrllkaSxY8eqZcuWDzUoAAAAkJvc18WkUuoUjc8884w+//xzHTt2TJJUtmxZde7cmbYXAAAA3JGDySQHA/WbGClLevddqEtSrVq1VKtWrYeVBQAAAMA/7qtQP3v2bKb2K1as2P28PAAAAJDr3VehXqJEif+cGN5kMikpKem+QgEAACDnMtpMK0bKkt59t76kXTgKAAAA4OG7r0K9YcOGt4yoX758WUeOHFFKSoqKFi2q0qVLP5SAAAAAQG50X4V6SEjIbdefOXNGrVq10vnz5/Xhhx8+QCwAAADkVCaT6T/bqG3JSFnSu6951O+kRIkSGjBggK5du6Y33njjYb40AAAAkKs81EI9OTlZW7ZskST99ttvD/OlAQAAgFzlvlpfSpUqdcu65ORkRUZGKi4uTpLk6en5YMkekhtJKbqRlGLvGPfFxemh/h4FZEtRf8yxd4QH4tNghL0jPJCore/aOwKAHMhBD3m0+AEZKUt691Wonzlz5ra9POlngunZs+f9pwIAAAByuYc6PaO3t7ceeeQR9enTR7169XqgYAAAAEBudl+FekpK9mwlAQAAgP0x60vm3HOhfv36dQ0aNEgmk0lt27bVM888kxW5AAAAgFztngt1Dw8PffHFF0pISFDHjh2zIhMAAACQ693XRa5Vq1aVJF25cuWhhgEAAEDOZzJJDgZaDNr5cn+F+rvvvitXV1dNmDBBJ06ceNiZAAAAgFzvvi4mHT9+vHx9fXX8+HFVqFBBZcqUkb+/f4ZGfJPJpE2bNj20oAAAAEBukulCPe2Oo9WqVVNISIj1at3k5GQdPXpUR48ete5rsVgMe/UsAAAA7Cut5cQojJQlvUwX6o0bN5aDg4O1YE8/j/rt5lQHAAAAcP/uqfUlrSA/ffp0loQBAAAAkOq+etSLFy/+sHMAAAAgl+CGR5lzz4X63r17lZSUlKl9GzZseM+BsouOQ4J1KfKaHBxMyuvhqrde66DK5QLtHQtADtasblmN79tCLs6Oiou/oUFvr9GBExet2xvVLK0Ns3rrzVnfas7KrXZMCgB4GO65UH/11VcztZ/JZMp0QZ8dLZzSQ96eHpKk70L269Upn+uXT9+0cyoAOVU+T3ctnviimvWbr8OnI/RY1RJaPPFF1erygSTJK4+bpgxoqe+3H7FzUgDAw3LP86hbLJZMLzlZWpEuSebYeMP+yQRAzlCqiJ+uRF/X4dMRkqRt+88oMCCfqpUrIkma8UZbvb3kZ12Jvm7PmACQKfa+wdHtFiO65xH1gIAAubq6ZkWWbGfQxE+1bc9xSdLn0/vZOQ2AnOxE2GX5enuobuXi2nEgVK0fryivPG4qXshHJQv7KiXFog2/HlLbxo/aOyoA4CG550L9q6++Uv369bMiS7YzZ/xLkqSVG3ZqytyvtfwDinUAWcMcG6/OQZ9pUv+WyuPhot8PhOrQqXDlcXfRqy82VPMB8+0dEQDwkN3XrC/I6IXWdTTi3S91JTpWvt557B0HQA61Zc9JPTXgpCTJxdlRZzaMlY+nuwLye2rnp0MlSX7eedS6QUXl98mjCfN/sGNaALgzkyl1MQojZUnPkIV6fHy85s2bp1WrVunQoUOKi4uTv7+/ypYtq1atWmnYsGF2zRd97bri4hMVUMBbkvTd5j/l4+0hHy+P/3gmANy/AD9PhUdekyQFvdJUm3efVPCX2xT85TbrPgvGdtSfxy4w6wsA5ACZLtSLFSsmk8kkNze3rMyjyMhINWnSRPv375ckeXh4qGzZsrp27Zo2b96sTZs22b1QN8fEq9foTxSfkCgHB5P88uXVZ+/35YJSAFlqbJ+n9FjVknJydNDOg6Hq99Yqe0cCAGShTBfqZ86cycIY/xo0aJC1SB8yZIjefvtt6y8H0dHRWrt2rU1y3E1gIV/98Mkb9o4BIJcZOG31f+7TZ/KXNkgCAA/GwWSSg4EGOI2UJT1Dtb5cvXpVq1aljhBVrVpVH3zwgRwc/p1B0tvbW927d7dTOgAAAMB27nke9ax07NgxJScnS5Ief/xxa5Herl07661mTSaTlixZcstzExISZDabMywAAABAdmWoQj299CPp5cqVU9WqVe+6/7Rp0+Tt7W1dAgMDszoiAAAA7oODARcjMlTrS7ly5eTo6Kjk5GT99ttv1vXvvPOOevTooQoVKtzxuUFBQRkuMjWbzfdcrHccEqxLkdfk4GBSXg9XvfVaB1Uul/E1zl6M1JDJn+vAsXMqVthPPy8bad227/BZDZu2QomJSRrUtaleaF1HkvTrrmNa/9Mevf9mp3vKAyDna1a3rMb3bSEXZ0fFxd/QoLfX6MCJi5Kk0b2a6YWnqinhRpIio6+rxcCPbvsar3VppC6tasrBwaTjoX+rz5QvFR0Tr3ye7vri7Zfl5+2hbftPa+h76yRJ+fPl0edTu6r14IVKSk6x1aECAO6RoX6B8Pb2VseOHSVJu3bt0vjx462tMP/F1dVVXl5eGZZ7tXBKD4V89qZ+XjZS/To9oVenfH7LPp4ebnqzb2vNm9jtlm2zP/1Rb73WQd9/8obe/+R7SVJc/A29//FGjR34zD3nAZCz5fN01+KJL6r3pJX6v64zNGr2Bi2e+KIkaWDHx1T5kQDV7PyBanedoW5jb/1+JElP/l8ZvdSmlhr3DlaNF6drz9FzmtCvhSSpU/Pq2rz7pGp3naFyxQuqYil/SdI7Q9pobPBGinQAMDhDFeqSNHv2bFWpUkWSNGnSJPn6+qp69epq3Lhxlr+3t+e/86CbY+NvO92ij3ce1alaWh7uLrdsc3JKHRFLuJEkx39ad97/eKN6d2yU4bUBQJJKFfHTlejrOnw6QpK0bf8ZBQbkU7VyRfRa10YaE7xRiUmpgxURV2Ju+xpVHimk3/afUcz1BEnSD78dVeeWNSRJiUnJ8nBzlslkkquLk24kJqtZ3bK6ei1Ov/911gZHCAC3l3bDIyMtRmS4Qt3Pz087duzQO++8o5o1ayolJUVHjhyRu7u7mjdvrvnz56tdu3ZZ9v6DJn6q6m3H6Z0FGzRn3Ev39NzXX2mhmct+1AtDgjVuUFsdPHZOoecj1eaJalkTFkC2diLssny9PVS3cnFJUuvHK8orj5sqlvJXQV9PPd2wkrZ8PEhbPh6k55re/jqdPUfO68naj8jfN6+k1FF0rzxu8vFy14rv96h0UT/tWDZEP/9+XBf+jtbI7k00njuWAkC2YKge9TTu7u4aMWKERowYYfP3njM+tThfuWGnpsz9Wss/6Jfp55YtEaD184ZIkpKTU9RxyFwFj39Ja/63W9/+sk+eedw08dVnlY87mAJQ6l/uOgd9pkn9WyqPh4t+PxCqQ6fCJUnOTo5yc3VWw55zVKyQj0IWDNTRM5es/etptuw5qQ+Xb9Hq6a8oJSVFX4cclCQlJaXoenyiOo/6zLrvu0Oe1vRPQ1S6qJ9GdHtSkvT24k23vCYAZDUHGWwedRknS3qGLNSN4IXWdTTi3S91JTpWvt557vn5C1aG6Jknq8nL010zFn+vXz59U6u+/0MLVoZoRO9WWZAYQHa0Zc9JPTXgpCTJxdlRZzaM1Y4DoboWm6AV3++RJJ29GKXtf55RzYqBty2qF6zergWrt0uS/q9SMZ2LuKpr/7TCpKlVMVAFfPNq47bD+ml+f70y8QuZJC0c+4KeGjA/aw8SAHBfDNf6Yi/R164r/O9o6+PvNv8pH28P+dzH6HfohUht/v2IXn72MSUlJSspOUWmf+7AFRuX8N8vACDXCPDztH4c9EpTbd59UqfORerLH/fpqXrlJEk+Xu6qVTFQB+8w8p32Gu6uzhrb5yl98FlIhu1Ojg6aMrCVRs78RpJSr7GxWGSxWJTH49brbQAAxsCI+j/MMfHqNfoTxSckysHBJL98efXZ+31lMpn02tTlav54ZbV4vLKux99Q/Y6TdSMxSeaYeFV7Zqyea1FbYwb8O6vLmBmrNXloB5lMJnnldVf7p2qqcddp8nB31YIpPex4lACMZmyfp/RY1ZJycnTQzoOh6vdW6t2Zx83dqI/GdlSf9vUkSdM/C9GuQ2Gpz+n9lC5eNmvR2h2SpG9m9pKDg0kuzk5avnGP5q36LcN7vNa1kT7/brcu/XNB6uQF/9PaD16RJI2a/Z1NjhMA0jPaBZxGypKeyWKxWOwdIiuYzWZ5e3srLCLqvqZqNAIXJ/7gAWR3Pg1sf63NwxS19V17RwDwAMxms/z9vBUdHW2IeiitPhuxeo9c8+S1dxyrhNgYvduhhmHOUxoqQQAAAMCAaH0BAACATTmYUhejMFKW9BhRBwAAAAyIQh0AAAAwIFpfAAAAYFMmkwx1wyMDRcmAEXUAAADAgCjUAQAAAAOi9QUAAAA2xQ2PMocRdQAAAMCAKNQBAAAAA6L1BQAAADbFDY8yhxF1AAAAwIAo1AEAAAADovUFAAAANmX6559RGClLejm+UHdxcpCLE384AGAfUVvftXcEZHM+dYbYO8IDido5094RgGyLChYAAAAwoBw/og4AAABjYdaXzGFEHQAAADAgCnUAAADAgGh9AQAAgE3R+pI5jKgDAAAABkShDgAAABgQrS8AAACwKZPJJJPJOP0mRsqSHiPqAAAAgAFRqAMAAAAGROsLAAAAbIpZXzKHEXUAAADAgBhRBwAgl2hWr7zGD2gtF2cnxcXf0KC3VurA8QuSpNF9WuiFFjWVkJikyKuxatF3jp3TAmBEHQCAXCCfp7sWT3lZvcd/rv/r9I5Gfbhei6e8LEka+GIjVS5TWDU7vq3aL7yjbqOW2jktcjqTyXjLg3j77bdlMpk0dOhQ67r4+HgNHDhQfn5+yps3rzp06KCIiIh7el0KdQAAcoFSRfPrSnSsDp8KlyRt23dKgQE+qla+qF576UmNmf2NEpOSJUkRkdfsGRXIVv744w999NFHqlKlSob1r732mr755hutWrVKmzdv1oULF9S+fft7em0KdQAAcoETYX/L1zuP6lYpIUlq3fBReeV1U8XShVTQz1NPN6qsLUtf05alr+m5ZtXtGxbIJmJiYtSlSxctXLhQPj4+1vXR0dH6+OOP9cEHH+jJJ59UzZo1tXjxYv3222/asWNHpl+fHnUAAHIBc0y8Oo/8RJMGPa08Hq76/c/TOnTyoiTJ2clRbm7OaththooV8lXI4qE6eibC2r8OPGwOJpMcDHSTobQsZrM5w3pXV1e5urre8XkDBw5U69at1bRpU02ZMsW6fvfu3UpMTFTTpk2t68qXL69ixYpp+/btqlu3bqZyUagDAJBLbNl1Qk/tmi1JcnF21Jn/TdGO/ad1LTZeK77bJUk6e/GKtu8/pZqVilGoI9cJDAzM8Hj8+PGaMGHCbff94osvtGfPHv3xxx+3bAsPD5eLi4vy5cuXYb2/v7/Cw8MznYdCHQCAXCIgv5fCL6eOGAb1aq7NfxzXqXOX9eUPe/RU/QpasGqrfLw8VKtScc1Y9rOd0wK2FxYWJi8vL+vjO42mh4WFaciQIfrxxx/l5uaWZXkM1aPeuHFjmUwmlShRIsP6kJAQmUwmmUwmLVmyxC7ZAADI7sb2a6l9q0fp4LoxKlbIV/0mrZAkjZvzjZrVK69dK9/Ujwtf1fSlm7Trr7N2ToucLO2GR0ZaJMnLyyvDcqdCfffu3bp06ZJq1KghJycnOTk5afPmzZo1a5acnJzk7++vGzdu6OrVqxmeFxERoYCAgEyfJ0bUAQDIJQZOWXnb9Veir+v5YYtsnAbIvpo0aaIDBw5kWNejRw+VL19eI0eOVGBgoJydnbVp0yZ16NBBknT06FGdPXtW9erVy/T7UKgDAAAA98DT01OPPvpohnV58uSRn5+fdX3Pnj01bNgw+fr6ysvLS4MHD1a9evUyfSGplIMK9YSEBCUkJFgf33zVLgAAAAziIdxk6KHKgiwzZsyQg4ODOnTooISEBDVv3lxz5869p9cwZKEeGhoq0z3+35s2bZomTpyYRYkAAACAOwsJCcnw2M3NTcHBwQoODr7v1zTUxaRpXFxcVKdOHetSoUKF/3xOUFCQoqOjrUtYWJgNkgIAYFvTh7fXkW/GKW73TFUpW8S6vnRgAf3yyVD9uWa0ti57XRVKBWRq2826ta2rA2vH6K/1YxU85gU5OaWWCjUqBGrH8uHasypIXdrUtu7fqHYZzR7VMQuOFIAhC/VChQppx44d1iUzfyZwdXW95UpdAABymjU/7VeTnjMVeiEyw/o5ozvq47W/qUr7tzR96U9aOKFLpralV7ywr8b3b6WmvWaqUtvJKujrqZ7P1pckvdG9qV5/b40avDRdo3u3kCS5uTprTJ8WGjPrmyw6WuRUDjIZbjEiQxbqAADg9rbtPanzl6IzrCvgk1c1KhSz3rRo7ab9KuKfT6WK5r/rtpu1b1JN324+qIjIa5KkRat/U8cWNSVJiUnJ8nBzlpurk5JTLJKkMX1aKHjFFkXHxGXZ8QK5mSF71AEAQOYV9c+n8MvRSk5Osa47Fx6lwEI+Ml+Lu+O2U+cuZ3idwAAfnQ2/Yn0ceiFSgQE+kqSpC3/QnNEd5eHuqlEz16tK2SIqWdRPY2Yzmg5kFQp1AADwn46eiVCz3rMlSQ4OJn0bPEA9x36qjs1r6Nkm1WSOjdfID9bq6jVG1/HfTAab9cVIWdIzVKF+89WyaRo3biyLxWLbMAAAZBPnIq4qIL+3HB0drCPnRQN8FHYxStdi4++47WZh4VEqma4lpnhhP4WF37rf4M6NteanfboaE6c3ezVX7U7vqHOr2hrUubGmfLQxi44SyH3oUQcAIJv7OypG+46E6cVWtSRJzzapqvOXrurUuct33XaztT/vV5tGj8rfz1OS1KtDfa36YU+GfYoX9tWTdcpp0eptcnZylJOjgywWi1IsKcrrcfvbrQO4P4YaUQcAAHc3e1RHtWxQSf5+nvp6Tn/FXI/Xo+2maNDUL7VwQmeN6NFM5th49Z243Pqcu22bO7aTNmw+qA1bDurM+UhN/mijfv5kqCRpy64TWrRmW4b3f/+N9ho+fY0kyRwTr5Xf79aulW8q9nqCugYtyfLjR87gYEpdjMJIWdIzWXJoT4nZbJa3t7ciIqOZqhEAkG351Bli7wgPJGrnTHtHyNXMZrP8/bwVHW2MeiitPvvgxz/lnsfT3nGs4mKvaVizKoY5T2lofQEAAAAMiNYXAAAA2JSDySQHA021YqQs6TGiDgAAABgQhToAAABgQLS+AAAAwKa44VHmMKIOAAAAGBCFOgAAAGBAtL4AAADAphxksFlfZJws6TGiDgAAABgQhToAAABgQLS+AAAAwKaY9SVzGFEHAAAADIhCHQAAADAgWl8AAABgUw4y1mixkbKkZ9RcAAAAQK7GiDoAIEfzqTPE3hEeSNTOmfaOAMBOKNQBAABgUyaTSSYDTbVipCzp0foCAAAAGBCFOgAAAGBAtL4AAADApkz/LEZhpCzpMaIOAAAAGBCFOgAAAGBAtL4AAADAphxMJjkYaKYVI2VJjxF1AAAAwIAo1AEAAAADovUFAAAANmfMZhNjYUQdAAAAMCAKdQAAAMCAaH0BACCTmtUrr/EDWsvF2Ulx8Tc06K2VOnD8giRpdJ8WeqFFTSUkJinyaqxa9J1j57SAcZlMqYtRGClLehTqAABkQj5Pdy2e8rKa9Z6lw6fC9Vi1Ulo85WXVeuFtDXyxkSqXKayaHd9WYlKy/P087R0XQA5AoQ4AQCaUKppfV6JjdfhUuCRp275TCgzwUbXyRfXaS0+qRb85SkxKliRFRF6zZ1QAOQSFOgAAmXAi7G/5eudR3SoltOPPM2rd8FF55XVTxdKFVNDPU083qqxnm1aVJM36LERf/bjXzokB4zKZTDIZqN/ESFnSo1AHACATzDHx6jzyE00a9LTyeLjq9z9P69DJi5IkZydHubk5q2G3GSpWyFchi4fq6JkIa/86ANwPCnUAADJpy64TemrXbEmSi7OjzvxvinbsP61rsfFa8d0uSdLZi1e0ff8p1axUjEIdwAPJNtMzNm7cWCaTSSVKlLB3FABALhWQ38v6cVCv5tr8x3GdOndZX/6wR0/VryBJ8vHyUK1KxXWQIh24IwcDLkbEiDoAAJk0tl9LPVa9tJwcHbTzzzPqN2mFJGncnG/00fjO6vNcA0nS9KWbtOuvs/aMCiAHoFAHACCTBk5Zedv1V6Kv6/lhi2ycBkBOR6EOAAAAm2LWl8zJMYV6QkKCEhISrI/NZrMd0wAAAAAPxqi98/ds2rRp8vb2ti6BgYH2jgQAMKDpw9vryDfjFLd7pqqULWJdXzqwgH75ZKj+XDNaW5e9rgqlAjK17Wbd2tbVgbVj9Nf6sQoe84KcnFJ/1NaoEKgdy4drz6ogdWlT27p/o9plNHtUxyw4UgDZXY4p1IOCghQdHW1dwsLC7B0JAGBAa37aryY9Zyr0QmSG9XNGd9THa39TlfZvafrSn7RwQpdMbUuveGFfje/fSk17zVSltpNV0NdTPZ+tL0l6o3tTvf7eGjV4abpG924hSXJzddaYPi00ZtY3WXS0gDGZDLgYUY4p1F1dXeXl5ZVhAQDgZtv2ntT5S9EZ1hXwyasaFYpZ50Jfu2m/ivjnU6mi+e+67Wbtm1TTt5sPKiLymiRp0erf1LFFTUlSYlKyPNyc5ebqpOQUiyRpTJ8WCl6xRdExcVl2vACyrxzTow4AwP0q6p9P4ZejlZycYl13LjxKgYV8ZL4Wd8dtp85dzvA6gQE+Oht+xfo49EKkAgN8JElTF/6gOaM7ysPdVaNmrleVskVUsqifxsxmNB3A7VGoAwBgA0fPRKhZ79S7mjo4mPRt8AD1HPupOjavoWebVJM5Nl4jP1irq9cYXUfOx6wvmZNtWl9CQkJksVh05swZe0cBAOQw5yKuKiC/txwd//2xWDTAR2EXo+667WZh4VEqFuBrfVy8sJ/Cwm/db3Dnxlrz0z5djYnTm72aq2vQEm3dc1KDOjd+uAcGIFvLNoU6AABZ5e+oGO07EqYXW9WSJD3bpKrOX7qqU+cu33Xbzdb+vF9tGj0qfz9PSVKvDvW16oc9GfYpXthXT9Ypp0Wrt8nZyVFOjg6yWCxKsaQor4drFh8pgOyE1hcAQK4ye1RHtWxQSf5+nvp6Tn/FXI/Xo+2maNDUL7VwQmeN6NFM5th49Z243Pqcu22bO7aTNmw+qA1bDurM+UhN/mijfv5kqCRpy64TWrRmW4b3f/+N9ho+fY0kyRwTr5Xf79aulW8q9nqCugYtyfLjB4zAQcYaLTZSlvRMFovFYu8QWcFsNsvb21sRkdHMAAMAuZhPnSH2jvBAonbOtHcEZGNms1n+ft6KjjZGPZRWn3269ag88nraO47V9ZhreqlBOcOcpzRG/QUCAAAAyNVofQEAAIBNMetL5jCiDgAAABgQhToAAABgQLS+AAAAwKZM/yxGYaQs6TGiDgAAABgQhToAAABgQLS+AAAAwKZMptTFKIyUJT1G1AEAAAADolAHAAAADIjWFwAAANiUg0xyMNBcK0bKkh4j6gAAAIABUagDAAAABkTrCwAAAGyKWV8yhxF1AAAAwIAYUQcA5GhRO2faO8ID8akzxN4RHkh2P/+APVGoAwAAwKZM//wzCiNlSY/WFwAAAMCAGFEHAACATXExaeYwog4AAAAYEIU6AAAAYEC0vgAAAMCmTDLJwUAXcHIxKQAAAIBMo1AHAAAADIjWFwAAANgUs75kDiPqAAAAgAFRqAMAAAAGROsLAAAAbIrWl8yhUAcAIJdoVq+8xg9oLRdnJ8XF39Cgt1bqwPELkqTRfVrohRY1lZCYpMirsWrRd46d0wKgUAcAIBfI5+muxVNeVrPes3T4VLgeq1ZKi6e8rFovvK2BLzZS5TKFVbPj20pMSpa/n6e94wIQhToAALlCqaL5dSU6VodPhUuStu07pcAAH1UrX1SvvfSkWvSbo8SkZElSROQ1e0ZFLmD6559RGClLelxMCgBALnAi7G/5eudR3SolJEmtGz4qr7xuqli6kAr6eerpRpW1Zelr2rL0NT3XrLp9wwKQxIg6AAC5gjkmXp1HfqJJg55WHg9X/f7naR06eVGS5OzkKDc3ZzXsNkPFCvkqZPFQHT0TYe1fB2AfFOoAAOQSW3ad0FO7ZkuSXJwddeZ/U7Rj/2ldi43Xiu92SZLOXryi7ftPqWalYhTqyDIOptTFKIyUJb1s0frSuHFjmUwmlShRwt5RAADItgLye1k/DurVXJv/OK5T5y7ryx/26Kn6FSRJPl4eqlWpuA5SpAN2x4g6AAC5xNh+LfVY9dJycnTQzj/PqN+kFZKkcXO+0UfjO6vPcw0kSdOXbtKuv87aMyoAUagDAJBrDJyy8rbrr0Rf1/PDFtk4DXIzZn3JnGzR+gIAAADkNjlmRD0hIUEJCQnWx2az2Y5pAAAAgAeTY0bUp02bJm9vb+sSGBho70gAAAC4DZPJeIsR5ZhCPSgoSNHR0dYlLCzM3pEAAHjopg9vryPfjFPc7pmqUraIdX3pwAL65ZOh+nPNaG1d9roqlArI1LabdWtbVwfWjtFf68cqeMwLcnJKLRVqVAjUjuXDtWdVkLq0qW3dv1HtMpo9qmMWHCmAHFOou7q6ysvLK8MCAEBOs+an/WrSc6ZCL0RmWD9ndEd9vPY3VWn/lqYv/UkLJ3TJ1Lb0ihf21fj+rdS010xVajtZBX091fPZ+pKkN7o31evvrVGDl6ZrdO8WkiQ3V2eN6dNCY2Z9k0VHC+RuOaZQBwAgN9i296TOX4rOsK6AT17VqFDMetOitZv2q4h/PpUqmv+u227Wvkk1fbv5oCIir0mSFq3+TR1b1JQkJSYly8PNWW6uTkpOsUiSxvRpoeAVWxQdE5dlx4ucyaR/Z34xxj9jyhYXk8bExEhKHTUHAAAZFfXPp/DL0UpOTrGuOxcepcBCPjJfi7vjtlPnLmd4ncAAH50Nv2J9HHohUoEBPpKkqQt/0JzRHeXh7qpRM9erStkiKlnUT2NmM5oOZBVDF+pxcXH63//+p3379kmSypQpY99AAADkUkfPRKhZ79mSJAcHk74NHqCeYz9Vx+Y19GyTajLHxmvkB2t19Rqj68DDYujWl3r16qldu3ZKTk6WyWTSkCFD7B0JAADDORdxVQH5veXo+O+P9aIBPgq7GHXXbTcLC49SsQBf6+Pihf0UFn7rfoM7N9aan/bpakyc3uzVXF2DlmjrnpMa1Lnxwz0w5FgOJuMtRmToQt1kMsnT01MNGzbUN998o2bNmtk7EgAAhvN3VIz2HQnTi61qSZKebVJV5y9d1alzl++67WZrf96vNo0elb+fpySpV4f6WvXDngz7FC/sqyfrlNOi1dvk7OQoJ0cHWSwWpVhSlNeDFlXgYTJ068vevXvtHQEAAEOZPaqjWjaoJH8/T309p79irsfr0XZTNGjql1o4obNG9Ggmc2y8+k5cbn3O3bbNHdtJGzYf1IYtB3XmfKQmf7RRP38yVJK0ZdcJLVqzLcP7v/9Gew2fvkaSZI6J18rvd2vXyjcVez1BXYOWZPnxA7mJyWKxWOwdIiuYzWZ5e3srIjKaqRoBANmWT53s3fYZtXOmvSPkamazWf5+3oqONkY9lFafbdx9Rnny2j9PmtgYs1rWLGGY85TG0K0vAAAAQG5FoQ4AAAAYkKF71AEAAJDzmEypi1EYKUt6jKgDAAAABkShDgAAABgQrS8AAACwKdM/i1EYKUt6jKgDAAAABkShDgAAABgQrS8AAACwKQeZ5GCgqVYcDNr8wog6AAAAYEAU6gAAAIAB0foCAAAAm2LWl8xhRB0AAAAwIAp1AAAAwIBofQEAwMCids60d4QH4lN7kL0jPLCoP+bYO0LOQ+9LpjCiDgAAABgQhToAAABgQLS+AAAAwKZM//wzCiNlSY8RdQAAAMCAKNQBAAAAA6L1BQAAALZlkkxG6jYxUpZ0GFEHAAAADIhCHQAAADAgWl8AAABgU9zvKHMYUQcAAAAMiEIdAAAAMCBaXwAAAGBb9L5kCoU6AADIFprVr6DxA5+Wi5Oj4uJvaNBbX+jAsfPasuwNubikljROjg6q9Ehh1e44VQePX7BzYuDBUKgDAADDy+fprsVvdVeznjN0+FS4HqteWovf6qZaz09Vw5fft+73bNNqGtWnFUU6cgR61AEAgOGVCiygK9GxOnwqXJK0be9JBQb4qFr5ohn269aunpau+80eEXEPTAb8Z0QU6gAAwPBOnL0kX+88qlu1pCSpdaPK8srrruKF/az7FPXPp8drlNGK7/6wV0zgoaL1BQAAGJ45Jl6dhy/SpMHPKI+7q37/87QOnbyopOQU6z5dn6mrjb8eVOTVWDsmBR4eCnUAAJAtbNl1XE/1milJcnF20pmfpurwqYvW7S8/U1evTl1pr3i4ByZT6mIURsqSHq0vAAAgWwjI72X9OKh3C23+45hOhV2WJDX+v7JycnTQph1H7BUPeOgMO6LeuHFjbd68WcWLF9eZM2fsHQcAANjZ2P6t9Vj10nJydNTOP0+r34TPrdu6t6uvZV/vkMVisWNC4OEybKEOAACQ3sDJK+64rfuoJbYLggfG/Y4yh9YXAAAAwIByzIh6QkKCEhISrI/NZrMd0wAAAAAPJseMqE+bNk3e3t7WJTAw0N6RAAAAcDsmAy4GlGMK9aCgIEVHR1uXsLAwe0cCAAC3MX3EczqyYaLi9s5RlbJFrOtLFyugX5YM05/rxmnrZ8NVoVRAprbdrFu7ejqwfpz++nq8gse+KCen1HKnRsVi2vHFm9qzerS6PF3Hun+j2mU1e3SnLDhS4MHkmELd1dVVXl5eGRYAAGA8a37aqyY9Zij0QmSG9XNGd9LHq7epSrtJmr7kRy2c9FKmtqVXvLCfxg9oo6avzFClZyaqoJ+XerZvIEl6o0czvf7uKjXo8p5G92kpSXJzddaYfq00Zub6LDpa5ETTpk1T7dq15enpqYIFC6pdu3Y6evRohn3i4+M1cOBA+fn5KW/evOrQoYMiIiLu6X0MX6hbLBbFx8dnWJKTk+0dCwAA3Kdte07q/KWrGdYV8MmrGhWLacV3f0iS1v60T0X8fVQqMP9dt92sfdNq+nbzAUVEXpMkLfrqV3VsUVOSlJiULA83F7m5Ois5JfWOpmP6tlLw8hBFx8Rl1eHiNkwG/HcvNm/erIEDB2rHjh368ccflZiYqKeeekqxsf/eFfe1117TN998o1WrVmnz5s26cOGC2rdvf0/vY/iLSc+ePSt3d/cM62bMmKGhQ4faJxAAAHjoigb4KPyyWcnJKdZ158KvKDDAV+aYuDtuS7vhUZrAQr46e/GK9XHohSsKDPCRJE1dsFFzxrwoDzcXjZqxTlXKFlHJon4aM4vRdNyb77//PsPjJUuWqGDBgtq9e7caNmyo6Ohoffzxx1q+fLmefPJJSdLixYtVoUIF7dixQ3Xr1s3U+xi+UAcAAHgYjp6OULOeH0qSHBxM+nbuIPUcu0wdW9TUs02ryxwTr5HTV+vqNUbXc6ubZw10dXWVq6vrfz4vOjpakuTr6ytJ2r17txITE9W0aVPrPuXLl1exYsW0ffv2TBfqhm19CQkJkcViue3CaDoAADnLufAoBeT3kqPjv6VJ0QBfhYVfueu2m4VdvKJihXytj4sX9lVYeNQt+w3u8oTW/LRXV69d15u9W6jryE+0dc8JDeryxEM+MtyOyWS8RZICAwMzzCI4bdq0/zyWlJQUDR06VI899pgeffRRSVJ4eLhcXFyUL1++DPv6+/srPDw80+fJsIU6AADIPf6OitG+I+f0YqvakqRnm1bT+UtXdSrs8l233Wztpn1q06iy/P08JUm9nntcq37YnWGf4oX99GSd8lr01VY5OznKydFRFotFKRaL8nr89+gpcq6wsLAMswgGBQX953MGDhyogwcP6osvvnjoeWh9AQAANjV7dCe1fLyS/P289PXcgYqJTdCjbSdq0JQVWjjpJY3o2Vzm2Hj1Hf+Z9Tl32zZ3XGdt2HxAGzYf0JnzkZo8b4N+XjxMkrRl93EtWr01w/u/P+I5DX9/tSTJHBOvlRt3adeqUYq9nqCuIxfb4AzAqO515sBBgwbp22+/1ZYtW1S0aFHr+oCAAN24cUNXr17NMKoeERGhgIA7Ty16M5PFYrFkeu9sxGw2y9vbWxGR0UzVCACAnfjUHmTvCA8s6o859o5w38xms/z9vBUdbYx6KK0+23rwnPJ62j9PmphrZjV4tGimz5PFYtHgwYO1du1ahYSEqEyZMhm2R0dHq0CBAlqxYoU6dOggSTp69KjKly9/Tz3qjKgDAAAA92DgwIFavny51q9fL09PT2vfube3t9zd3eXt7a2ePXtq2LBh8vX1lZeXlwYPHqx69eplukiXKNQBAACAezJv3jxJUuPGjTOsX7x4sbp37y4pdTpxBwcHdejQQQkJCWrevLnmzp17T+9DoQ4AAADbMv2zGMU9ZslM57ibm5uCg4MVHBx8n6GY9QUAAAAwJAp1AAAAwIBofQEAAIBNmf75ZxRGypIeI+oAAACAAVGoAwAAAAZE6wsAAABsymRKXYzCSFnSY0QdAAAAMCAKdQAAAMCAaH0BAACATWXz+x3ZDCPqAAAAgAFRqAMAAAAGROsLAAAAbIvel0zJ8YV66N+xyhvvaO8Y96VkwTz2jgAgl0tKTrF3hAfm5Mgfj+0p6o859o7wwIr3W2XvCPct5cZ1e0fAA+C7FwAAAGBAOX5EHQAAAMZi+uefURgpS3qMqAMAAAAGRKEOAAAAGBCtLwAAALApkyl1MQojZUmPEXUAAADAgCjUAQAAAAOi9QUAAAA2xf2OMocRdQAAAMCAKNQBAAAAA6L1BQAAALZF70umMKIOAAAAGBAj6pnw7vz12rzzsC5eitKKWUNUrnRhSdKNxCR9sOhbbd9zTK7OzipTspDeGt7JzmkBwPjiExLVZ+wSHT0dLndXZ+X38dS7IzqqVGABe0cDsoxPHhd99Xoj62N3F0cVL5BHlYZ9rZIF8+qtTtXl4uwgV2dHfbHtjIK/P2rHtDACCvVMaNKgsro910ivDJ+fYf2sxRtlkknrFgyXyWTS5SvX7JQQALKfl9rVV9N6FWUymbRo1Ra9NnWF1s971d6xgCwTFXtDTSb9aH3c/6myql+ugK7GJur9l2rp3fUH9cP+i8qXx1nbJrfQj/sv6NjFnFlbmP75ZxRGypIerS+ZUPPRUvLPny/Durj4G1r/vz80sFtzmf65nVV+X087pAOA7MfN9f/bu/f4mO78j+PvM7lMkiYZxCVFNFFpUa103RvKbinpRfVG1bZFS7copVulLFF0225XiUtVW7eqS6ml1rq3iIqlKPbX2lZRUfcmchERMvP7I0yTlVaQzHxHX895nMcjc+Zc3id/zOOTbz7newLU5o5b3N+fDetFK/VwmpdTAZ71eIsYzU7eJ0lyyaXwkEBJUkigv/LOOZV+Ks+b8WAARtSvUOrhnxQeFqKp8z7Xv7/6TnZ7gJ59vI2axNXydjQA8DlT5q1Vuztv9XYMwGMa3hihciGBWrnzsCSp37QtmtEnXoM61FNEmF0vfbhVxzPPeDklvI1C/Qrl5zt1+Fi6ataorL7dErT7+x/Va+j7mj9pgCLKM7IOACX19vSV2nfwhD6ZwD0++O3o0jxGH6fsV77TJUnqm1Bbr32ySws3p+qGitfpHwNbacf+tGu39cUqWExhUpbCaH25QpGVyslms5TQ6nZJUu0bq6lqlQras/+Il5MBgO+Y+NEaLV27Q3Pf/pNCggK9HQfwiBC7n9o3qq45G/ZLkiqEBirh9mpauDlVkvTDiVPauvcnNa5V0YspYQLjCvW0tDQNGjRIderUUXBwsEJDQxUXF6fRo0crJyfH2/HcyjuuU+P6tZSy7VtJ0o9H0nToaJpioip7ORkA+IZ3Zn+mhSu3akFSbznCQrwdB/CYDo2i9H+pGdpzpGC0/OSpPOXk5at57YJZjyqEBup3MRHa/WOGN2PCAEa1vhw8eFDx8fE6cOCAJCk6Olp5eXnasWOHduzYoQULFmj9+vUKC/Nsa8mo8Z9ow5bd+ik9W72HfaCQYLs+fX+gXun9oF4dt6Bg9hebpSF9HlLlig6PZgMAX3ToWLqGJS1SdLUIdeg9XpJkD/DXiqkvejkZUPYebx6jWedvIpUkp0vqOTlFwx6tL3+bJX8/m6as/lZf7r12b7DmeUclY7lcLpe3Q1zQvn17LVmyRJI0Z84cPfZYQb/i66+/rsGDB0uSnn/+eSUlJV3yWJmZmXI4HNq8+5BCw8LLLnQZiql8nbcjAPiNO5fv9HaEq+bvZ9w/j+FjbvjTfG9HuGLOvByd+LCrMjIyFB7u/XroQn229dvDRtVn2VmZanDT9cb8ni4w5tsrPT1dS5culSS1atXKXaRL0sCBAxUTEyNJ+uijj2TQ3xYAAAC4XJaBi4GMKdS/++47OZ0FIzdxcXFFPrPZbLrtttskFfSwHz9+/KL9z5w5o8zMzCILAAAA4KuM6lG/wCpmjhyb7df/pvjrX/+qESNGXNZ53py8WOv+/Y0OH0vXnKR+uvnGqpKkvLPnNOb9fypl27eyBwQoNuZ6jX7p4mnDFq/aojmLv3C/P/ZThm6/JUZ/H/qkfjySpsFvzFZO7hkltLpdT3f6gyRp74GjSpq2TGOHd72srABgutwzZ9XzL9P1331HFGwPUMXyYXpzYEfVjKpUZLvsnDPqNvgD7dydqnP5Tn2/+g33Zz8c+kk9h07XqdNn9HDbhurf9W5J0rf7jujViZ9q1ls9PXpNQEncdWukBnWoJ5tlyd/P0sQV/9XHG39Qv3tqq+Md0apZOVTdJ23Usq8OFbt/nWrh+muX36limF35Tpe270vToI+2KfesU46QAE3rdYcqhNq16bvjGvTRdklSRGig3nuumTqOWa9z+XQaXKuMKdRr1aolm80mp9Op7du3F/nM6XRqx44dkqQKFSqoUqVKF+0/ePBgDRgwwP0+MzNTUVFRv3rOu5rfqqceaanuL00usj5p2jJZsrRoykuyLEsn0oqfw/SBNo30QJtG7veP9hqje35fMF3jx//cqI73NVNCq9v1yHN/12P3xyskOFBvvbdEQ3o/9Ku5AMBXPdHhDrVuVleWZen9+evV/7U5WvxO3yLbBPjb1PeJ1ioXHqIOvcYX+WzqgmR1f6SFHmnbUPGdX1OPR+/UdSF2DRm7UG+93MmTlwKU2MRnmuihv63V1wczFBURog2j2mnp1h+1/pujWrQ5VW93a/ir++eedeqV2dv19cEM2Sxpcs+m6pNQW299+rUeblJDG3Yf05h/fqNPXmyp2lXDtftQpkZ0itPoT3b5bJFunX+ZwqQshRnT+lKhQgXde++9kqS1a9dq7ty57s/efPNN7d27V5LUpUuXYkfc7Xa7wsPDiyyX0qBeTVWpWK7IutO5eVq8cot6P9XWfZ6KFS49y8yu3QeUdjJbdzapK0ny9/dT7pmzOpefL6fLJZvN0oJ/bVKz229StcgKlzweAPiaIHuA2txxi/u7s2G9aKUevnjWCntggFo0vEmO0OCLPvP3t+l0bp7OnsuX0+mSZbM0feEG/b5xbd1QNaLMrwG4Ei6XS+HBAZKksOAApWfnKe9cvrbvS9cPJ05dcv99x7L19cGCqRidLmn7vjRFRRRMKHE236UQu78sSwoMsCkv36nf31JFGTl52noNzwqDAsYU6pI0ceJE1ahRQ5LUuXNnxcTEqFq1au4ZX+Li4jRq1KgyzZB6+CeFh4Vo6rzP1aVfkroPfEf//mrPJfdbtHKL7v3D7xTg7ydJeqx9vD5L+Y+6vjhJTzx0p7JP5Wr1F7v0+APNyzQ/AJhiyry1anfnrZe1T4+OLbV03U4l9Bij3l3+oKzsXC35fIeefaxV2YQESsGz727S1F536Ms37tGnL/9efadu1tkrHOkOCfRTlxYxWv7Vj5KkTzb9oOhKoVozrI3Wf31UR9JP64V76+i1hf8pzUuAoYxpfZGkqKgobdu2TW+++aYWL16s/fv3u28k7dixo/r376+QkLJ9KEZ+vlOHj6WrZo3K6tstQbu//1G9hr6v+ZMGKKJ88SPrp3PztHL9Ds0Y09u9rlKFcE0a+Yz7/cDXZmnA0/fpy53fa/6/NikwwF99urZT1crly/R6AMAb3p6+UvsOntAnEy6+v+fXRFZ0aP64Xu733V+ZqhF9O2jD1u80beEG2QP9NfS5+xV1Pf+ZhBn8bJZeuK+Ouk/aqE3fnVBcdHnN7BOvVokrlZadd1nHCvCzNOXZplr39VEt217Qz56Tl69nJqe4t3m1U31NWP5fxVQOVb97a0uS3v7nN+4ReZ9hScU0SHiPSVkKMWpEXZIiIiL0xhtvaPfu3crNzVVOTo527NihIUOGlHmRLkmRlcrJZrOU0Kqg17z2jdVUtUoF7dl/5Bf3WZW8UzVvqKKaNaoU+/maL3ap+vURuvnGqnpj8mKN6N9RD7ZtrMmzVpbJNQCAN038aI2Wrt2huW//SSFBgVd8nCWffaXoahV1603VNfjvCzThL130xAPN9Pp7/yrFtMDVqRdVTpGOYG367oQk6av96TqUflr1apS7rOP4+1ma8mwzHc3I1ZA5XxW7ze0x5VUxzK5VOw9rdOc4vTp/p0Yu2KnRnW+/yquAqYwr1L2tvOM6Na5fSynbvpUk/XgkTYeOpikmqvIv7rNo1RZ1uLtRsZ9lZZ/W7MVfqOfjrSUVzIpgs1my2SzlnL68v7QBwHTvzP5MC1du1YKk3nKEXfngSkZWjqZ8vE4vPd1OknT6TJ4smyXLsnQq50xpxQWu2qH0HFUpF6TY6wv+6x5d+TpFVw7V90eKn4iiOH42S+/2bKqTp/L04sytxW7j72fpLw/fpuEfF0yuEWL3l8slOZ3SdUFGNUigFBn1ZNLSVJInk44a/4k2bNmtn9Kz5QgPUUiwXZ++P1AHD/+kV8ct0MnMHFk2Sz0736W74gv6LF8dt0Atm9RVy6YFN43uP3hcf3whSStmDtV1IfZiz3H3nfXVuH4tSdLC5f/WrH8kKyDAX8P7PaK6sdV/8Rp4MikAb7ucJ5MeOpau+u2HK7pahK4LCZIk2QP8tWLqi3p9ylJFVnSo60MF9+m07PK6TpzM1vG0LEVWDFfzBrGalPik+1gvvj5XHVr/Ti0a3iRJ+nDRRr0z53MFBvhp7JDHFVenRolz8WRSXK1LPZn0wcZR6ndPnYLJIyxLSf/6Rgs3p6r/vXX0ZMuaigizKzv3nM6czVfrV1fpp+w8DXzgFh05eVoz1+3Vw01qaFKPJvq/1JO6UJVt3nNCg2f/PAtev3tq62hGruZ+sV+S1Oa26zX04fO1yYKdWrOr+P/8m/pk0u17jijMoCeTZmVl6vZakcb8ni74TRfqpqNQB+Btl1Oom4pCHVfrUoW6ySjUS8bUQp1vLwAAAMBANDUBAADAsyyZNdOKSVkKYUQdAAAAMBCFOgAAAGAgWl8AAADgUdb5lylMylIYI+oAAACAgSjUAQAAAAPR+gIAAACPsqyCxRQmZSmMEXUAAADAQBTqAAAAgIFofQEAAIBH8byjkmFEHQAAADAQhToAAABgIFpfAAAA4Fn0vpTINVuou1wuSVJ2dpaXk1y5zKB8b0cA8Bt3Lt/p7QhXzd+Pfx7j6jjzcrwd4Yo5805L+rkugm+5Zgv1rKyCAv0PDW/2chIAAADvysrKksPh8HYMXKZrtlCvWrWqUlNTFRYWJqsMZrHPzMxUVFSUUlNTFR4eXurH9wRfvwbye5+vXwP5vc/Xr4H83ufr11DW+V0ul7KyslS1atVSP/bVsM6/TGFSlsKu2ULdZrOpevXqZX6e8PBwn/xiKMzXr4H83ufr10B+7/P1ayC/9/n6NZRlfkbSfReNewAAAICBrtkRdQAAAJjJklQGnclXzKAoRTCifoXsdruGDx8uu93u7ShXzNevgfze5+vXQH7v8/VrIL/3+fo1+Hp+lC3LxXw9AAAA8IDMzEw5HA79Z98xhRl0T0FWZqbqxVRWRkaGUfc60PoCAAAAj+J5RyVD6wsAAABgIAp1AAAAwEAU6gBwlbp27SrLsmRZltauXetef2FddHS017JdSnR0tDsnAHiKZZm3mIhCHYBPSUxMdBeWhReHw6H4+Hh98MEHuhbukT958qQSExOVmJio6dOnezsOAMALuJkUwDUhMzNTGzdu1MaNG/XFF19o6tSp3o6k5ORkSVJQUNBl73vy5EmNGDFCktSyZUt17dq1NKMBAHwAI+oAfFZCQoKSk5O1atUqPfPMM+7106ZN05dffvmL+zmdTuXm5pZ5vubNm6t58+Zq2LBhmZ8LAHyLZeBiHgp1AD6rcuXKat68uVq3bq0pU6YoJibG/VlycnKRNpmpU6dq1KhRuuGGGxQQEKBNmzZJklwul6ZNm6b4+HiFh4crODhY9evX17hx4+R0Oi8654QJE3TjjTcqODhYjRs31mefffaL+X6pRz0/P1+TJk1Ss2bN5HA4FBwcrNjYWD377LOSCnreC1/LunXr3Mdq1aqVe312drYSExNVr149BQcHKzw8XK1atdKyZcsuypKTk6O+ffuqUqVKCg0NVfv27bV///6S/JoBAF5C6wuAa4JlWUUeUpGXl1fk89GjR2vv3r0X7de1a1fNnDmzyLqdO3fqhRdeUEpKiubOnete/9Zbb+mll15yv9+yZYvatWunWrVqlTjn2bNndf/992vFihVF1u/Zs0d79uzRu+++W6LjZGRkqEWLFtq1a5d7XW5urtatW6d169Zp4sSJ6tWrl/uzjh07aunSpe73S5Ys0fbt25WTk1Pi7AAAz2JEHYDPO3PmjD788EPt3LnTve7WW28tss3evXvVpUsXLV26VDNnzlS1atW0YMECd5F+8803a86cOVqyZImaNm0qSZo3b57mzZsnSUpPT9ewYcPcx3v++ee1dOlSderUSd98802JsyYlJbmL9JCQEI0cOVLLly/Xe++9p0aNGkmShgwZovnz57v3iYuLU3JyspKTkzV+/Hj3NheK9Hvuucd9XZGRkZKk/v37KzU1VZK0YsUKd5EeHByssWPHatGiRYqMjFRaWlqJswNAafH2DC++MusLI+oAfNaMGTM0Y8aMi9Y3bNhQbdu21ebNm93r4uPjNWvWrCLbFR4d7927t6pXry5Jevrpp92tMbNmzVKnTp20atUqnT59WpLUqFEjJSUlSZLatm2r9evX68CBAyXK/OGHH7p/fvvtt9WzZ0/3+wt99rGxsQoICHCvdzgcat68ufu90+nU7NmzJUmBgYEaMGCA7Ha7wsPD9dBDD2nSpEnKy8vTxx9/rBdffFGLFy9279unTx/169dPklS3bl3ddNNNJcoNAPA8CnUA14zAwEB17NhRY8eOlZ+fX5HP7rvvvou2//bbb90/9+3bt9hjXhgtL9w2c2HkW5L8/PzUoEGDEhfqhc9ZXKaSOHHihNLT0yUVtPi0bt262O0ulT02Nlbly5d3HwsAYBYKdQA+KyEhQa+88oosy1JYWJhiY2MVHBxc7LZVqlS5onOcOnXqktuY+rAgX84O4Npm2jwrJmUpjB51AD7rwqwv8fHxuu22236xSJeKL0gLt318/vnncrlcFy3ff/+9JKlmzZrubQtP/Zifn/+rU0H+2jkL39z5v2y2n7+e/3f2mYoVK6p8+fKSpNDQUGVlZV2UOz8/X9OmTfvV7Hv27KFHHQAMRqEO4DerS5cu7p+feOIJTZ48WWvWrNHcuXM1cuRINW3aVH/7298kSW3atHE/uGjz5s164YUXtGzZMnXv3r3EbS+S9Mc//tH9c//+/TV69GitXLlS06ZNU7NmzdyfXSjEJWnXrl1atGiRNmzYoAMHDshms6lz586SCqZovPvuuzV37lytXr1a06dP15///GfVqlXL3Wffvn1797EmTJig8ePH69NPPy1y/QAA89D6AuA369FHH9WTTz6pmTNn6uDBg3ruuecu2qZdu3aSCgrnxMREDRo0SJI0btw4jRs3TjabTTVr1ix26sfi9OvXTytWrNDq1at16tQpDR06tNjtwsLC1KBBA23dulUnT57Ugw8+KEkaPny4EhMTNXr0aCUnJ2vXrl1KSUlRSkrKL56zXbt2SkhI0LJly9zzqUtSpUqV5HA4lJGRUaLsAFBaTJtpxaQshTGiDuA3bcaMGZo5c6Zatmwph8OhwMBA1ahRQ3fddZeSkpKKzEX+8ssva9y4cYqOjpbdbldcXJwWL16sFi1alPh8AQEBWrZsmZKSktS4cWOFhoYqKChItWrVUo8ePYpsO2fOHLVr167I6PoF5cqVU0pKikaOHKn69esrODhYISEhio2N1SOPPKI5c+a4p5mUpPnz56t3796KiIhQSEiIe7aacuXKXf4vDQDgEZbL5XJ5OwQAAACufZmZmXI4HPrvgeMKK/SQOm/LyszUzTUqKSMjo8jD87yN1hcAAAB4lHX+ZQqTshRG6wsAAABgIAp1AAAAwEC0vgAAAMCzeOJRiTCiDgAAABiIQh0AAAAwEK0vAAAA8Cg6X0qGEXUAAADAQBTqAAAAgIFofQEAAIBHWVbBYgqTshTGiDoAAABgIAp1AAAAwEC0vgAAAMCjrPMvU5iUpTBG1AEAAAADUagDAAAABqL1BQAAAJ7FE49KhBF1AAAAwEAU6gAAAICBaH0BAACAR9H5UjKMqAMAAAAGolAHAAAADETrCwAAADzKsgoWU5iUpTBG1AEAAAADUagDAAAABqL1BQAAAB5myTJqrhWTsvyMEXUAAADAQBTqAAAAgIFofQEAAIBHMetLyTCiDgAAABiIQh0AAAAwEIU6AAAAYCAKdQAAAMBAFOoAAACAgZj1BQAAAB7FrC8lw4g6AAAAYCAKdQAAAMBAtL4AAADAo6zzL1OYlKUwRtQBAAAAA1GoAwAAAAai9QUAAAAexawvJcOIOgAAAGAgCnUAAADAQLS+AAAAwKOs84spTMpSGCPqAAAAgIEo1AEAAAAD0foCAAAAz6L3pUQYUQcAAAAMRKEOAAAAGIjWFwAAAHiUdf5lCpOyFMaIOgAAAGAgCnUAAADAQLS+AAAAwKMsq2AxhUlZCmNEHQAAADAQhToAAABgIFpfAAAA4FE876hkGFEHAAAADEShDgAAABiI1hcAAAB4Fr0vJcKIOgAAAGAgCnUAAADAQLS+AAAAwKOs8y9TmJSlMEbUAQAAgCswceJERUdHKygoSE2aNNHmzZtL9fgU6gAAAMBlmjdvngYMGKDhw4dr27Ztql+/vtq2batjx46V2jko1AEAAOBRlmXecrnGjBmjHj16qFu3bqpbt64mT56skJAQTZ06tdR+TxTqAAAAwGXIy8vT1q1b1bp1a/c6m82m1q1bKyUlpdTOw82kAAAA8KjMzExvRyjiQp7/zWW322W32y/a/sSJE8rPz1eVKlWKrK9SpYp2795darko1AEAAOARgYGBioyMVGxMlLejXCQ0NFRRUUVzDR8+XImJid4JJAp1AAAAeEhQUJD27dunvLw8b0e5iMvlkvU/zerFjaZLUsWKFeXn56ejR48WWX/06FFFRkaWWiYKdQAAAHhMUFCQgoKCvB3jqgQGBqpBgwZas2aNOnToIElyOp1as2aN+vTpU2rnoVAHAAAALtOAAQP01FNPqWHDhmrcuLHGjh2rU6dOqVu3bqV2Dgp1AAAA4DJ16tRJx48f17Bhw3TkyBHFxcVp+fLlF91gejUsl8vlKrWjAQAAACgVzKMOAAAAGIhCHQAAADAQhToAAABgIAp1AAAAwEAU6gAAAICBKNQBAAAAA1GoAwAAAAaiUAcAAAAMRKEOAAAAGIhCHQAAADAQhToAAABgIAp1AAAAwED/D/CduQybfCCJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency: [340, 350, 360]\n",
      "Error occurred while extracting feature importances: 'numpy.ndarray' object has no attribute 'columns'\n",
      "Model 1 - Accuracy: 1.0\n",
      "Model 2 - Accuracy: 1.0\n",
      "Model 3 - Accuracy: 1.0\n",
      "Model 4 - Accuracy: 0.9896551724137931\n",
      "Model 5 - Accuracy: 1.0\n",
      "df_new_sample[Sample]: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'L' 'O']\n",
      "y_new_sample: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'L' 'O']\n",
      "Model 1 - Accuracy: 0.19170984455958548\n",
      "Model 2 - Accuracy: 0.6614853195164075\n",
      "Model 3 - Accuracy: 0.34283246977547494\n",
      "Model 4 - Accuracy: 0.45682210708117443\n",
      "Model 5 - Accuracy: 0.6770293609671848\n",
      "Frequency: [350]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Danim\\Documents\\GitHub\\PIC-PAPER-01\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred while extracting feature importances: 'numpy.ndarray' object has no attribute 'columns'\n",
      "Model 1 - Accuracy: 0.9517241379310345\n",
      "Model 2 - Accuracy: 0.9620689655172414\n",
      "Model 3 - Accuracy: 0.803448275862069\n",
      "Model 4 - Accuracy: 0.9448275862068966\n",
      "Model 5 - Accuracy: 0.9482758620689655\n",
      "df_new_sample[Sample]: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'L' 'O']\n",
      "y_new_sample: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'L' 'O']\n",
      "Model 1 - Accuracy: 0.47063903281519864\n",
      "Model 2 - Accuracy: 0.5690846286701209\n",
      "Model 3 - Accuracy: 0.20898100172711573\n",
      "Model 4 - Accuracy: 0.4991364421416235\n",
      "Model 5 - Accuracy: 0.531951640759931\n"
     ]
    }
   ],
   "source": [
    "csv_path = os.path.normpath(os.path.join(notebook_dir, '..', '..', 'results/exp_5/results_WS_05.csv'))\n",
    "\n",
    "input_path_train_data = 'data/experiment_5_plastics/processed/'\n",
    "input_path_new_sample = 'data/experiment_5_plastics/processed/new_sample/'\n",
    "\n",
    "# Training options\n",
    "drop_sample = True\n",
    "eliminate_std_dev = False\n",
    "eliminate_LG = False\n",
    "HG_diff = False\n",
    "LG_diff = False\n",
    "apply_scaling = False\n",
    "apply_savitzky_golay = True\n",
    "apply_pca = False\n",
    "apply_lda = False \n",
    "apply_qda = False\n",
    "apply_ica = False\n",
    "\n",
    "print(f'Training')\n",
    "\n",
    "# window_intervals = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "window_intervals = [0.1]\n",
    "\n",
    "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'O']\n",
    "test_percentage = 0.2\n",
    "\n",
    "for window_interval in window_intervals:\n",
    "    print(f'Window interval: {window_interval}')\n",
    "    df_train, df_test, labels = prepare_train_test_data(notebook_dir, input_dir=input_path_train_data, test_percentage=test_percentage, time_window_s=window_interval, stabilised_time_s=12, split = True, verbose=True)\n",
    "    df_new_sample, labels = prepare_train_test_data(notebook_dir, input_dir=input_path_new_sample, test_percentage=test_percentage, time_window_s=window_interval, stabilised_time_s=12, split = False, verbose=True)\n",
    "    \n",
    "    # Drop NaN values\n",
    "    df_train = df_train.dropna()\n",
    "    df_test = df_test.dropna()\n",
    "    df_new_sample = df_new_sample.dropna()\n",
    "\n",
    "    for freq in freqs:\n",
    "\n",
    "        subset_freqs = freq\n",
    "        print(f'Frequency: {freq}')\n",
    "        \n",
    "        X_train, y_train = preprocess_data(df_train, labels, subset_freqs, eliminate_std_dev, eliminate_LG, drop_sample=True) \n",
    "        X_test, y_test = preprocess_data(df_test, labels, subset_freqs, eliminate_std_dev, eliminate_LG, drop_sample=True)\n",
    "\n",
    "        X_train = add_features(X_train, y_train, subset_freqs, HG_diff, LG_diff)\n",
    "        X_test = add_features(X_test, y_test, subset_freqs, HG_diff, LG_diff)\n",
    "\n",
    "        # Apply standard scaling\n",
    "        if apply_scaling:\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "\n",
    "        if apply_savitzky_golay:\n",
    "            X_train = savgol_filter(X_train, window_length=3, polyorder=2)\n",
    "            X_test = savgol_filter(X_test, window_length=3, polyorder=2)\n",
    "\n",
    "        if apply_pca:\n",
    "            pca = PCA(n_components=0.95)  \n",
    "            X_train = pca.fit_transform(X_train)\n",
    "            X_test = pca.transform(X_test)\n",
    "\n",
    "        if apply_lda:\n",
    "            lda = LinearDiscriminantAnalysis()\n",
    "            X_train = lda.fit_transform(X_train, y_train)\n",
    "            X_test = lda.transform(X_test)\n",
    "\n",
    "        if apply_qda:\n",
    "            qda = QuadraticDiscriminantAnalysis()\n",
    "            qda.fit(X_train, y_train)\n",
    "            # Get probability estimates\n",
    "            X_train_qda = qda.predict_proba(X_train)\n",
    "            X_test_qda = qda.predict_proba(X_test)\n",
    "            \n",
    "            # To combine with original features\n",
    "            X_train = np.hstack((X_train, X_train_qda))\n",
    "            X_test = np.hstack((X_test, X_test_qda))\n",
    "\n",
    "\n",
    "        if apply_ica:\n",
    "            ica = FastICA(n_components=2)\n",
    "            X_train = ica.fit_transform(X_train)\n",
    "            X_test = ica.transform(X_test)\n",
    "\n",
    "        # Define model names\n",
    "        models = ['RF', 'NB', 'LR', 'GB', 'SVM']\n",
    "\n",
    "        # Train the models\n",
    "        rf_model, nb_model, lr_model, gb_model, svm_model, training_times = train_models(X_train, y_train, seed)\n",
    "\n",
    "        # Feature Importance Extraction \n",
    "        try:\n",
    "            rf_imp, lr_imp, gb_imp, nb_imp, svm_imp = get_feature_importances(\n",
    "                rf_model, lr_model, gb_model, nb_model, svm_model, \n",
    "                X_train, y_train, seed, False, 20  # plot=True, n=10\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while extracting feature importances: {e}\")\n",
    "\n",
    "        # Make Predictions\n",
    "        y_pred = []\n",
    "        inference_times = []\n",
    "\n",
    "        for model in [rf_model, \n",
    "                    nb_model, \n",
    "                    lr_model, \n",
    "                    gb_model, \n",
    "                    svm_model]:\n",
    "            start_time = time.time()\n",
    "            predictions = model.predict(X_test)\n",
    "            total_time = time.time() - start_time\n",
    "            inference_times.append(total_time / len(X_test))  # Time per sample\n",
    "            y_pred.append(predictions)\n",
    "        \n",
    "            \n",
    "        # Evaluate Models\n",
    "        accuracies, precisions, recalls, f1_scores, aic_scores, bic_scores, predictions = evaluate_models(y_test, y_pred, verbose=0)\n",
    "\n",
    "        updated_results = save_model_results(\n",
    "            models=models,\n",
    "            data='test',\n",
    "            time_window_s=window_interval,\n",
    "            accuracies=accuracies,\n",
    "            precisions=precisions,\n",
    "            recalls=recalls,\n",
    "            f1_scores=f1_scores,\n",
    "            aic_scores=aic_scores,\n",
    "            bic_scores=bic_scores,\n",
    "            predictions=predictions,\n",
    "            n_features=X_train.shape[1],\n",
    "            freqs=subset_freqs,\n",
    "            csv_path=csv_path,\n",
    "            training_times=training_times,\n",
    "            inference_times=inference_times\n",
    "        )\n",
    "\n",
    "        print(f'df_new_sample[Sample]: {df_new_sample['Sample'].unique()}')\n",
    "        X_new_sample, y_new_sample = preprocess_data(df_new_sample, labels, subset_freqs, eliminate_std_dev, eliminate_LG, drop_sample=True)\n",
    "        print(f'y_new_sample: {y_new_sample.unique()}')\n",
    "\n",
    "        X_new_sample = add_features(X_new_sample, y_new_sample, subset_freqs, HG_diff, LG_diff)\n",
    "\n",
    "\n",
    "        if apply_scaling:\n",
    "            X_new_sample = scaler.transform(X_new_sample)\n",
    "\n",
    "        if apply_savitzky_golay:\n",
    "            X_new_sample = savgol_filter(X_new_sample, window_length=3, polyorder = 2)\n",
    "\n",
    "        if apply_pca:\n",
    "            X_new_sample = pca.transform(X_new_sample)\n",
    "\n",
    "        if apply_qda:\n",
    "            X_new_sample_qda = qda.predict_proba(X_new_sample)\n",
    "            X_new_sample = np.hstack((X_new_sample, X_new_sample_qda))\n",
    "                                    \n",
    "        if apply_lda:\n",
    "            X_new_sample = lda.transform(X_new_sample)\n",
    "\n",
    "        if apply_ica:\n",
    "            X_new_sample = ica.transform(X_new_sample)\n",
    "\n",
    "        # Make Predictions\n",
    "        y_pred_ns = []\n",
    "        inference_times_ns = []\n",
    "        for model in [rf_model, \n",
    "                        nb_model, \n",
    "                        lr_model, \n",
    "                        gb_model, \n",
    "                        svm_model]:\n",
    "                start_time = time.time()\n",
    "                predictions = model.predict(X_new_sample)\n",
    "                total_time = time.time() - start_time\n",
    "                inference_times_ns.append(total_time / len(X_new_sample))  \n",
    "                y_pred_ns.append(predictions)\n",
    "        \n",
    "\n",
    "        # Evaluate Models\n",
    "        accuracies, precisions, recalls, f1_scores, aic_scores, bic_scores, predictions = evaluate_models(y_new_sample, y_pred_ns, verbose=0)\n",
    "\n",
    "        # Plot Confusion Matrix\n",
    "        save_path = os.path.normpath(os.path.join(notebook_dir, '..', '..', 'results/conf_matrix/'))\n",
    "\n",
    "        for i, accuracy in enumerate(accuracies):\n",
    "            if accuracy >= 0.8:\n",
    "                model_name = f\"{models[i]}_{freq}\"\n",
    "                # plot_confusion_matrix(y_new_sample, y_pred_ns[i], np.unique(y_train))\n",
    "                plot_confusion_matrix_pdf(y_new_sample, y_pred_ns[i], np.unique(y_train), save_path, model_name)\n",
    "\n",
    "        updated_results = save_model_results(\n",
    "            models=models,\n",
    "            data='new_sample',\n",
    "            time_window_s=window_interval,\n",
    "            accuracies=accuracies,\n",
    "            precisions=precisions,\n",
    "            recalls=recalls,\n",
    "            f1_scores=f1_scores,\n",
    "            aic_scores=aic_scores,\n",
    "            bic_scores=bic_scores,\n",
    "            predictions=predictions,\n",
    "            n_features=X_train.shape[1],\n",
    "            freqs=subset_freqs,\n",
    "            csv_path=csv_path,\n",
    "            training_times=training_times,\n",
    "            inference_times=inference_times_ns\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_color_brightness(color, factor=0.6):\n",
    "    return tuple([min(1, max(0, c * factor)) for c in color])\n",
    "\n",
    "def plot_pca_3d(X_train_pca, y_pca, elev=30, azim=-45, show_labels=True):\n",
    "    \"\"\"\n",
    "    Plot PCA results in 3D, 2D, or 1D depending on the number of components.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train_pca : array\n",
    "        PCA-transformed data\n",
    "    y_pca : array\n",
    "        Labels for each point\n",
    "    elev : float, default=30\n",
    "        Elevation angle for 3D plot viewing\n",
    "    azim : float, default=-45\n",
    "        Azimuth angle for 3D plot viewing\n",
    "    show_labels : bool, default=True\n",
    "        Whether to show labels at the centroid of each class\n",
    "    \"\"\"\n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y_pca)\n",
    "    unique_classes = np.unique(y_encoded)\n",
    "    n_classes = len(unique_classes)\n",
    "    \n",
    "    # Define color palette using Seaborn's husl palette\n",
    "    base_palette = sns.color_palette(\"husl\", n_classes)\n",
    "    \n",
    "    # Create a mapping of labels to colors\n",
    "    color_dict = {}\n",
    "    for i, label in enumerate(le.classes_):\n",
    "        color_dict[label] = base_palette[i]\n",
    "    \n",
    "    # Get number of components\n",
    "    n_components = X_train_pca.shape[1]\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    if n_components >= 3:\n",
    "        # 3D plot\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        \n",
    "        # Set the viewing angle\n",
    "        ax.view_init(elev=elev, azim=azim)\n",
    "        \n",
    "        # Plot each class separately\n",
    "        for i, class_name in enumerate(le.classes_):\n",
    "            mask = y_pca == class_name\n",
    "            color = base_palette[i]\n",
    "            \n",
    "            # Scatter points\n",
    "            ax.scatter(X_train_pca[mask, 0], \n",
    "                      X_train_pca[mask, 1],\n",
    "                      X_train_pca[mask, 2],\n",
    "                      color=color,\n",
    "                      edgecolor=adjust_color_brightness(color, 0.6),\n",
    "                      label=class_name,\n",
    "                      s=25,\n",
    "                      alpha=0.6)\n",
    "            \n",
    "            # Add labels if requested\n",
    "            if show_labels:\n",
    "                # Calculate centroid\n",
    "                centroid = np.mean(X_train_pca[mask], axis=0)\n",
    "                \n",
    "                # Use a fixed offset based on viewing angle for label positioning\n",
    "                offset_factor = 0.2  # Adjust this factor to increase/decrease offset\n",
    "                \n",
    "                # Calculate offset based on data range\n",
    "                data_range = np.ptp(X_train_pca, axis=0)\n",
    "                \n",
    "                # Compute an offset that considers the viewing angle\n",
    "                sin_azim = np.sin(np.radians(azim))\n",
    "                cos_azim = np.cos(np.radians(azim))\n",
    "                sin_elev = np.sin(np.radians(elev))\n",
    "                cos_elev = np.cos(np.radians(elev))\n",
    "                \n",
    "                # Calculate offset vector\n",
    "                offset_x = offset_factor * data_range[0] * sin_azim\n",
    "                offset_y = offset_factor * data_range[1] * cos_azim\n",
    "                offset_z = offset_factor * data_range[2] * cos_elev\n",
    "                \n",
    "                # Position for label\n",
    "                label_pos = (centroid[0] + offset_x,\n",
    "                             centroid[1] + offset_y,\n",
    "                             centroid[2] + offset_z)\n",
    "                \n",
    "                # Draw an arrow from the label to the centroid\n",
    "                ax.plot([label_pos[0], centroid[0]],\n",
    "                       [label_pos[1], centroid[1]],\n",
    "                       [label_pos[2], centroid[2]],\n",
    "                       'k-', linewidth=1, alpha=0.6)\n",
    "                \n",
    "                # Add the label\n",
    "                ax.text(label_pos[0], label_pos[1], label_pos[2],\n",
    "                       class_name,\n",
    "                       fontsize=10,\n",
    "                       fontweight='bold',\n",
    "                       color='black',\n",
    "                       ha='center',\n",
    "                       va='center',\n",
    "                       bbox=dict(facecolor='white', \n",
    "                                alpha=0.9, \n",
    "                                boxstyle='round,pad=0.3',\n",
    "                                edgecolor='gray'))\n",
    "        \n",
    "        ax.set_xlabel('PC1')\n",
    "        ax.set_ylabel('PC2')\n",
    "        ax.set_zlabel('PC3')\n",
    "        \n",
    "        # Add grid for better depth perception\n",
    "        ax.grid(True)\n",
    "        \n",
    "    elif n_components == 2:\n",
    "        # 2D plot\n",
    "        ax = fig.add_subplot(111)\n",
    "        \n",
    "        # Plot each class separately\n",
    "        for i, class_name in enumerate(le.classes_):\n",
    "            mask = y_pca == class_name\n",
    "            color = base_palette[i]\n",
    "            \n",
    "            # Scatter points\n",
    "            ax.scatter(X_train_pca[mask, 0],\n",
    "                      X_train_pca[mask, 1],\n",
    "                      color=color,\n",
    "                      edgecolor=adjust_color_brightness(color, 0.6),\n",
    "                      label=class_name,\n",
    "                      s=25, \n",
    "                      alpha=0.6)\n",
    "        \n",
    "        # Add labels\n",
    "        if show_labels:\n",
    "            for i, class_name in enumerate(le.classes_):\n",
    "                mask = y_pca == class_name\n",
    "                color = base_palette[i]\n",
    "                \n",
    "                # Calculate centroid of this class\n",
    "                centroid = np.mean(X_train_pca[mask], axis=0)\n",
    "                \n",
    "                # Create a marker at centroid location that will be behind the text\n",
    "                ax.scatter(centroid[0], centroid[1],\n",
    "                          color='white',\n",
    "                          s=250,\n",
    "                          alpha=0.8,\n",
    "                          edgecolor='gray',\n",
    "                          zorder=5)  # Higher zorder to ensure it's drawn on top\n",
    "                \n",
    "                # Add text label at centroid\n",
    "                ax.text(centroid[0], centroid[1], \n",
    "                        class_name, \n",
    "                        fontsize=12, \n",
    "                        fontweight='bold', \n",
    "                        color='black',\n",
    "                        ha='center', va='center',\n",
    "                        bbox=dict(facecolor='white', alpha=0.9, boxstyle='round,pad=0.3', \n",
    "                                  edgecolor='gray'),\n",
    "                        zorder=10)  # Even higher zorder for text\n",
    "            \n",
    "        ax.set_xlabel('PC1')\n",
    "        ax.set_ylabel('PC2')\n",
    "        \n",
    "    else:\n",
    "        # 1D plot\n",
    "        ax = fig.add_subplot(111)\n",
    "        \n",
    "        # Plot each class separately\n",
    "        for i, class_name in enumerate(le.classes_):\n",
    "            mask = y_pca == class_name\n",
    "            color = base_palette[i]\n",
    "            \n",
    "            # Scatter points\n",
    "            ax.scatter(X_train_pca[mask, 0],\n",
    "                      np.zeros_like(X_train_pca[mask, 0]),\n",
    "                      color=color,\n",
    "                      edgecolor=adjust_color_brightness(color, 0.6),\n",
    "                      label=class_name,\n",
    "                      s=25, #dot size\n",
    "                      alpha=0.6)\n",
    "            \n",
    "            # Add label if requested\n",
    "            if show_labels:\n",
    "                # Calculate centroid of this class\n",
    "                centroid = np.mean(X_train_pca[mask], axis=0)\n",
    "                \n",
    "                # Add text label at centroid\n",
    "                ax.text(centroid[0], 0.05, \n",
    "                        class_name, \n",
    "                        fontsize=12, \n",
    "                        fontweight='bold', \n",
    "                        color='black',\n",
    "                        ha='center', va='center',\n",
    "                        bbox=dict(facecolor='white', alpha=0.9, boxstyle='round,pad=0.3',\n",
    "                                 edgecolor='gray'))\n",
    "            \n",
    "        ax.set_xlabel('PC1')\n",
    "        plt.yticks([])\n",
    "    \n",
    "    # Add legend with class names\n",
    "    plt.legend(loc='best', markerscale=1.5)\n",
    "    \n",
    "    # Add explained variance ratio to title if available\n",
    "    if hasattr(pca, 'explained_variance_ratio_'):\n",
    "        if n_components >= 3:\n",
    "            variance_text = f'PC1: {pca.explained_variance_ratio_[0]:.2%}, PC2: {pca.explained_variance_ratio_[1]:.2%}, PC3: {pca.explained_variance_ratio_[2]:.2%}'\n",
    "        elif n_components == 2:\n",
    "            variance_text = f'PC1: {pca.explained_variance_ratio_[0]:.2%}, PC2: {pca.explained_variance_ratio_[1]:.2%}'\n",
    "        else:\n",
    "            variance_text = f'PC1: {pca.explained_variance_ratio_[0]:.2%}'\n",
    "        plt.title(f'PCA Visualization\\n{variance_text}')\n",
    "    else:\n",
    "        plt.title('PCA Visualization')\n",
    "\n",
    "    # Save figure with angle and label information in filename\n",
    "    filepath = os.path.normpath(os.path.join(notebook_dir, '..', '..', 'results/pca_models/'))\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "        \n",
    "    freqs_code = '_'.join(map(str, subset_freqs))\n",
    "    labels_suffix = \"_labeled\" if show_labels else \"\"\n",
    "    plt.savefig(f'{filepath}/pca_viz_{freqs_code}_elev{elev}_azim{azim}{labels_suffix}.pdf', bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    return ax\n",
    "\n",
    "\n",
    "# PCA 3D Visualization\n",
    "# Generate multiple views of the same PCA result\n",
    "for freq in freqs:\n",
    "    subset_freqs = freq\n",
    "    print(f'Frequency: {freq}')\n",
    "\n",
    "    X_train, y_train = preprocess_data(df_train, labels, subset_freqs, eliminate_std_dev, eliminate_LG, drop_sample=True) \n",
    "    X_test, y_test = preprocess_data(df_test, labels, subset_freqs, eliminate_std_dev, eliminate_LG, drop_sample=True)\n",
    "\n",
    "    X_train = add_features(X_train, y_train, subset_freqs, HG_diff, LG_diff)\n",
    "    X_test = add_features(X_test, y_test, subset_freqs, HG_diff, LG_diff)\n",
    "\n",
    "    pca = PCA(n_components=0.95)  \n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    # Print all PCA component percentages\n",
    "    print(\"Explained variance by PCA components:\")\n",
    "    for i, var in enumerate(pca.explained_variance_ratio_):\n",
    "        print(f\"PC{i+1}: {var*100:.2f}%\")\n",
    "    print(f\"Total variance explained: {sum(pca.explained_variance_ratio_)*100:.2f}%\")\n",
    "    print(f\"Number of components: {len(pca.explained_variance_ratio_)}\")\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    y_pca = y_train\n",
    "    \n",
    "    # Generate different views of the same data\n",
    "    views = [\n",
    "        (30, -45),     # Default view\n",
    "        # (0, 0),      # Front view\n",
    "        # (0, 90),     # Side view\n",
    "        # (90, 0),     # Top view\n",
    "        (20, -70),   \n",
    "        (30, -20),   \n",
    "        (25, -25),   \n",
    "        (35, -75),   \n",
    "\n",
    "    ]\n",
    "    \n",
    "    for elev, azim in views:\n",
    "        plot_pca_3d(X_train_pca, y_pca, elev=elev, azim=azim, show_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Visualization (Frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_color_brightness(color, factor=0.6):\n",
    "    return tuple([min(1, max(0, c * factor)) for c in color])\n",
    "\n",
    "def plot_3d_specific_frequencies(df, freq_names, elev=30, azim=-45):\n",
    "    \"\"\"\n",
    "    Plot 3D visualization using 3 selected frequencies directly from the dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        DataFrame containing the frequency data\n",
    "    freq_names : list\n",
    "        List of 3 column names to visualize (e.g., ['340.0 HG (mV)', '350.0 HG (mV)', '360.0 HG (mV)'])\n",
    "    elev : float, default=30\n",
    "        Elevation angle for 3D plot viewing\n",
    "    azim : float, default=-45\n",
    "        Azimuth angle for 3D plot viewing\n",
    "    \"\"\"\n",
    "    # Check if we have 3 frequencies\n",
    "    if len(freq_names) != 3:\n",
    "        raise ValueError(\"Need exactly 3 frequency names for 3D plot\")\n",
    "    \n",
    "    # Check if frequencies exist in dataframe\n",
    "    for freq in freq_names:\n",
    "        if freq not in df.columns:\n",
    "            raise ValueError(f\"Frequency column '{freq}' not found in dataframe\")\n",
    "    \n",
    "    # Extract data for the 3 frequencies and the sample labels\n",
    "    X_3d = df[freq_names].values\n",
    "    y = df['Sample'].values\n",
    "    \n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    unique_classes = np.unique(y_encoded)\n",
    "    n_classes = len(unique_classes)\n",
    "    \n",
    "    # Define color palette using Seaborn's husl palette\n",
    "    base_palette = sns.color_palette(\"husl\", n_classes)\n",
    "    \n",
    "    # Create a mapping of labels to colors\n",
    "    color_dict = {}\n",
    "    for i, label in enumerate(le.classes_):\n",
    "        color_dict[label] = base_palette[i]\n",
    "    \n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Set the viewing angle\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "    \n",
    "    # Plot each class separately for better legend\n",
    "    for i, class_name in enumerate(le.classes_):\n",
    "        mask = y == class_name\n",
    "        color = base_palette[i]\n",
    "        ax.scatter(X_3d[mask, 0], \n",
    "                  X_3d[mask, 1],\n",
    "                  X_3d[mask, 2],\n",
    "                  color=color,\n",
    "                  edgecolor=adjust_color_brightness(color, 0.6),\n",
    "                  label=class_name,\n",
    "                  s=25,  # dot size\n",
    "                  alpha=0.6)\n",
    "    \n",
    "    # Extract frequency values from column names for axis labels\n",
    "    freq_values = []\n",
    "    for name in freq_names:\n",
    "        # Extract the numeric part from strings like \"340.0 HG (mV)\"\n",
    "        match = re.search(r'(\\d+\\.?\\d*)', name)\n",
    "        if match:\n",
    "            freq_values.append(match.group(1))\n",
    "        else:\n",
    "            freq_values.append(name)\n",
    "    \n",
    "    # Set axis labels with frequency values\n",
    "    ax.set_xlabel(f'{freq_names[0]}')\n",
    "    ax.set_ylabel(f'{freq_names[1]}')\n",
    "    ax.set_zlabel(f'{freq_names[2]}')\n",
    "    \n",
    "    # Add grid for better depth perception\n",
    "    ax.grid(True)\n",
    "    \n",
    "    # Add legend with class names\n",
    "    plt.legend(loc='best', markerscale=1.5)\n",
    "    \n",
    "    # Set title\n",
    "    plt.title(f'3D Visualization of Selected Frequencies\\n{freq_values[0]}, {freq_values[1]}, {freq_values[2]} GHz')\n",
    "\n",
    "    # Save figure with angle and frequency information in filename\n",
    "    filepath = os.path.normpath(os.path.join(notebook_dir, '..', '..', 'results/freq_viz/'))\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "        \n",
    "    # Create a cleaner filename\n",
    "    clean_freqs = [re.sub(r'[^\\d.]', '', f) for f in freq_values]\n",
    "    freqs_code = '_'.join(clean_freqs)\n",
    "    plt.savefig(f'{filepath}/freq_viz_{freqs_code}_elev{elev}_azim{azim}.pdf', bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    return ax\n",
    "\n",
    "import re  # Import regex for extracting frequency values\n",
    "\n",
    "# Define specific target frequencies to visualize\n",
    "target_freqs = [340.0, 350.0, 360.0]  # Adjust to your desired frequencies\n",
    "\n",
    "# Find matching columns in the original dataframe\n",
    "hg_columns = []\n",
    "for target_freq in target_freqs:\n",
    "    # Find columns that match this frequency \n",
    "    for col in train_set_test.columns:\n",
    "        if f\"{target_freq} HG (mV)\" in col:\n",
    "            hg_columns.append(col)\n",
    "            break\n",
    "\n",
    "if len(hg_columns) == 3:\n",
    "    # Use the original dataframe with the identified columns\n",
    "    df_viz = train_set_test.copy()\n",
    "    \n",
    "    # Apply preprocessing to these specific columns\n",
    "    if apply_savitzky_golay:\n",
    "        for col in hg_columns:\n",
    "            df_viz[col] = savgol_filter(df_viz[col].values, \n",
    "                                      window_length=5, polyorder=3)\n",
    "        \n",
    "    # Generate different viewing angles\n",
    "    views = [\n",
    "        (30, -45),   # Default view\n",
    "        (20, -70),   \n",
    "        (30, -20),   \n",
    "        (10, -120),  \n",
    "    ]\n",
    "    \n",
    "    for elev, azim in views:\n",
    "        plot_3d_specific_frequencies(df_viz, hg_columns, elev=elev, azim=azim)\n",
    "else:\n",
    "    print(f\"Could not find all required frequency columns. Found: {hg_columns}\")\n",
    "    # Print available columns to help troubleshoot\n",
    "    print(f\"Available columns: {[col for col in train_set_test.columns if 'HG (mV)' in col]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_freqs = list(range(100, 600, 10))\n",
    "\n",
    "X_train, y_train = preprocess_data(df_train, labels, subset_freqs, eliminate_std_dev, eliminate_LG, drop_sample=True)\n",
    "X_train = add_features(X_train, y_train, subset_freqs, HG_diff, LG_diff)\n",
    "\n",
    "## NON PCA VISUALIZATION ##\n",
    "# Choose specific variables for visualization\n",
    "var1 = '410.0 HG (mV)'\n",
    "var2 = '360.0 HG (mV)'\n",
    "\n",
    "try:\n",
    "    X_train[var1].describe()\n",
    "except Exception as e:\n",
    "    var1 = f'{var1} mean'\n",
    "    var2 = f'{var2} mean'\n",
    "\n",
    "def plot_data_visualization(X_train, y_train, var1, var2):\n",
    "    \n",
    "    # Get unique classes and encode\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y_train)\n",
    "    n_classes = len(np.unique(y_encoded))\n",
    "    \n",
    "    # Create custom colormap with only needed colors\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, 20))  # Get all 20 colors\n",
    "    colors = colors[:n_classes]  # Take only needed colors\n",
    "    custom_cmap = plt.cm.colors.ListedColormap(colors)\n",
    "    \n",
    "    # Create plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(X_train[var1], \n",
    "                         X_train[var2],\n",
    "                         c=y_encoded,\n",
    "                         cmap=custom_cmap,\n",
    "                         edgecolor='k', \n",
    "                         s=25)\n",
    "    \n",
    "    # Create custom legend\n",
    "    legend_elements = [plt.Line2D([0], [0], \n",
    "                                marker='o', \n",
    "                                color='w',\n",
    "                                markerfacecolor=colors[i], \n",
    "                                label=class_name,\n",
    "                                markersize=10) \n",
    "                      for i, class_name in enumerate(le.classes_)]\n",
    "    \n",
    "    plt.legend(handles=legend_elements, title=\"Classes\")\n",
    "    plt.xlabel(var1)\n",
    "    plt.ylabel(var2)\n",
    "    plt.show()\n",
    "\n",
    "plot_data_visualization(X_train, y_train, var1, var2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
