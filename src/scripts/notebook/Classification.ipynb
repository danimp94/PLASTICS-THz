{"cells":[{"cell_type":"markdown","metadata":{"id":"peUcVKtbGPfD"},"source":["# LSTM Classification Model\n","\n","This notebook demonstrates how to load data, preprocess it, define an LSTM model, train the model, and evaluate its performance. The data is assumed to be in CSV format and stored in a directory.\n","\n","## Setup\n","\n","First, we need to install the necessary libraries. Run the following cell to install them."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15655,"status":"ok","timestamp":1730117020991,"user":{"displayName":"DANIEL MORENO PARIS","userId":"17921422726169854440"},"user_tz":-60},"id":"aAZ2n50rGS-C","outputId":"1d58f03f-332a-41d3-c875-8de8e853e0e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n","Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"]}],"source":["%pip install torch torchvision torchaudio\n","%pip install pandas scikit-learn\n","%pip install wandb onnx -Uq"]},{"cell_type":"markdown","metadata":{"id":"l4d3KxhxGML8"},"source":["## Import Libraries and seed\n","Import the necessary libraries for data processing, model building, training, and evaluation. Adding a seed ensures reproducibility by making sure that the random number generation is consistent across different runs."]},{"cell_type":"code","execution_count":48,"metadata":{"executionInfo":{"elapsed":453,"status":"ok","timestamp":1730120031207,"user":{"displayName":"DANIEL MORENO PARIS","userId":"17921422726169854440"},"user_tz":-60},"id":"9a9HvzrNG8iw"},"outputs":[],"source":["import os\n","import random\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","import wandb\n","\n","def set_seed(seed):\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    random.seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1886,"status":"ok","timestamp":1730120034103,"user":{"displayName":"DANIEL MORENO PARIS","userId":"17921422726169854440"},"user_tz":-60},"id":"SUQtUPxSBzq4","outputId":"bca99c35-beb2-4e85-9dfb-b373ccf157b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1730120034104,"user":{"displayName":"DANIEL MORENO PARIS","userId":"17921422726169854440"},"user_tz":-60},"id":"AoCyZSTt7qqS","outputId":"52ea51dd-625e-4928-f922-dab105b963b4"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["wandb.login()"]},{"cell_type":"markdown","metadata":{"id":"S1-6Xv6LHHmZ"},"source":["## Load Data from Github Repository\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":494,"status":"ok","timestamp":1730117554902,"user":{"displayName":"DANIEL MORENO PARIS","userId":"17921422726169854440"},"user_tz":-60},"id":"eI7hrAaVHL44"},"outputs":[],"source":["## Remove PIC-PAPER-01 folder:\n","!rm -rf PIC-PAPER-01\n","\n","# # Download Github Repo (Private) https://stackoverflow.com/questions/74532852/clone-github-repo-with-fine-grained-token/78280453#78280453\n","# !git clone --no-checkout https://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@github.com/danimp94/PIC-PAPER-01.git\n","\n","# # To clone data folder only:\n","# %cd PIC-PAPER-01 # Navigate to the repository directory\n","# !git sparse-checkout init --cone # Initialize sparse-checkout\n","# !git sparse-checkout set data # Set the sparse-checkout to include only the data/ folder\n","# !git checkout # Checkout the specified folder"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2234,"status":"ok","timestamp":1730120036774,"user":{"displayName":"DANIEL MORENO PARIS","userId":"17921422726169854440"},"user_tz":-60},"id":"hAY8BfVX9XCK","outputId":"87e63dbc-360a-4932-9936-e6ca7b249eed"},"outputs":[{"name":"stdout","output_type":"stream","text":["        Sample  Frequency (GHz)     LG (mV)    HG (mV)  Thickness (mm)\n","0           A1            100.0   -7.080942  -0.854611             0.2\n","1           A1            100.0   67.024785   0.244141             0.2\n","2           A1            100.0  124.893178  -1.098776             0.2\n","3           A1            100.0   91.075571   0.000000             0.2\n","4           A1            100.0   48.956174   0.122094             0.2\n","...        ...              ...         ...        ...             ...\n","2737958    REF            600.0    0.366256  16.237333             0.0\n","2737959    REF            600.0    0.000000  -7.080942             0.0\n","2737960    REF            600.0   -0.244170  15.260652             0.0\n","2737961    REF            600.0    0.366256  20.021975             0.0\n","2737962    REF            600.0    0.122085  13.185203             0.0\n","\n","[2737963 rows x 5 columns]\n"]}],"source":["input_path = '/content/drive/MyDrive/PhD/Colab Notebooks/'\n","\n","data_frames = []\n","for file in os.listdir(input_path):\n","    if file.endswith('.csv'):\n","        df = pd.read_csv(os.path.join(input_path, file), delimiter=';', header=0)\n","        data_frames.append(df)\n","data = pd.concat(data_frames, ignore_index=True)\n","\n","print(data)"]},{"cell_type":"markdown","metadata":{"id":"wiCTw-qcKXhn"},"source":["## Preprocess Data\n","Define a function to preprocess the data. This includes encoding categorical labels and standardizing the features."]},{"cell_type":"code","execution_count":52,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1730120036774,"user":{"displayName":"DANIEL MORENO PARIS","userId":"17921422726169854440"},"user_tz":-60},"id":"zJoZqi5LDPl8"},"outputs":[],"source":["def calculate_averages_and_dispersion(data, data_percentage=3.7):\n","    df = data\n","    results = []\n","    for (sample, freq), group in df.groupby(['Sample', 'Frequency (GHz)']):\n","        window_size = max(1, int(len(group) * data_percentage / 100))\n","        # print(f\"Processing sample: {sample}, frequency: {freq} with window size: {window_size}\")\n","        for start in range(0, len(group), window_size):\n","            window_data = group.iloc[start:start + window_size]\n","            mean_values = window_data[['LG (mV)', 'HG (mV)']].mean()\n","            std_deviation_values = window_data[['LG (mV)', 'HG (mV)']].std()\n","            variance_values = window_data[['LG (mV)', 'HG (mV)']].var()\n","            results.append({\n","                'Frequency (GHz)': freq,\n","                'LG (mV) mean': mean_values['LG (mV)'],\n","                'HG (mV) mean': mean_values['HG (mV)'],\n","                'LG (mV) std deviation': std_deviation_values['LG (mV)'],\n","                'HG (mV) std deviation': std_deviation_values['HG (mV)'],\n","                'Thickness (mm)': window_data['Thickness (mm)'].iloc[0],\n","                'Sample': sample,\n","            })\n","    results_df = pd.DataFrame(results)\n","    # results_df.to_csv(output_file, sep=';', index=False)\n","    # print(f\"Processed {input_file} and saved to {output_file}\")\n","    print(results_df)\n","    return results_df"]},{"cell_type":"code","execution_count":53,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1730120038125,"user":{"displayName":"DANIEL MORENO PARIS","userId":"17921422726169854440"},"user_tz":-60},"id":"KZPdMwkkKmm7"},"outputs":[],"source":["def preprocess_data(data):\n","    # Windowing the data\n","    data = calculate_averages_and_dispersion(data)\n","\n","    # Assuming the last column is the target\n","    X = data.iloc[:, :-1].values\n","    y = data.iloc[:, -1].values\n","\n","    # Encode the target variable if it's categorical\n","    if y.dtype == 'object':\n","        le = LabelEncoder()\n","        y = le.fit_transform(y)\n","\n","    # Standardize the features\n","    scaler = StandardScaler()\n","    X = scaler.fit_transform(X)\n","\n","    # Convert to PyTorch tensors\n","    X = torch.tensor(X, dtype=torch.float32)\n","    y = torch.tensor(y, dtype=torch.long)\n","\n","    return X, y"]},{"cell_type":"markdown","metadata":{"id":"RI96M_V6KpyH"},"source":["## Define LSTM Model\n","Define the LSTM model architecture"]},{"cell_type":"code","execution_count":54,"metadata":{"executionInfo":{"elapsed":421,"status":"ok","timestamp":1730120039043,"user":{"displayName":"DANIEL MORENO PARIS","userId":"17921422726169854440"},"user_tz":-60},"id":"h6j-_U_RKxlR"},"outputs":[],"source":["class LSTMModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(LSTMModel, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n","        self.dropout = nn.Dropout(0.2)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        h_0 = torch.zeros(1, x.size(0), self.hidden_dim).to(x.device)\n","        c_0 = torch.zeros(1, x.size(0), self.hidden_dim).to(x.device)\n","        out, _ = self.lstm(x, (h_0, c_0))\n","        out = self.dropout(out[:, -1, :])\n","        out = self.fc(out)\n","        return out"]},{"cell_type":"markdown","metadata":{"id":"afvxx1KzKzYp"},"source":["## Train Model\n","Define a function to train the model"]},{"cell_type":"code","execution_count":55,"metadata":{"executionInfo":{"elapsed":455,"status":"ok","timestamp":1730120041320,"user":{"displayName":"DANIEL MORENO PARIS","userId":"17921422726169854440"},"user_tz":-60},"id":"-3a9IuRVK3Wq"},"outputs":[],"source":["def train_model(model, train_loader, criterion, optimizer, device, num_epochs=100):\n","    for epoch in range(num_epochs):\n","        model.train()\n","        for X_batch, y_batch in train_loader:\n","            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","            outputs = model(X_batch)\n","            loss = criterion(outputs, y_batch)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"]},{"cell_type":"markdown","metadata":{"id":"G1bDpP8JK5jp"},"source":["## Evaluate Model\n"]},{"cell_type":"code","execution_count":56,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1730120042333,"user":{"displayName":"DANIEL MORENO PARIS","userId":"17921422726169854440"},"user_tz":-60},"id":"TIDNXJGRK9af"},"outputs":[],"source":["def evaluate_model(model, test_loader, device):\n","    model.eval()\n","    with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        for X_batch, y_batch in test_loader:\n","            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","            outputs = model(X_batch)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += y_batch.size(0)\n","            correct += (predicted == y_batch).sum().item()\n","\n","        accuracy = correct / total\n","        print(f'Test Accuracy: {accuracy:.4f}')"]},{"cell_type":"markdown","metadata":{"id":"W4PeoxmkKQu8"},"source":["## Hyperparameters Definition"]},{"cell_type":"code","execution_count":57,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1730120043416,"user":{"displayName":"DANIEL MORENO PARIS","userId":"17921422726169854440"},"user_tz":-60},"id":"oLRhwd8cKKJH"},"outputs":[],"source":["config = dict(\n","    epochs=10,\n","    seed = 40,\n","    classes=10,\n","    kernels=[16, 32],\n","    batch_size=128,\n","    learning_rate=0.005,\n","    dataset=\"experiment_1\",\n","    architecture=\"LSTM\")"]},{"cell_type":"markdown","metadata":{"id":"WEtZPi2fLQGL"},"source":["## Run Training"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":238942,"status":"ok","timestamp":1730120283566,"user":{"displayName":"DANIEL MORENO PARIS","userId":"17921422726169854440"},"user_tz":-60},"id":"AwFKsiy3LVKk","outputId":"2523c06b-e9ca-4933-9f11-f57fe41a9343"},"outputs":[{"name":"stdout","output_type":"stream","text":["       Frequency (GHz)  LG (mV) mean  HG (mV) mean  LG (mV) std deviation  \\\n","0                100.0     54.879155     -0.022198              29.958659   \n","1                100.0     54.511665      0.048093              28.096155   \n","2                100.0     55.099894     -0.118380              26.833871   \n","3                100.0     48.387674      0.103588              28.843498   \n","4                100.0     49.932853     -0.071525              23.093397   \n","...                ...           ...           ...                    ...   \n","24271            600.0     -0.006143     10.237498               0.890999   \n","24272            600.0     -0.006910     10.949278               0.858148   \n","24273            600.0      0.029178     10.547702               0.842082   \n","24274            600.0      0.065266     10.051683               0.891632   \n","24275            600.0     -0.228910      9.766817               0.856929   \n","\n","       HG (mV) std deviation  LG (mV) variance  HG (mV) variance  \\\n","0                   0.644211        897.521243          0.415008   \n","1                   0.704742        789.393915          0.496661   \n","2                   0.755493        720.056631          0.570769   \n","3                   0.854655        831.947365          0.730435   \n","4                   0.650231        533.305001          0.422800   \n","...                      ...               ...               ...   \n","24271               8.205224          0.793878         67.325703   \n","24272               8.679982          0.736419         75.342089   \n","24273               8.802972          0.709102         77.492320   \n","24274               8.365464          0.795007         69.980989   \n","24275               9.725526          0.734327         94.585853   \n","\n","       Thickness (mm) Sample  \n","0                 0.2     A1  \n","1                 0.2     A1  \n","2                 0.2     A1  \n","3                 0.2     A1  \n","4                 0.2     A1  \n","...               ...    ...  \n","24271             0.0    REF  \n","24272             0.0    REF  \n","24273             0.0    REF  \n","24274             0.0    REF  \n","24275             0.0    REF  \n","\n","[24276 rows x 9 columns]\n","Using device: cuda\n","Epoch [1/100], Loss: 2.1310\n","Epoch [2/100], Loss: 1.5674\n","Epoch [3/100], Loss: 1.3515\n","Epoch [4/100], Loss: 1.3677\n","Epoch [5/100], Loss: 1.0352\n","Epoch [6/100], Loss: 0.8247\n","Epoch [7/100], Loss: 1.1370\n","Epoch [8/100], Loss: 1.1440\n","Epoch [9/100], Loss: 0.7580\n","Epoch [10/100], Loss: 0.9999\n","Epoch [11/100], Loss: 0.9206\n","Epoch [12/100], Loss: 0.7340\n","Epoch [13/100], Loss: 0.9383\n","Epoch [14/100], Loss: 0.6277\n","Epoch [15/100], Loss: 0.6213\n","Epoch [16/100], Loss: 0.7394\n","Epoch [17/100], Loss: 0.8126\n","Epoch [18/100], Loss: 0.6807\n","Epoch [19/100], Loss: 0.4261\n","Epoch [20/100], Loss: 0.6137\n","Epoch [21/100], Loss: 0.7703\n","Epoch [22/100], Loss: 0.6079\n","Epoch [23/100], Loss: 0.3618\n","Epoch [24/100], Loss: 0.7042\n","Epoch [25/100], Loss: 0.6126\n","Epoch [26/100], Loss: 0.5986\n","Epoch [27/100], Loss: 0.6283\n","Epoch [28/100], Loss: 0.6299\n","Epoch [29/100], Loss: 0.5073\n","Epoch [30/100], Loss: 0.6152\n","Epoch [31/100], Loss: 0.6183\n","Epoch [32/100], Loss: 0.4268\n","Epoch [33/100], Loss: 0.4788\n","Epoch [34/100], Loss: 0.6540\n","Epoch [35/100], Loss: 0.5632\n","Epoch [36/100], Loss: 0.4018\n","Epoch [37/100], Loss: 0.4586\n","Epoch [38/100], Loss: 0.4402\n","Epoch [39/100], Loss: 0.6520\n","Epoch [40/100], Loss: 0.5061\n","Epoch [41/100], Loss: 0.4830\n","Epoch [42/100], Loss: 0.4218\n","Epoch [43/100], Loss: 0.7082\n","Epoch [44/100], Loss: 0.4233\n","Epoch [45/100], Loss: 0.5333\n","Epoch [46/100], Loss: 0.5119\n","Epoch [47/100], Loss: 0.4234\n","Epoch [48/100], Loss: 0.4344\n","Epoch [49/100], Loss: 0.4392\n","Epoch [50/100], Loss: 0.6935\n","Epoch [51/100], Loss: 0.5198\n","Epoch [52/100], Loss: 0.3043\n","Epoch [53/100], Loss: 0.5168\n","Epoch [54/100], Loss: 0.5086\n","Epoch [55/100], Loss: 0.5077\n","Epoch [56/100], Loss: 0.5968\n","Epoch [57/100], Loss: 0.3840\n","Epoch [58/100], Loss: 0.4040\n","Epoch [59/100], Loss: 0.4910\n","Epoch [60/100], Loss: 0.4998\n","Epoch [61/100], Loss: 0.3702\n","Epoch [62/100], Loss: 0.3708\n","Epoch [63/100], Loss: 0.4257\n","Epoch [64/100], Loss: 0.4824\n","Epoch [65/100], Loss: 0.4496\n","Epoch [66/100], Loss: 0.4358\n","Epoch [67/100], Loss: 0.2411\n","Epoch [68/100], Loss: 0.4887\n","Epoch [69/100], Loss: 0.4524\n","Epoch [70/100], Loss: 0.5018\n","Epoch [71/100], Loss: 0.4869\n","Epoch [72/100], Loss: 0.2764\n","Epoch [73/100], Loss: 0.3938\n","Epoch [74/100], Loss: 0.5617\n","Epoch [75/100], Loss: 0.5914\n","Epoch [76/100], Loss: 0.4403\n","Epoch [77/100], Loss: 0.2984\n","Epoch [78/100], Loss: 0.4188\n","Epoch [79/100], Loss: 0.4690\n","Epoch [80/100], Loss: 0.3302\n","Epoch [81/100], Loss: 0.1522\n","Epoch [82/100], Loss: 0.4376\n","Epoch [83/100], Loss: 0.4954\n","Epoch [84/100], Loss: 0.3667\n","Epoch [85/100], Loss: 0.4504\n","Epoch [86/100], Loss: 0.6155\n","Epoch [87/100], Loss: 0.4046\n","Epoch [88/100], Loss: 0.3305\n","Epoch [89/100], Loss: 0.4601\n","Epoch [90/100], Loss: 0.3748\n","Epoch [91/100], Loss: 0.2352\n","Epoch [92/100], Loss: 0.3400\n","Epoch [93/100], Loss: 0.3368\n","Epoch [94/100], Loss: 0.4443\n","Epoch [95/100], Loss: 0.4228\n","Epoch [96/100], Loss: 0.4091\n","Epoch [97/100], Loss: 0.4809\n","Epoch [98/100], Loss: 0.4612\n","Epoch [99/100], Loss: 0.5171\n","Epoch [100/100], Loss: 0.2992\n","Test Accuracy: 0.7805\n"]}],"source":["    # Set seed for reproducibility\n","    seed = config['seed']\n","    set_seed(seed)\n","\n","    # Load and preprocess data\n","    X, y = preprocess_data(data)\n","\n","    # Split the data into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=seed)\n","\n","    # Reshape data to fit LSTM input requirements [samples, time steps, features]\n","    # Assuming each sample is a sequence of length 1 (time steps = 1)\n","    X_train = X_train.unsqueeze(1)\n","    X_test = X_test.unsqueeze(1)\n","\n","    # Create DataLoader\n","    train_dataset = TensorDataset(X_train, y_train)\n","    test_dataset = TensorDataset(X_test, y_test)\n","    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","    # Set device\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    print(f\"Using device: {device}\")\n","\n","    # Initialize the model, loss function, and optimizer\n","    input_dim = X_train.shape[2]\n","    hidden_dim = 50\n","    output_dim = len(torch.unique(y))\n","    model = LSTMModel(input_dim, hidden_dim, output_dim).to(device)\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","    # Train the model\n","    train_model(model, train_loader, criterion, optimizer, device)\n","\n","    # Evaluate the model\n","    evaluate_model(model, test_loader, device)\n","\n","    # Save the model\n","    torch.save(model.state_dict(), 'lstm_model.pth')\n","\n","    # # Save the model as onnx\n","    # torch.onnx.export(model, X_train, 'lstm_model.onnx')"]},{"cell_type":"markdown","metadata":{"id":"faC6EfmDMsRL"},"source":["## Run inference"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":480},"executionInfo":{"elapsed":493,"status":"error","timestamp":1730120862602,"user":{"displayName":"DANIEL MORENO PARIS","userId":"17921422726169854440"},"user_tz":-60},"id":"nxNfBFvFowYp","outputId":"c525951b-46e4-4e4f-9232-55d63400cfac"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-59-f0ed6b1134de>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(input_path))\n"]},{"ename":"RuntimeError","evalue":"For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-59-f0ed6b1134de>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-54-5a20863c5a96>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mh_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mc_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1113\u001b[0m                             \u001b[0;34mf\"also be 2-D but got ({hx[0].dim()}-D, {hx[1].dim()}-D) tensors\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m                         )\n\u001b[0;32m-> 1115\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m                     \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m                 \u001b[0;31m# Each batch of the hidden state should match the input sequence that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors"]}],"source":["# Run model Inference\n","\n","# Load test data\n","\n","\n","\n","# Load pretrained model\n","input_path = '/content/lstm_model.pth'\n","model.load_state_dict(torch.load(input_path))\n","model.eval()\n","\n","with torch.no_grad():\n","    X = X.to(device)\n","    outputs = model(X)\n","    _, predicted = torch.max(outputs.data, 1)\n","print(predicted)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EWlhqvklpFQQ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMcH5jIwSmKBObkcqp1gR9b","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
