{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peUcVKtbGPfD"
      },
      "source": [
        "# Multi-Layer Perceptron Classification Model\n",
        "\n",
        "This notebook demonstrates how to load data, preprocess it, define an MLP model, train the model, and evaluate its performance. The data is assumed to be in CSV format and stored in a directory.\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, we need to install the necessary libraries. Run the following cell to install them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAZ2n50rGS-C",
        "outputId": "b91731d2-ab4b-4fdf-c276-74f7e39e3c15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install torch torchvision torchaudio\n",
        "%pip install pandas scikit-learn\n",
        "%pip install wandb onnx -Uq\n",
        "%pip install joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4d3KxhxGML8"
      },
      "source": [
        "## Import Libraries and seed\n",
        "Import the necessary libraries for data processing, model building, training, and evaluation. Adding a seed ensures reproducibility by making sure that the random number generation is consistent across different runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a9HvzrNG8iw",
        "outputId": "863913e7-a236-4d12-b3a1-77d8a2adfe44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "import wandb\n",
        "\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUQtUPxSBzq4",
        "outputId": "44aedbe6-3792-4d72-fe2c-5bea99497dd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "AoCyZSTt7qqS",
        "outputId": "e0ae8d64-e03b-4486-9da1-4fe62ea5fe37"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login()\n",
        "#94b4debef3cc9601df4d91995649548f8ab3a097"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1-6Xv6LHHmZ"
      },
      "source": [
        "## Load Data from Github Repository\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eI7hrAaVHL44"
      },
      "outputs": [],
      "source": [
        "## Remove PIC-PAPER-01 folder:\n",
        "!rm -rf PIC-PAPER-01\n",
        "\n",
        "# # Download Github Repo (Private) https://stackoverflow.com/questions/74532852/clone-github-repo-with-fine-grained-token/78280453#78280453\n",
        "# !git clone --no-checkout https://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@github.com/danimp94/PIC-PAPER-01.git\n",
        "\n",
        "# # To clone data folder only:\n",
        "# %cd PIC-PAPER-01 # Navigate to the repository directory\n",
        "# !git sparse-checkout init --cone # Initialize sparse-checkout\n",
        "# !git sparse-checkout set data # Set the sparse-checkout to include only the data/ folder\n",
        "# !git checkout # Checkout the specified folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hAY8BfVX9XCK"
      },
      "outputs": [],
      "source": [
        "def load_data_from_directory(input_path):\n",
        "    data_frames = []\n",
        "    for file in os.listdir(input_path):\n",
        "        if file.endswith('.csv'):\n",
        "            df = pd.read_csv(os.path.join(input_path, file), delimiter=';', header=0)\n",
        "            data_frames.append(df)\n",
        "    data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "    print(data)\n",
        "    print(data.shape)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiCTw-qcKXhn"
      },
      "source": [
        "## Preprocessing Data\n",
        "Define a function to preprocess the data. This includes encoding categorical labels and standardizing the features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zJoZqi5LDPl8"
      },
      "outputs": [],
      "source": [
        "def calculate_averages_and_dispersion(data, data_percentage):\n",
        "    df = data\n",
        "    results = []\n",
        "    for (sample, freq), group in df.groupby(['Sample', 'Frequency (GHz)']):\n",
        "        window_size = max(1, int(len(group) * data_percentage / 100))\n",
        "        # print(f\"Processing sample: {sample}, frequency: {freq} with window size: {window_size}\")\n",
        "        for start in range(0, len(group), window_size):\n",
        "            window_data = group.iloc[start:start + window_size]\n",
        "            mean_values = window_data[['LG (mV)', 'HG (mV)']].mean()\n",
        "            std_deviation_values = window_data[['LG (mV)', 'HG (mV)']].std()\n",
        "            results.append({\n",
        "                'Frequency (GHz)': freq,\n",
        "                'LG (mV) mean': mean_values['LG (mV)'],\n",
        "                'HG (mV) mean': mean_values['HG (mV)'],\n",
        "                'LG (mV) std deviation': std_deviation_values['LG (mV)'],\n",
        "                'HG (mV) std deviation': std_deviation_values['HG (mV)'],\n",
        "                'Thickness (mm)': window_data['Thickness (mm)'].iloc[0], # iloc[0]\n",
        "                'Sample': sample,\n",
        "            })\n",
        "    results_df = pd.DataFrame(results)\n",
        "    # results_df.to_csv(output_file, sep=';', index=False)\n",
        "    # print(f\"Processed {input_file} and saved to {output_file}\")\n",
        "    print(results_df)\n",
        "    return results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KZPdMwkkKmm7"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(data, data_percentage):\n",
        "    # Windowing the data\n",
        "    data = calculate_averages_and_dispersion(data, data_percentage)\n",
        "    print(data.shape)\n",
        "\n",
        "    # Assuming the last column is the target\n",
        "    X = data.iloc[:, :-1].values\n",
        "    y = data.iloc[:, -1].values\n",
        "\n",
        "    # Encode the target variable if it's categorical\n",
        "    if y.dtype == 'object':\n",
        "        le = LabelEncoder()\n",
        "        y = le.fit_transform(y)\n",
        "\n",
        "    # le is the fitted LabelEncoder\n",
        "    joblib.dump(le, 'label_encoder.pkl')\n",
        "\n",
        "    # Get the original labels and their encoded values\n",
        "    original_labels = le.classes_\n",
        "    encoded_values = le.transform(original_labels)\n",
        "\n",
        "    # Create a DataFrame to display the mapping\n",
        "    label_mapping_df = pd.DataFrame({\n",
        "        'Original Label': original_labels,\n",
        "        'Encoded Value': encoded_values\n",
        "    })\n",
        "\n",
        "    # Display the DataFrame\n",
        "    print(label_mapping_df)\n",
        "\n",
        "    # Standardize the features\n",
        "    print('prestandarization: ',X)\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "    print('post-std: ', X)\n",
        "\n",
        "    # # Convert to PyTorch tensors\n",
        "    # X = torch.tensor(X, dtype=torch.float32)\n",
        "    # y = torch.tensor(y, dtype=torch.long)\n",
        "    # print(X.shape)\n",
        "    # print(y.shape)\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTXvxCzu6MBA",
        "outputId": "0969acc6-57f8-4742-bd03-09b92ff9b449"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Sample  Frequency (GHz)     LG (mV)    HG (mV)  Thickness (mm)\n",
            "0           A1            100.0   -7.080942  -0.854611             0.2\n",
            "1           A1            100.0   67.024785   0.244141             0.2\n",
            "2           A1            100.0  124.893178  -1.098776             0.2\n",
            "3           A1            100.0   91.075571   0.000000             0.2\n",
            "4           A1            100.0   48.956174   0.122094             0.2\n",
            "...        ...              ...         ...        ...             ...\n",
            "2737958    REF            600.0    0.366256  16.237333             0.0\n",
            "2737959    REF            600.0    0.000000  -7.080942             0.0\n",
            "2737960    REF            600.0   -0.244170  15.260652             0.0\n",
            "2737961    REF            600.0    0.366256  20.021975             0.0\n",
            "2737962    REF            600.0    0.122085  13.185203             0.0\n",
            "\n",
            "[2737963 rows x 5 columns]\n",
            "(2737963, 5)\n",
            "       Frequency (GHz)  LG (mV) mean  HG (mV) mean  LG (mV) std deviation  \\\n",
            "0                100.0     54.879155     -0.022198              29.958659   \n",
            "1                100.0     54.511665      0.048093              28.096155   \n",
            "2                100.0     55.099894     -0.118380              26.833871   \n",
            "3                100.0     48.387674      0.103588              28.843498   \n",
            "4                100.0     49.932853     -0.071525              23.093397   \n",
            "...                ...           ...           ...                    ...   \n",
            "24271            600.0     -0.006143     10.237498               0.890999   \n",
            "24272            600.0     -0.006910     10.949278               0.858148   \n",
            "24273            600.0      0.029178     10.547702               0.842082   \n",
            "24274            600.0      0.065266     10.051683               0.891632   \n",
            "24275            600.0     -0.228910      9.766817               0.856929   \n",
            "\n",
            "       HG (mV) std deviation  Thickness (mm) Sample  \n",
            "0                   0.644211             0.2     A1  \n",
            "1                   0.704742             0.2     A1  \n",
            "2                   0.755493             0.2     A1  \n",
            "3                   0.854655             0.2     A1  \n",
            "4                   0.650231             0.2     A1  \n",
            "...                      ...             ...    ...  \n",
            "24271               8.205224             0.0    REF  \n",
            "24272               8.679982             0.0    REF  \n",
            "24273               8.802972             0.0    REF  \n",
            "24274               8.365464             0.0    REF  \n",
            "24275               9.725526             0.0    REF  \n",
            "\n",
            "[24276 rows x 7 columns]\n",
            "(24276, 7)\n",
            "   Original Label  Encoded Value\n",
            "0              A1              0\n",
            "1              B1              1\n",
            "2              C1              2\n",
            "3              D1              3\n",
            "4              E1              4\n",
            "5              E2              5\n",
            "6              E3              6\n",
            "7              F1              7\n",
            "8              G1              8\n",
            "9              H1              9\n",
            "10             I1             10\n",
            "11             J1             11\n",
            "12             K1             12\n",
            "13             L1             13\n",
            "14             M1             14\n",
            "15             N1             15\n",
            "16            REF             16\n",
            "prestandarization:  [[ 1.00000000e+02  5.48791546e+01 -2.21984593e-02  2.99586589e+01\n",
            "   6.44211013e-01  2.00000000e-01]\n",
            " [ 1.00000000e+02  5.45116655e+01  4.80931111e-02  2.80961548e+01\n",
            "   7.04741777e-01  2.00000000e-01]\n",
            " [ 1.00000000e+02  5.50998945e+01 -1.18380115e-01  2.68338710e+01\n",
            "   7.55492800e-01  2.00000000e-01]\n",
            " ...\n",
            " [ 6.00000000e+02  2.91776164e-02  1.05477018e+01  8.42082041e-01\n",
            "   8.80297222e+00  0.00000000e+00]\n",
            " [ 6.00000000e+02  6.52656478e-02  1.00516826e+01  8.91631588e-01\n",
            "   8.36546406e+00  0.00000000e+00]\n",
            " [ 6.00000000e+02 -2.28909625e-01  9.76681712e+00  8.56929097e-01\n",
            "   9.72552584e+00  0.00000000e+00]]\n",
            "post-std:  [[-1.69841555  1.89048564 -0.59910406  3.78386722 -0.66239994 -0.49655985]\n",
            " [-1.69841555  1.87496667 -0.59876148  3.5203746  -0.65782384 -0.49655985]\n",
            " [-1.69841555  1.89980743 -0.59957282  3.34179648 -0.65398709 -0.49655985]\n",
            " ...\n",
            " [ 1.69841555 -0.42581485 -0.54758935 -0.3353201  -0.04560149 -0.71054001]\n",
            " [ 1.69841555 -0.42429087 -0.55000681 -0.32831022 -0.0786769  -0.71054001]\n",
            " [ 1.69841555 -0.43671381 -0.55139517 -0.33321966  0.02414312 -0.71054001]]\n"
          ]
        }
      ],
      "source": [
        "input_path = '/content/drive/MyDrive/PhD/Colab Notebooks/training_data/'\n",
        "data = load_data_from_directory(input_path)\n",
        "\n",
        "# Load and preprocess data\n",
        "X, y = preprocess_data(data, data_percentage=3.7) # 1s window size\n",
        "\n",
        "\n",
        "# print(le.classes_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZjha9Cx6MBB"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLRhwd8cKKJH",
        "outputId": "430defea-75da-46d4-a51c-14cf8cac091e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epochs': 10, 'seed': 48, 'classes': 17, 'learning_rate': 0.002, 'dataset': 'experiment_1', 'architecture': 'MLP', 'hidden_dim': 16, 'batch_size': 32}\n"
          ]
        }
      ],
      "source": [
        "config = dict(\n",
        "    epochs = 10,\n",
        "    seed = 48,\n",
        "    classes = 17,\n",
        "    learning_rate = 0.002,\n",
        "    dataset = \"experiment_1\",\n",
        "    architecture = \"MLP\",\n",
        "    hidden_dim = 16,\n",
        "    batch_size = 32\n",
        ")\n",
        "\n",
        "print(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73lbgWbceGk8"
      },
      "source": [
        "## NN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nGtMP0a_d1zg"
      },
      "outputs": [],
      "source": [
        "class Multiclass(nn.Module):\n",
        "    ''' Multiclass classification\n",
        "        input_size: number of features\n",
        "        hidden_size: number of neurons in the hidden layer\n",
        "        num_classes: number of classes to classify\n",
        "    '''\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(Multiclass, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)  # First fully connected layer\n",
        "        self.relu = nn.ReLU() # Activation layer (ReLU)\n",
        "        self.fc_out = nn.Linear(hidden_size, num_classes) # Last fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc_out(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEtZPi2fLQGL"
      },
      "source": [
        "## Run Training\n",
        "\n",
        "Do not use it if just want to run inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1OR7_UmMhT7_"
      },
      "outputs": [],
      "source": [
        "def train_model(X_train, y_train, X_test, y_test, config):\n",
        "    # Set random seed\n",
        "    set_seed(config['seed'])\n",
        "\n",
        "    # Initialize the model\n",
        "    input_dim = X.shape[-1]\n",
        "    hidden_dim = config['hidden_dim']\n",
        "    output_dim = config['classes']\n",
        "    print(input_dim, hidden_dim, output_dim)\n",
        "    model = Multiclass(input_dim, hidden_dim, output_dim).to(device)\n",
        "\n",
        "    # Define the loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
        "\n",
        "    # Convert data to PyTorch tensors\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "    y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "    # Create TensorDataset and DataLoader for training data\n",
        "    train_dataset = TensorDataset(X_train, y_train)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)  # Shuffle for better training\n",
        "\n",
        "    # Create TensorDataset and DataLoader for test data\n",
        "    test_dataset = TensorDataset(X_test, y_test)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(config['epochs']):\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, target)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            # Update weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # Evaluate on test data\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                outputs = model(data)\n",
        "                test_loss += criterion(outputs, target).item()  # Sum up batch loss\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                correct += (predicted == target).sum().item()\n",
        "\n",
        "        test_loss /= len(test_loader.dataset)\n",
        "        accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "        print(f'Epoch: {epoch+1}, Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC8fnd6ni4sI",
        "outputId": "4cdab6da-84b2-46dc-926f-efdd150fbcf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6 16 17\n"
          ]
        }
      ],
      "source": [
        "# Split trainig data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, shuffle=True)\n",
        "\n",
        "train_model(X_train, y_train, X_test, y_test, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acwT3zcgjWPj"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3-PgjKIjVfM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn-KrUz59yds"
      },
      "source": [
        "## Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AwFKsiy3LVKk"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), 'lstm_model.pth')\n",
        "\n",
        "# # Save the model as onnx\n",
        "# torch.onnx.export(model, X_train, 'lstm_model.onnx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ggQaw0lISGG"
      },
      "outputs": [],
      "source": [
        "def preprocess_test_data(data, data_percentage):\n",
        "    # Windowing the data\n",
        "    data = calculate_averages_and_dispersion(data, data_percentage)\n",
        "    print(data.shape)\n",
        "\n",
        "    # Assuming the last column is the target\n",
        "    X = data.iloc[:, :-1].values\n",
        "    y = data.iloc[:, -1].values\n",
        "\n",
        "    # Encode labeling of target data using presaved pkl file\n",
        "    # Load label encoder\n",
        "    label_encoder_path = '/content/drive/MyDrive/PhD/Colab Notebooks/label_encoder.pkl'\n",
        "    le = joblib.load(label_encoder_path)\n",
        "    y = le.transform(y)\n",
        "    print('y: ', y)\n",
        "\n",
        "    # Standardize the features\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    X = torch.tensor(X, dtype=torch.float32)\n",
        "    y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXfBY8sm1Z43"
      },
      "source": [
        "## Load New Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ArtddUGY1Z43",
        "outputId": "92ab76eb-d330-4536-b71d-f76e551b9503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['REF_1.csv', '.ipynb_checkpoints']\n",
            "      Sample  Frequency (GHz)    LG (mV)    HG (mV)  Thickness (mm)\n",
            "0        REF              100  32.718837  -0.854611               0\n",
            "1        REF              100  19.289465   0.122118               0\n",
            "2        REF              100  29.178366   0.244164               0\n",
            "3        REF              100  42.729825   0.854540               0\n",
            "4        REF              100  54.083751   0.366259               0\n",
            "...      ...              ...        ...        ...             ...\n",
            "63784    REF              600  -0.244170  33.207178               0\n",
            "63785    REF              600  -0.854596  41.753143               0\n",
            "63786    REF              600   0.854596  21.242827               0\n",
            "63787    REF              600   0.000000  36.747649               0\n",
            "63788    REF              600   0.244170  27.225003               0\n",
            "\n",
            "[63789 rows x 5 columns]\n",
            "(63789, 5)\n",
            "     Frequency (GHz)  LG (mV) mean  HG (mV) mean  LG (mV) std deviation  \\\n",
            "0                100     51.378981     -0.063946              20.119522   \n",
            "1                100     43.726854      0.056686              18.066434   \n",
            "2                100     44.811088      0.074118              18.031144   \n",
            "3                100     46.787705      0.005805              20.747336   \n",
            "4                100     46.867642     -0.040696              21.492982   \n",
            "..               ...           ...           ...                    ...   \n",
            "658              600      0.112186     33.592131               0.810680   \n",
            "659              600      0.103387     32.597852               0.896565   \n",
            "660              600      0.276067     33.182981               0.890577   \n",
            "661              600     -0.067092     33.749412               1.053275   \n",
            "662              600     -0.313933     35.073338               0.821568   \n",
            "\n",
            "     HG (mV) std deviation  Thickness (mm) Sample  \n",
            "0                 0.738717               0    REF  \n",
            "1                 0.700541               0    REF  \n",
            "2                 0.717143               0    REF  \n",
            "3                 0.783414               0    REF  \n",
            "4                 0.716474               0    REF  \n",
            "..                     ...             ...    ...  \n",
            "658               8.833808               0    REF  \n",
            "659               9.363379               0    REF  \n",
            "660               9.369229               0    REF  \n",
            "661               9.338285               0    REF  \n",
            "662               8.520847               0    REF  \n",
            "\n",
            "[663 rows x 7 columns]\n",
            "(663, 7)\n",
            "y:  [16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16]\n"
          ]
        }
      ],
      "source": [
        "# Load new data\n",
        "input_data_test = '/content/drive/MyDrive/PhD/Colab Notebooks/test_data/'\n",
        "print(os.listdir(input_data_test))\n",
        "\n",
        "data_test = load_data_from_directory(input_data_test)\n",
        "\n",
        "# Load and preprocess data\n",
        "X_test, y_test = preprocess_test_data(data_test, data_percentage=8.33) # 1s window size\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faC6EfmDMsRL"
      },
      "source": [
        "## Run inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nxNfBFvFowYp",
        "outputId": "cb2d9130-c306-4e3f-a749-55b004d4bef4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "input_dim: 6, hidden_dim: 16, output_dim: 17\n",
            "Model outputs shape: tensor([[ 1.3491,  3.5732,  1.2201,  ..., -3.7836, -3.6188, -4.8005],\n",
            "        [ 1.8630,  5.4226,  1.2803,  ..., -4.9602, -4.7864, -6.1734],\n",
            "        [ 1.9243,  5.4553,  1.1771,  ..., -4.8817, -4.7239, -6.1027],\n",
            "        ...,\n",
            "        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
            "        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
            "        [    nan,     nan,     nan,  ...,     nan,     nan,     nan]])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "['B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1'\n",
            " 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1'\n",
            " 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1'\n",
            " 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1'\n",
            " 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1'\n",
            " 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1'\n",
            " 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1'\n",
            " 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1'\n",
            " 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1'\n",
            " 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1' 'B1'\n",
            " 'B1' 'B1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1' 'A1'\n",
            " 'A1' 'A1' 'A1' 'A1' 'A1']\n",
            "Classes in label encoder: ['A1' 'B1' 'C1' 'D1' 'E1' 'E2' 'E3' 'F1' 'G1' 'H1' 'I1' 'J1' 'K1' 'L1'\n",
            " 'M1' 'N1' 'REF']\n",
            "Number of classes: 17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-231-7cbfd7c448a5>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n",
            "<ipython-input-231-7cbfd7c448a5>:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_test = torch.tensor(y_test).long().to(device)\n"
          ]
        }
      ],
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "# Initialize the model\n",
        "input_dim = X_test.shape[-1]\n",
        "hidden_dim = config['hidden_dim']  # Replace with the hidden dimension used during training\n",
        "output_dim = config['classes']  # Replace with the number of output classes used during training\n",
        "model = Multiclass(input_dim, hidden_dim, output_dim).to(device)\n",
        "\n",
        "# # Load label encoder\n",
        "label_encoder_path = '/content/drive/MyDrive/PhD/Colab Notebooks/label_encoder.pkl'\n",
        "le = joblib.load(label_encoder_path)\n",
        "\n",
        "# Load pretrained model\n",
        "model_path = '/content/drive/MyDrive/PhD/Colab Notebooks/lstm_model.pth'\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    X_test = X_test.unsqueeze(1).to(device)\n",
        "    y_test = torch.tensor(y_test).long().to(device)\n",
        "    outputs = model(X_test)\n",
        "    print(\"Model outputs shape:\", outputs.data)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "# Decode the predicted labels\n",
        "# Now perform the inverse transform\n",
        "\n",
        "print(predicted)\n",
        "\n",
        "predicted_labels = le.inverse_transform(predicted.cpu().numpy())\n",
        "\n",
        "print(predicted_labels)\n",
        "\n",
        "print(\"Classes in label encoder:\", le.classes_)\n",
        "print(\"Number of classes:\", len(le.classes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktsgpY21NcOV"
      },
      "source": [
        "| Original Label | Encoded Value |\n",
        "|----------------|---------------|\n",
        "| A1             | 0             |\n",
        "| B1             | 1             |\n",
        "| C1             | 2             |\n",
        "| D1             | 3             |\n",
        "| E1             | 4             |\n",
        "| E2             | 5             |\n",
        "| E3             | 6             |\n",
        "| F1             | 7             |\n",
        "| G1             | 8             |\n",
        "| H1             | 9             |\n",
        "| I1             | 10            |\n",
        "| J1             | 11            |\n",
        "| K1             | 12            |\n",
        "| L1             | 13            |\n",
        "| M1             | 14            |\n",
        "| N1             | 15            |\n",
        "| REF            | 16            |"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
